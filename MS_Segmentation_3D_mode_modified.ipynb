{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MS_Segmentation_3D_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AattLHDvEMlg",
        "jQ4u3Mi-EbGY",
        "RiCZ5HSZEwkS",
        "JrPignYnE8WQ",
        "8gsK42XfPMrP"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYF5f6vGEBJF",
        "colab_type": "text"
      },
      "source": [
        "# UNION 3D MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AattLHDvEMlg",
        "colab_type": "text"
      },
      "source": [
        "## Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCIKjffpJnY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "    \n",
        "def modality(Path,index):\n",
        "    X = []\n",
        "    X_per_paitent = []\n",
        "    p=os.listdir(Path) \n",
        "    recs_in=[]\n",
        "    counter=0\n",
        "    counter_2=0\n",
        "    #recs_segmented=[]\n",
        "    for i in p[:14]:                                                                      # Loading all the folders in the given path\n",
        "        q = os.listdir(os.path.join(Path,i))     \n",
        "\n",
        "        x = nib.load(os.path.join(Path,i,q[index]))         \n",
        "        f = x.get_fdata()\n",
        "        f = np.asarray(f,'float32')\n",
        "        \n",
        "        ct=0\n",
        "        recs_in.append(f.shape[2])\n",
        "        #print(counter_2)\n",
        "        counter_2+=1\n",
        "        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n",
        "            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n",
        "            if(index not in [3,4,5,6,7,8,9] and np.sum(_slice) != 0 ): \n",
        "                if index==1:\n",
        "                  ct+=1 \n",
        "                  counter+=1 \n",
        "                 # print(counter)                                      # To check whether the slice is null or not\n",
        "              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n",
        "                  _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001)\n",
        "                else:\n",
        "                                              # To check whether the slice is null or not\n",
        "              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n",
        "                  _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n",
        "            elif(index in [3,4,5,6,7,8,9]):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n",
        "                _slice = np.array(_slice)\n",
        "                _slice[_slice > 0] = 1.0\n",
        "                _slice[_slice < 0] = 0.0\n",
        "            _slice = _slice.T\n",
        "            _slice = _slice[:,:,np.newaxis]\n",
        "            X.append(_slice)\n",
        "       \n",
        "   # X=np.array(X,dtype='float32')\n",
        "    return X,recs_in"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CzV3b0Faeiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual,recs): \n",
        "     \n",
        "    X=[]\n",
        "    Y=[]\n",
        "    counter=0\n",
        "    counter_2=0\n",
        "    mult=0;\n",
        "    count=0\n",
        "    rec=[]\n",
        "    keep_count=[]\n",
        "    keep=[]\n",
        "    print(recs)\n",
        "    r=np.array(recs,dtype='float32')\n",
        "    print(np.sum(r))\n",
        "    print(len(X_Dp))\n",
        "\n",
        "    for i in range(len(X_Dp)):  \n",
        "        if counter==(recs[mult]):\n",
        "          print(counter)\n",
        "          mult+=1\n",
        "          rec.append(count)\n",
        "          counter=0\n",
        "          print(counter_2)\n",
        "          count=0\n",
        "        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n",
        "        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n",
        "            X.append(final_slice)\n",
        "            Y.append(Y_Manual[i])\n",
        "            \n",
        "            count+=1\n",
        "        counter+=1\n",
        "        counter_2+=1\n",
        "\n",
        "    \n",
        "    rec.append(count)\n",
        "#   Converting the list into array  \n",
        "    X=np.array(X,dtype='float32')\n",
        "    Y=np.array(Y,dtype='float32')\n",
        "    rec=np.array(rec,dtype='float32')\n",
        "    \n",
        "    return X,Y,rec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDfO2AeSnQvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_data(X,Y,rec):\n",
        "    np.save(\"drive/My Drive/MS_data/X_union_new.npy\",X)\n",
        "    np.save(\"drive/My Drive/MS_data/Y_union_new.npy\",Y)\n",
        "    np.save(\"drive/My Drive/MS_data/union_new_rec_after_removal.npy\",rec)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUpSEmO_oFzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def union(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7):\n",
        "  Y=[]\n",
        "  sum2=[]\n",
        "  flag=0\n",
        "  #y=np.array()\n",
        "  print(\"A\")\n",
        "  for i in range (len(Y_1)):\n",
        "    #print(Y_1[i])\n",
        "    \n",
        "        f=np.concatenate((Y_1[i],Y_2[i],Y_3[i],Y_4[i],Y_5[i],Y_6[i],Y_7[i]),axis=-1)\n",
        "        sum=np.sum(f,axis=2)\n",
        "       # print(sum)\n",
        "        \n",
        "          #print(j)\n",
        "        sum_1=np.divide(sum,7)\n",
        "        sum_1=np.ceil(sum_1)\n",
        "        sum2.append(sum_1)\n",
        "\n",
        "    #sum2=np.array(sum2,dtype='float32')\n",
        "    \n",
        "        \n",
        "  return sum2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ4u3Mi-EbGY",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing DataSets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syzATPlboPcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import dataPrepare as process\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n",
        "#import Modified_UNet \n",
        "#import plots\n",
        "#import Metrics\n",
        "\n",
        "# Setting the path\n",
        "Path='drive/My Drive/Pre-processed'\n",
        "\n",
        "\n",
        "\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n",
        "X_Dp_t,rec      =   modality(Path,0)\n",
        "X_Flair_t,rec_1   =   modality(Path,1)\n",
        "X_Gado_t,rec    =   modality(Path,2)\n",
        "X_T1_t,rec      =   modality(Path,10)\n",
        "X_T2_t,rec      =   modality(Path,11)\n",
        "rec=np.array(rec_1,dtype='float32')\n",
        "np.save(\"drive/My Drive/MS_data/union_new_rec_before_removal.npy\",rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srdK34TwP1ms",
        "colab_type": "code",
        "outputId": "ca4e3671-04fb-4cae-d93b-a8abfbf67d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX79MewjodRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import dataPrepare as process\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n",
        "#import Modified_UNet \n",
        "#import plots\n",
        "#import Metrics\n",
        "\n",
        "# Setting the path\n",
        "Path='drive/My Drive/Pre-processed'\n",
        "Y_1,rec  =   modality(Path,3)\n",
        "Y_2,rec  =   modality(Path,4)\n",
        "Y_3,rec  =   modality(Path,5)\n",
        "Y_4,rec  =   modality(Path,6)\n",
        "Y_5,rec  =   modality(Path,7)\n",
        "Y_6,rec  =   modality(Path,8)\n",
        "Y_7,rec  =   modality(Path,9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKZkQ3uroH07",
        "colab_type": "code",
        "outputId": "d0d1be89-86b3-4f6f-c9d8-7d424d55cc8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_Manual=union(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkAjIX2UVK9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.save(\"drive/My Drive/MS_data/Y_manual_new.npy\",Y_Manual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzLefJh_Z8IK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_manual=list(Y_Manual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTHwKTWjj4Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=np.load(\"drive/My Drive/MS_data/Y_manual_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9AsuZHRoKAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y,rec = remove_null_samples(X_Dp_t, X_Flair_t, X_Gado_t, X_T1_t, X_T2_t, Y_manual,rec_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylJ6XQHMq6vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "store_data(X,Y,rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGVsUHhyrBL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "Y=np.load(\"drive/My Drive/MS_data/Y_union_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SccUiBcot4-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taZnaq3mt7cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_1=Y_Manual[:1401]\n",
        "Y_2=Y_Manual[1401:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usOtbVExt8wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p=[]\n",
        "y=[]\n",
        "z=[]\n",
        "a=[]\n",
        "n=1\n",
        "for i in Y_1:\n",
        "  print(n)\n",
        "  for j in i:\n",
        "    for k in j:\n",
        "      #print(k)\n",
        "      a.append(k)\n",
        "     # print(a)\n",
        "      z.append(a)\n",
        "      a=[]\n",
        "    #print(z)\n",
        "    y.append(z)\n",
        "    z=[]\n",
        "  p.append(y)\n",
        "  y=[]\n",
        "  n+=1\n",
        "\n",
        "\n",
        "#print(p)\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pet5yUkouAPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=np.array(p)\n",
        "np.save(\"drive/My Drive/MS_data/temp_1_new.npy\",temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0BnWXrDuA0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q=[]\n",
        "y=[]\n",
        "z=[]\n",
        "a=[]\n",
        "n=1401\n",
        "for i in Y_2:\n",
        "  print(n)\n",
        "  for j in i:\n",
        "    for k in j:\n",
        "      #print(k)\n",
        "      a.append(k)\n",
        "     # print(a)\n",
        "      z.append(a)\n",
        "      a=[]\n",
        "    #print(z)\n",
        "    y.append(z)\n",
        "    z=[]\n",
        "  q.append(y)\n",
        "  y=[]\n",
        "  n+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz_ePYqHuDKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp2=np.array(q)\n",
        "np.save(\"drive/My Drive/MS_data/temp_2_new.npy\",temp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnX_jmQuFth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=np.load(\"drive/My Drive/MS_data/temp_1_new.npy\")\n",
        "p=list(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5IaMRKNuHW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp2=np.load(\"drive/My Drive/MS_data/temp_2_new.npy\")\n",
        "q=list(temp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qByqrVa5uIvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j=1401\n",
        "for i in q:\n",
        "  print(j)\n",
        "  p.append(i)\n",
        "  j+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FkrLTNduNCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\",p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOpVvUmrLUdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "P=np.load(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgLo-nESs8Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWrx4FyktDzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Kwef7CuN4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y=[]\n",
        "d_temp_1=[]\n",
        "d_temp_2=[]\n",
        "for i in range(len(Y[0])):\n",
        "  d_temp_1=[]\n",
        "  for j in range(len(Y[0][0])):\n",
        "    d_temp_2=[]\n",
        "    for k in range(len(Y[0][0][0])):\n",
        "      d_temp_2.append(0.)\n",
        "    d_temp_1.append(d_temp_2)\n",
        "  dummy_y.append(d_temp_1)\n",
        "Y_dummy=np.array(dummy_y, dtype='float32')\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReQHjsh-xP_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.load(\"drive/My Drive/MS_data/X_union_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uFj_QNFx5Sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_MLJSObxNIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_x=[]\n",
        "d_temp_1=[]\n",
        "d_temp_2=[]\n",
        "for i in range(len(X[0])):\n",
        "  d_temp_1=[]\n",
        "  for j in range(len(X[0][0])):\n",
        "    d_temp_2=[]\n",
        "    for k in range(len(X[0][0][0])):\n",
        "      d_temp_2.append(0.)\n",
        "    d_temp_1.append(d_temp_2)\n",
        "  dummy_x.append(d_temp_1)\n",
        "X_dummy=np.array(dummy_x, dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7yLaaPQyHgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_dummy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geCW3Vpeuf8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Y=np.load(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\")\n",
        "X=np.load(\"drive/My Drive/MS_data/X_union_new.npy\")\n",
        "#r=np.load(\"drive/My Drive/MS_data/union_new_rec_after_removal.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddq0jtVO4YEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)\n",
        "#Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb-6TQsLqc13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=Y.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBrcxwD9zWLy",
        "colab_type": "code",
        "outputId": "d90c54c9-5096-4f39-da4d-c3d64ba1fe0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMi_8pUYzwER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extra=[0,1,6,4,6,0,5,0,4,3,1,3,3,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Juxcrr4hso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext=np.array(extra,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p4sdFME4qUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s=np.sum(ext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgb6Eh2w0BX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r=np.load(\"drive/My Drive/MS_data/union_new_rec_after_removal.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx5aWSi_0HlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec=list(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPJFT4K90LKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7wbeeen0Sc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j=0\n",
        "index=0\n",
        "for i in extra:\n",
        "  k=0\n",
        "  \n",
        "  print(i)\n",
        "  index=index+rec[j]\n",
        "  j+=1\n",
        "  while(k<i):\n",
        "    index=index+k\n",
        "    print(index)\n",
        "    index=int(index)\n",
        "    Y.insert(index,Y_dummy)\n",
        "    X.insert(index,X_dummy)\n",
        "\n",
        "    k+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlEjbPeZuh3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec=list(r)\n",
        "X=list(X)\n",
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyanMQSYNhdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.array(X,dtype='float32')\n",
        "Y=np.array(Y,dtype='float32')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M7nKfjAQ5Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/Actual_X.npy\",X)\n",
        "np.save(\"drive/My Drive/MS_data/Actual_Y.npy\",Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PJhn7d9O0Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "Y=np.load(\"drive/My Drive/MS_data/Actual_X.npy\")\n",
        "X=np.load(\"drive/My Drive/MS_data/Actual_Y.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYG1ndywBQYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_1=[]\n",
        "Y_1=[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wi0K2bKBXtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)\n",
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UnFSs1HBim5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_x_p=0\n",
        "length=8\n",
        "index_x=length\n",
        "index_y_p=0\n",
        "index_y=length\n",
        "x_temp=[]\n",
        "y_temp=[]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY9EZjehB_7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while index_x<=len(X) and index_y<=len(Y):\n",
        "  x_temp=X[index_x_p:index_x]\n",
        "  y_temp=Y[index_y_p:index_y]\n",
        "  x_temp_1=np.array(x_temp,dtype='float32')\n",
        "  y_temp_1=np.array(y_temp,dtype='float32')\n",
        "  X_1.append(x_temp_1)\n",
        "  Y_1.append(y_temp_1)\n",
        "  index_y_p=index_y_p+length\n",
        "  index_x_p=index_x_p+length\n",
        "  index_x=index_x+length\n",
        "  index_y=index_y+length\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgZ1El2dSpHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_1=np.array(X_1,dtype='float32')\n",
        "Y_1=np.array(Y_1,dtype='float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n1sIu0zE4zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/train_X.npy\",X_1)\n",
        "np.save(\"drive/My Drive/MS_data/train_Y.npy\",Y_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_er8KWNbXhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_1=np.load(\"drive/My Drive/MS_data/train_X.npy\")\n",
        "Y_1=np.load(\"drive/My Drive/MS_data/train_Y.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiCZ5HSZEwkS",
        "colab_type": "text"
      },
      "source": [
        "## MODELLING and PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKpZV05AJMwa",
        "colab_type": "code",
        "outputId": "865189f2-2a80-42cf-bdc5-d5fc7764f079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Dec 13 18:56:04 2019\n",
        "\n",
        "@author: Krishna Chandra\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input ,BatchNormalization , Activation \n",
        "from keras.layers.convolutional import Conv3D, UpSampling3D\n",
        "from keras.layers.pooling import MaxPooling3D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "\n",
        "def Convolution(input_tensor,filters):\n",
        "    \n",
        "    x = Conv3D(filters=filters,kernel_size=(3, 3, 3),padding = 'same',strides=(1, 1, 1))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x) \n",
        "    return x\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "def model(input_shape):\n",
        "    \n",
        "    inputs = Input((input_shape))\n",
        "    \n",
        "    conv_1 = Convolution(inputs,32)                                                                                         # 8,256,256,32\n",
        "    \n",
        "    maxp_1 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_1)                            # 4,128,128,32    \n",
        "    conv_2 = Convolution(maxp_1,64)                                                                                         # 4,128,128,64\n",
        "    maxp_2 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_2)                            # 2,64,64,64\n",
        "    \n",
        "    conv_3 = Convolution(maxp_2,128)                                                                                        # 2,64,64,128\n",
        "    \n",
        "    maxp_3 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_3)                            # 1,32,32,128 \n",
        "    \n",
        "    \n",
        "    conv_4 = Convolution(maxp_3,256)                                                                                        # 1,32,32,256\n",
        "   \n",
        "    upsample_5 = UpSampling3D((2, 2, 2)) (conv_4)                                                                           # 2,64,64,256\n",
        "\n",
        "    upsample_5 = concatenate([upsample_5, conv_3])                                                                          # 2,64,64,256+128\n",
        "    \n",
        "    conv_5 = Convolution(upsample_5,128)                                                                                    # 2,64,64,128\n",
        "    upsample_6 = UpSampling3D((2, 2, 2)) (conv_5)                                                                           # 4,128,128,128                                                                                \n",
        "    \n",
        "    upsample_6 = concatenate([upsample_6, conv_2])                                                                          # 4,128,128,128+64\n",
        "    \n",
        "    conv_6 = Convolution(upsample_6,64)                                                                                     # 4,128,128,64        \n",
        "    upsample_7 = UpSampling3D((2, 2, 2)) (conv_6)                                                                           # 8,256,256,64   \n",
        "    \n",
        "    upsample_7 = concatenate([upsample_7, conv_1])                                                                          # 8,256,256,64+32  \n",
        "\n",
        "    conv_8 = Convolution(upsample_7,32)                                                                                     # 8,256,256,32\n",
        "    \n",
        "    \n",
        "    outputs = Conv3D(1, (1, 1, 1), activation='sigmoid') (conv_8)\n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[outputs]) \n",
        "    \n",
        "    return model\n",
        "     \n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifTECqUZJ1ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Computing Dice_Coefficient\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Computing Precision \n",
        "def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "# Computing Sensitivity      \n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "# Computing Specificity\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrPignYnE8WQ",
        "colab_type": "text"
      },
      "source": [
        "## TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-0wUUKoJ5d7",
        "colab_type": "code",
        "outputId": "227594fe-2cf3-4f13-ec1b-f5314e651637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv3D, UpSampling3D\n",
        "from tensorflow.keras.layers import MaxPooling3D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train , X_test, Y_train, Y_test = train_test_split(X_1, Y_1, test_size=0.15, random_state=32)\n",
        "\n",
        "\n",
        "# Loding the modified U-net \n",
        "model = model(input_shape = (8,256,256,5))\n",
        "model.summary()\n",
        "\n",
        "checkpointer = ModelCheckpoint('drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5', verbose=1)\n",
        "callback_list=[checkpointer]\n",
        "\n",
        "# Compiling the model\n",
        "k_adam=Adam(lr=0.001)\n",
        "model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n",
        "# Fitting the model over the data\n",
        "history = model.fit(X_train,Y_train,batch_size=8,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n",
        "\n",
        "# Saving the model\n",
        "model.save('drive/My Drive/MS_data/Modified_UNet_3D_Union.h5')\n",
        "history.history\n",
        "\n",
        "# Evaluating the model on the training and testing data \n",
        "model.evaluate(x=X_train, y=Y_train, batch_size=8 , verbose=1, sample_weight=None, steps=None)\n",
        "model.evaluate(x=X_test, y=Y_test, batch_size=8, verbose=1, sample_weight=None, steps=None)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 8, 256, 256, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 8, 256, 256,  4352        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 8, 256, 256,  128         conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 8, 256, 256,  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D)    (None, 4, 128, 128,  0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 4, 128, 128,  55360       max_pooling3d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 4, 128, 128,  256         conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 4, 128, 128,  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 2, 64, 64, 64 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 2, 64, 64, 12 221312      max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2, 64, 64, 12 512         conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 2, 64, 64, 12 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3D)  (None, 1, 32, 32, 12 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 1, 32, 32, 25 884992      max_pooling3d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1, 32, 32, 25 1024        conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1, 32, 32, 25 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d (UpSampling3D)    (None, 2, 64, 64, 25 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2, 64, 64, 38 0           up_sampling3d[0][0]              \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 2, 64, 64, 12 1327232     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 2, 64, 64, 12 512         conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 2, 64, 64, 12 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_1 (UpSampling3D)  (None, 4, 128, 128,  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 128, 128,  0           up_sampling3d_1[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 4, 128, 128,  331840      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 4, 128, 128,  256         conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 4, 128, 128,  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_2 (UpSampling3D)  (None, 8, 256, 256,  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 256, 256,  0           up_sampling3d_2[0][0]            \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 8, 256, 256,  82976       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 256, 256,  128         conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 256, 256,  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 8, 256, 256,  33          activation_6[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,910,913\n",
            "Trainable params: 2,909,505\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9836 - dice_coef: 0.7672 - precision: 0.9445 - sensitivity: 0.9853 - specificity: 0.9849\n",
            "Epoch 00001: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 36s 1s/step - loss: 0.1525 - accuracy: 0.9836 - dice_coef: 0.7672 - precision: 0.9445 - sensitivity: 0.9853 - specificity: 0.9849 - val_loss: 0.2409 - val_accuracy: 0.9775 - val_dice_coef: 0.7191 - val_precision: 0.9200 - val_sensitivity: 0.9932 - val_specificity: 0.9724\n",
            "Epoch 2/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9938 - dice_coef: 0.8439 - precision: 0.9752 - sensitivity: 0.9940 - specificity: 0.9941\n",
            "Epoch 00002: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 37s 1s/step - loss: 0.0806 - accuracy: 0.9938 - dice_coef: 0.8439 - precision: 0.9752 - sensitivity: 0.9940 - specificity: 0.9941 - val_loss: 0.4725 - val_accuracy: 0.8247 - val_dice_coef: 0.3814 - val_precision: 0.9978 - val_sensitivity: 0.2860 - val_specificity: 0.9998\n",
            "Epoch 3/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9956 - dice_coef: 0.8934 - precision: 0.9844 - sensitivity: 0.9945 - specificity: 0.9961\n",
            "Epoch 00003: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0530 - accuracy: 0.9956 - dice_coef: 0.8934 - precision: 0.9844 - sensitivity: 0.9945 - specificity: 0.9961 - val_loss: 0.1263 - val_accuracy: 0.9877 - val_dice_coef: 0.7731 - val_precision: 0.9997 - val_sensitivity: 0.9498 - val_specificity: 0.9999\n",
            "Epoch 4/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9968 - dice_coef: 0.9174 - precision: 0.9898 - sensitivity: 0.9950 - specificity: 0.9975\n",
            "Epoch 00004: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0392 - accuracy: 0.9968 - dice_coef: 0.9174 - precision: 0.9898 - sensitivity: 0.9950 - specificity: 0.9975 - val_loss: 0.0406 - val_accuracy: 0.9969 - val_dice_coef: 0.9274 - val_precision: 0.9960 - val_sensitivity: 0.9914 - val_specificity: 0.9987\n",
            "Epoch 5/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9979 - dice_coef: 0.9332 - precision: 0.9944 - sensitivity: 0.9955 - specificity: 0.9987\n",
            "Epoch 00005: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0295 - accuracy: 0.9979 - dice_coef: 0.9332 - precision: 0.9944 - sensitivity: 0.9955 - specificity: 0.9987 - val_loss: 0.0306 - val_accuracy: 0.9975 - val_dice_coef: 0.9447 - val_precision: 0.9973 - val_sensitivity: 0.9925 - val_specificity: 0.9992\n",
            "Epoch 6/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9983 - dice_coef: 0.9492 - precision: 0.9959 - sensitivity: 0.9960 - specificity: 0.9991\n",
            "Epoch 00006: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0227 - accuracy: 0.9983 - dice_coef: 0.9492 - precision: 0.9959 - sensitivity: 0.9960 - specificity: 0.9991 - val_loss: 0.0195 - val_accuracy: 0.9976 - val_dice_coef: 0.9655 - val_precision: 0.9949 - val_sensitivity: 0.9950 - val_specificity: 0.9984\n",
            "Epoch 7/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9988 - dice_coef: 0.9564 - precision: 0.9977 - sensitivity: 0.9967 - specificity: 0.9994\n",
            "Epoch 00007: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0186 - accuracy: 0.9988 - dice_coef: 0.9564 - precision: 0.9977 - sensitivity: 0.9967 - specificity: 0.9994 - val_loss: 0.0139 - val_accuracy: 0.9981 - val_dice_coef: 0.9752 - val_precision: 0.9962 - val_sensitivity: 0.9962 - val_specificity: 0.9988\n",
            "Epoch 8/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9990 - dice_coef: 0.9649 - precision: 0.9982 - sensitivity: 0.9972 - specificity: 0.9996\n",
            "Epoch 00008: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0145 - accuracy: 0.9990 - dice_coef: 0.9649 - precision: 0.9982 - sensitivity: 0.9972 - specificity: 0.9996 - val_loss: 0.0119 - val_accuracy: 0.9984 - val_dice_coef: 0.9786 - val_precision: 0.9956 - val_sensitivity: 0.9978 - val_specificity: 0.9986\n",
            "Epoch 9/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9992 - dice_coef: 0.9743 - precision: 0.9989 - sensitivity: 0.9977 - specificity: 0.9997\n",
            "Epoch 00009: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0113 - accuracy: 0.9992 - dice_coef: 0.9743 - precision: 0.9989 - sensitivity: 0.9977 - specificity: 0.9997 - val_loss: 0.0102 - val_accuracy: 0.9989 - val_dice_coef: 0.9813 - val_precision: 0.9975 - val_sensitivity: 0.9980 - val_specificity: 0.9992\n",
            "Epoch 10/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9993 - dice_coef: 0.9723 - precision: 0.9990 - sensitivity: 0.9977 - specificity: 0.9998\n",
            "Epoch 00010: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0106 - accuracy: 0.9993 - dice_coef: 0.9723 - precision: 0.9990 - sensitivity: 0.9977 - specificity: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9991 - val_dice_coef: 0.9862 - val_precision: 0.9977 - val_sensitivity: 0.9984 - val_specificity: 0.9993\n",
            "Epoch 11/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9995 - dice_coef: 0.9789 - precision: 0.9993 - sensitivity: 0.9982 - specificity: 0.9998\n",
            "Epoch 00011: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0085 - accuracy: 0.9995 - dice_coef: 0.9789 - precision: 0.9993 - sensitivity: 0.9982 - specificity: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9993 - val_dice_coef: 0.9861 - val_precision: 0.9990 - val_sensitivity: 0.9984 - val_specificity: 0.9997\n",
            "Epoch 12/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9995 - dice_coef: 0.9797 - precision: 0.9993 - sensitivity: 0.9984 - specificity: 0.9998\n",
            "Epoch 00012: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0077 - accuracy: 0.9995 - dice_coef: 0.9797 - precision: 0.9993 - sensitivity: 0.9984 - specificity: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9994 - val_dice_coef: 0.9881 - val_precision: 0.9987 - val_sensitivity: 0.9989 - val_specificity: 0.9996\n",
            "Epoch 13/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9995 - dice_coef: 0.9841 - precision: 0.9994 - sensitivity: 0.9985 - specificity: 0.9999\n",
            "Epoch 00013: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0062 - accuracy: 0.9995 - dice_coef: 0.9841 - precision: 0.9994 - sensitivity: 0.9985 - specificity: 0.9999 - val_loss: 0.0054 - val_accuracy: 0.9994 - val_dice_coef: 0.9900 - val_precision: 0.9985 - val_sensitivity: 0.9992 - val_specificity: 0.9995\n",
            "Epoch 14/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9996 - dice_coef: 0.9868 - precision: 0.9996 - sensitivity: 0.9987 - specificity: 0.9999\n",
            "Epoch 00014: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0054 - accuracy: 0.9996 - dice_coef: 0.9868 - precision: 0.9996 - sensitivity: 0.9987 - specificity: 0.9999 - val_loss: 0.0046 - val_accuracy: 0.9994 - val_dice_coef: 0.9917 - val_precision: 0.9983 - val_sensitivity: 0.9993 - val_specificity: 0.9994\n",
            "Epoch 15/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9996 - dice_coef: 0.9887 - precision: 0.9996 - sensitivity: 0.9987 - specificity: 0.9999\n",
            "Epoch 00015: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0049 - accuracy: 0.9996 - dice_coef: 0.9887 - precision: 0.9996 - sensitivity: 0.9987 - specificity: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9996 - val_dice_coef: 0.9938 - val_precision: 0.9993 - val_sensitivity: 0.9989 - val_specificity: 0.9998\n",
            "Epoch 16/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997 - dice_coef: 0.9900 - precision: 0.9995 - sensitivity: 0.9989 - specificity: 0.9999\n",
            "Epoch 00016: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0042 - accuracy: 0.9997 - dice_coef: 0.9900 - precision: 0.9995 - sensitivity: 0.9989 - specificity: 0.9999 - val_loss: 0.0034 - val_accuracy: 0.9997 - val_dice_coef: 0.9938 - val_precision: 0.9999 - val_sensitivity: 0.9988 - val_specificity: 1.0000\n",
            "Epoch 17/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9996 - dice_coef: 0.9864 - precision: 0.9996 - sensitivity: 0.9987 - specificity: 0.9999\n",
            "Epoch 00017: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0047 - accuracy: 0.9996 - dice_coef: 0.9864 - precision: 0.9996 - sensitivity: 0.9987 - specificity: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9995 - val_dice_coef: 0.9952 - val_precision: 0.9999 - val_sensitivity: 0.9981 - val_specificity: 1.0000\n",
            "Epoch 18/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9997 - dice_coef: 0.9921 - precision: 0.9997 - sensitivity: 0.9989 - specificity: 0.9999\n",
            "Epoch 00018: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0035 - accuracy: 0.9997 - dice_coef: 0.9921 - precision: 0.9997 - sensitivity: 0.9989 - specificity: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9996 - val_dice_coef: 0.9954 - val_precision: 0.9999 - val_sensitivity: 0.9986 - val_specificity: 1.0000\n",
            "Epoch 19/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9996 - dice_coef: 0.9903 - precision: 0.9993 - sensitivity: 0.9988 - specificity: 0.9998\n",
            "Epoch 00019: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0040 - accuracy: 0.9996 - dice_coef: 0.9903 - precision: 0.9993 - sensitivity: 0.9988 - specificity: 0.9998 - val_loss: 0.0031 - val_accuracy: 0.9991 - val_dice_coef: 0.9966 - val_precision: 1.0000 - val_sensitivity: 0.9965 - val_specificity: 1.0000\n",
            "Epoch 20/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998 - dice_coef: 0.9928 - precision: 0.9998 - sensitivity: 0.9992 - specificity: 1.0000\n",
            "Epoch 00020: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0030 - accuracy: 0.9998 - dice_coef: 0.9928 - precision: 0.9998 - sensitivity: 0.9992 - specificity: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995 - val_dice_coef: 0.9960 - val_precision: 1.0000 - val_sensitivity: 0.9978 - val_specificity: 1.0000\n",
            "Epoch 21/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998 - dice_coef: 0.9936 - precision: 0.9997 - sensitivity: 0.9992 - specificity: 0.9999\n",
            "Epoch 00021: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0026 - accuracy: 0.9998 - dice_coef: 0.9936 - precision: 0.9997 - sensitivity: 0.9992 - specificity: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9997 - val_dice_coef: 0.9961 - val_precision: 1.0000 - val_sensitivity: 0.9990 - val_specificity: 1.0000\n",
            "Epoch 22/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9998 - dice_coef: 0.9923 - precision: 0.9997 - sensitivity: 0.9991 - specificity: 0.9999\n",
            "Epoch 00022: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0028 - accuracy: 0.9998 - dice_coef: 0.9923 - precision: 0.9997 - sensitivity: 0.9991 - specificity: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9996 - val_dice_coef: 0.9968 - val_precision: 1.0000 - val_sensitivity: 0.9983 - val_specificity: 1.0000\n",
            "Epoch 23/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998 - dice_coef: 0.9944 - precision: 0.9998 - sensitivity: 0.9991 - specificity: 0.9999\n",
            "Epoch 00023: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0024 - accuracy: 0.9998 - dice_coef: 0.9944 - precision: 0.9998 - sensitivity: 0.9991 - specificity: 0.9999 - val_loss: 0.0019 - val_accuracy: 0.9997 - val_dice_coef: 0.9968 - val_precision: 0.9999 - val_sensitivity: 0.9990 - val_specificity: 1.0000\n",
            "Epoch 24/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9998 - dice_coef: 0.9952 - precision: 0.9998 - sensitivity: 0.9992 - specificity: 0.9999\n",
            "Epoch 00024: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0022 - accuracy: 0.9998 - dice_coef: 0.9952 - precision: 0.9998 - sensitivity: 0.9992 - specificity: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9998 - val_dice_coef: 0.9969 - val_precision: 0.9999 - val_sensitivity: 0.9992 - val_specificity: 1.0000\n",
            "Epoch 25/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9998 - dice_coef: 0.9948 - precision: 0.9997 - sensitivity: 0.9993 - specificity: 0.9999\n",
            "Epoch 00025: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0021 - accuracy: 0.9998 - dice_coef: 0.9948 - precision: 0.9997 - sensitivity: 0.9993 - specificity: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9998 - val_dice_coef: 0.9977 - val_precision: 1.0000 - val_sensitivity: 0.9991 - val_specificity: 1.0000\n",
            "Epoch 26/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9999 - dice_coef: 0.9960 - precision: 0.9999 - sensitivity: 0.9994 - specificity: 1.0000\n",
            "Epoch 00026: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0017 - accuracy: 0.9999 - dice_coef: 0.9960 - precision: 0.9999 - sensitivity: 0.9994 - specificity: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998 - val_dice_coef: 0.9976 - val_precision: 1.0000 - val_sensitivity: 0.9992 - val_specificity: 1.0000\n",
            "Epoch 27/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999 - dice_coef: 0.9961 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000\n",
            "Epoch 00027: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0016 - accuracy: 0.9999 - dice_coef: 0.9961 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998 - val_dice_coef: 0.9973 - val_precision: 0.9999 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n",
            "Epoch 28/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999 - dice_coef: 0.9960 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000\n",
            "Epoch 00028: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0016 - accuracy: 0.9999 - dice_coef: 0.9960 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998 - val_dice_coef: 0.9976 - val_precision: 1.0000 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n",
            "Epoch 29/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9999 - dice_coef: 0.9954 - precision: 0.9999 - sensitivity: 0.9994 - specificity: 1.0000\n",
            "Epoch 00029: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0017 - accuracy: 0.9999 - dice_coef: 0.9954 - precision: 0.9999 - sensitivity: 0.9994 - specificity: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9999 - val_dice_coef: 0.9974 - val_precision: 0.9999 - val_sensitivity: 0.9995 - val_specificity: 1.0000\n",
            "Epoch 30/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999 - dice_coef: 0.9969 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00030: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0013 - accuracy: 0.9999 - dice_coef: 0.9969 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999 - val_dice_coef: 0.9976 - val_precision: 0.9999 - val_sensitivity: 0.9996 - val_specificity: 1.0000\n",
            "Epoch 31/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - dice_coef: 0.9976 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00031: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0011 - accuracy: 0.9999 - dice_coef: 0.9976 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999 - val_dice_coef: 0.9977 - val_precision: 0.9999 - val_sensitivity: 0.9996 - val_specificity: 1.0000\n",
            "Epoch 32/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999 - dice_coef: 0.9965 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00032: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0014 - accuracy: 0.9999 - dice_coef: 0.9965 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999 - val_dice_coef: 0.9979 - val_precision: 1.0000 - val_sensitivity: 0.9996 - val_specificity: 1.0000\n",
            "Epoch 33/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - dice_coef: 0.9976 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00033: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0011 - accuracy: 0.9999 - dice_coef: 0.9976 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9999 - val_dice_coef: 0.9983 - val_precision: 1.0000 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n",
            "Epoch 34/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999 - dice_coef: 0.9978 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00034: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0010 - accuracy: 0.9999 - dice_coef: 0.9978 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9999 - val_dice_coef: 0.9983 - val_precision: 0.9999 - val_sensitivity: 0.9996 - val_specificity: 1.0000\n",
            "Epoch 35/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - dice_coef: 0.9972 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00035: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0011 - accuracy: 0.9999 - dice_coef: 0.9972 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 9.3290e-04 - val_accuracy: 0.9999 - val_dice_coef: 0.9986 - val_precision: 1.0000 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n",
            "Epoch 36/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 9.9921e-04 - accuracy: 0.9999 - dice_coef: 0.9976 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00036: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 9.9921e-04 - accuracy: 0.9999 - dice_coef: 0.9976 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998 - val_dice_coef: 0.9983 - val_precision: 1.0000 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n",
            "Epoch 37/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 8.4105e-04 - accuracy: 0.9999 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00037: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 8.4105e-04 - accuracy: 0.9999 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 9.1440e-04 - val_accuracy: 0.9999 - val_dice_coef: 0.9984 - val_precision: 0.9999 - val_sensitivity: 0.9997 - val_specificity: 1.0000\n",
            "Epoch 38/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 9.1220e-04 - accuracy: 0.9999 - dice_coef: 0.9977 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00038: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 9.1220e-04 - accuracy: 0.9999 - dice_coef: 0.9977 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_dice_coef: 0.9981 - val_precision: 0.9998 - val_sensitivity: 0.9998 - val_specificity: 0.9999\n",
            "Epoch 39/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 8.6921e-04 - accuracy: 0.9999 - dice_coef: 0.9980 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00039: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 8.6921e-04 - accuracy: 0.9999 - dice_coef: 0.9980 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 9.9173e-04 - val_accuracy: 0.9998 - val_dice_coef: 0.9987 - val_precision: 1.0000 - val_sensitivity: 0.9993 - val_specificity: 1.0000\n",
            "Epoch 40/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998 - dice_coef: 0.9976 - precision: 0.9998 - sensitivity: 0.9994 - specificity: 1.0000\n",
            "Epoch 00040: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0011 - accuracy: 0.9998 - dice_coef: 0.9976 - precision: 0.9998 - sensitivity: 0.9994 - specificity: 1.0000 - val_loss: 7.1100e-04 - val_accuracy: 0.9998 - val_dice_coef: 0.9992 - val_precision: 0.9999 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n",
            "Epoch 41/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 9.8409e-04 - accuracy: 0.9999 - dice_coef: 0.9976 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00041: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 9.8409e-04 - accuracy: 0.9999 - dice_coef: 0.9976 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 7.2228e-04 - val_accuracy: 0.9999 - val_dice_coef: 0.9988 - val_precision: 1.0000 - val_sensitivity: 0.9997 - val_specificity: 1.0000\n",
            "Epoch 42/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 9.1747e-04 - accuracy: 0.9999 - dice_coef: 0.9978 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00042: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 9.1747e-04 - accuracy: 0.9999 - dice_coef: 0.9978 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 8.2692e-04 - val_accuracy: 0.9999 - val_dice_coef: 0.9988 - val_precision: 1.0000 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n",
            "Epoch 43/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 7.7893e-04 - accuracy: 0.9999 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00043: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 7.7893e-04 - accuracy: 0.9999 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 7.9029e-04 - val_accuracy: 0.9999 - val_dice_coef: 0.9987 - val_precision: 1.0000 - val_sensitivity: 0.9996 - val_specificity: 1.0000\n",
            "Epoch 44/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 8.9806e-04 - accuracy: 0.9999 - dice_coef: 0.9975 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00044: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 8.9806e-04 - accuracy: 0.9999 - dice_coef: 0.9975 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 6.1231e-04 - val_accuracy: 0.9999 - val_dice_coef: 0.9992 - val_precision: 1.0000 - val_sensitivity: 0.9996 - val_specificity: 1.0000\n",
            "Epoch 45/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 7.7530e-04 - accuracy: 0.9999 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00045: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 7.7530e-04 - accuracy: 0.9999 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 6.9741e-04 - val_accuracy: 0.9999 - val_dice_coef: 0.9988 - val_precision: 1.0000 - val_sensitivity: 0.9997 - val_specificity: 1.0000\n",
            "Epoch 46/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998 - dice_coef: 0.9976 - precision: 0.9997 - sensitivity: 0.9994 - specificity: 0.9999\n",
            "Epoch 00046: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0013 - accuracy: 0.9998 - dice_coef: 0.9976 - precision: 0.9997 - sensitivity: 0.9994 - specificity: 0.9999 - val_loss: 0.0082 - val_accuracy: 0.9985 - val_dice_coef: 0.9920 - val_precision: 0.9942 - val_sensitivity: 0.9996 - val_specificity: 0.9981\n",
            "Epoch 47/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997 - dice_coef: 0.9972 - precision: 0.9996 - sensitivity: 0.9989 - specificity: 0.9999\n",
            "Epoch 00047: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0017 - accuracy: 0.9997 - dice_coef: 0.9972 - precision: 0.9996 - sensitivity: 0.9989 - specificity: 0.9999 - val_loss: 0.0015 - val_accuracy: 0.9996 - val_dice_coef: 0.9981 - val_precision: 0.9998 - val_sensitivity: 0.9986 - val_specificity: 0.9999\n",
            "Epoch 48/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998 - dice_coef: 0.9977 - precision: 0.9997 - sensitivity: 0.9994 - specificity: 0.9999\n",
            "Epoch 00048: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0012 - accuracy: 0.9998 - dice_coef: 0.9977 - precision: 0.9997 - sensitivity: 0.9994 - specificity: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9996 - val_dice_coef: 0.9988 - val_precision: 1.0000 - val_sensitivity: 0.9984 - val_specificity: 1.0000\n",
            "Epoch 49/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 9.0344e-04 - accuracy: 0.9998 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9994 - specificity: 1.0000\n",
            "Epoch 00049: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 9.0344e-04 - accuracy: 0.9998 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9994 - specificity: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9996 - val_dice_coef: 0.9981 - val_precision: 1.0000 - val_sensitivity: 0.9984 - val_specificity: 1.0000\n",
            "Epoch 50/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 9.1554e-04 - accuracy: 0.9999 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000\n",
            "Epoch 00050: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 9.1554e-04 - accuracy: 0.9999 - dice_coef: 0.9982 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000 - val_loss: 9.5423e-04 - val_accuracy: 0.9997 - val_dice_coef: 0.9991 - val_precision: 1.0000 - val_sensitivity: 0.9989 - val_specificity: 1.0000\n",
            "Epoch 51/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 6.2923e-04 - accuracy: 0.9999 - dice_coef: 0.9988 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00051: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 6.2923e-04 - accuracy: 0.9999 - dice_coef: 0.9988 - precision: 0.9999 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 7.5573e-04 - val_accuracy: 0.9998 - val_dice_coef: 0.9991 - val_precision: 1.0000 - val_sensitivity: 0.9992 - val_specificity: 1.0000\n",
            "Epoch 52/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998 - dice_coef: 0.9967 - precision: 0.9996 - sensitivity: 0.9992 - specificity: 0.9999\n",
            "Epoch 00052: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0014 - accuracy: 0.9998 - dice_coef: 0.9967 - precision: 0.9996 - sensitivity: 0.9992 - specificity: 0.9999 - val_loss: 0.0010 - val_accuracy: 0.9998 - val_dice_coef: 0.9984 - val_precision: 0.9999 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n",
            "Epoch 53/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998 - dice_coef: 0.9954 - precision: 0.9985 - sensitivity: 0.9994 - specificity: 0.9999\n",
            "Epoch 00053: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0014 - accuracy: 0.9998 - dice_coef: 0.9954 - precision: 0.9985 - sensitivity: 0.9994 - specificity: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9994 - val_dice_coef: 0.9982 - val_precision: 1.0000 - val_sensitivity: 0.9977 - val_specificity: 1.0000\n",
            "Epoch 54/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9996 - dice_coef: 0.9967 - precision: 0.9994 - sensitivity: 0.9985 - specificity: 0.9999\n",
            "Epoch 00054: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0018 - accuracy: 0.9996 - dice_coef: 0.9967 - precision: 0.9994 - sensitivity: 0.9985 - specificity: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9989 - val_dice_coef: 0.9970 - val_precision: 1.0000 - val_sensitivity: 0.9957 - val_specificity: 1.0000\n",
            "Epoch 55/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998 - dice_coef: 0.9982 - precision: 0.9998 - sensitivity: 0.9992 - specificity: 1.0000\n",
            "Epoch 00055: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0010 - accuracy: 0.9998 - dice_coef: 0.9982 - precision: 0.9998 - sensitivity: 0.9992 - specificity: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9994 - val_dice_coef: 0.9979 - val_precision: 1.0000 - val_sensitivity: 0.9974 - val_specificity: 1.0000\n",
            "Epoch 56/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 8.0690e-04 - accuracy: 0.9999 - dice_coef: 0.9984 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000\n",
            "Epoch 00056: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 8.0690e-04 - accuracy: 0.9999 - dice_coef: 0.9984 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995 - val_dice_coef: 0.9984 - val_precision: 1.0000 - val_sensitivity: 0.9978 - val_specificity: 1.0000\n",
            "Epoch 57/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 6.1289e-04 - accuracy: 0.9999 - dice_coef: 0.9988 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00057: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 6.1289e-04 - accuracy: 0.9999 - dice_coef: 0.9988 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995 - val_dice_coef: 0.9985 - val_precision: 1.0000 - val_sensitivity: 0.9979 - val_specificity: 1.0000\n",
            "Epoch 58/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 6.5045e-04 - accuracy: 0.9999 - dice_coef: 0.9986 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000\n",
            "Epoch 00058: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 6.5045e-04 - accuracy: 0.9999 - dice_coef: 0.9986 - precision: 0.9999 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 8.9112e-04 - val_accuracy: 0.9998 - val_dice_coef: 0.9989 - val_precision: 1.0000 - val_sensitivity: 0.9992 - val_specificity: 1.0000\n",
            "Epoch 59/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 5.4077e-04 - accuracy: 0.9999 - dice_coef: 0.9989 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00059: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 5.4077e-04 - accuracy: 0.9999 - dice_coef: 0.9989 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 8.1227e-04 - val_accuracy: 0.9998 - val_dice_coef: 0.9991 - val_precision: 1.0000 - val_sensitivity: 0.9991 - val_specificity: 1.0000\n",
            "Epoch 60/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 5.1538e-04 - accuracy: 0.9999 - dice_coef: 0.9989 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000\n",
            "Epoch 00060: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Union_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 5.1538e-04 - accuracy: 0.9999 - dice_coef: 0.9989 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 8.2708e-04 - val_accuracy: 0.9998 - val_dice_coef: 0.9990 - val_precision: 1.0000 - val_sensitivity: 0.9992 - val_specificity: 1.0000\n",
            "40/40 [==============================] - 12s 301ms/step - loss: 6.8391e-04 - accuracy: 0.9998 - dice_coef: 0.9990 - precision: 1.0000 - sensitivity: 0.9993 - specificity: 1.0000\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 5.6840e-04 - accuracy: 0.9999 - dice_coef: 0.9989 - precision: 1.0000 - sensitivity: 0.9995 - specificity: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0005684037460014224,\n",
              " 0.9998953938484192,\n",
              " 0.998874306678772,\n",
              " 0.9999828934669495,\n",
              " 0.9994743466377258,\n",
              " 0.9999971389770508]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gsK42XfPMrP",
        "colab_type": "text"
      },
      "source": [
        "## ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5onEDAFPAXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy vs Epoch\n",
        "def Accuracy_Graph(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    #plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "    \n",
        "# Dice Similarity Coefficient vs Epoch\n",
        "def Dice_coefficient_Graph(history):\n",
        "\n",
        "    plt.plot(history.history['dice_coef'])\n",
        "    plt.plot(history.history['val_dice_coef'])\n",
        "    #plt.title('Dice_Coefficient')\n",
        "    plt.ylabel('Dice_Coefficient')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "# Loss vs Epoch\n",
        "def Loss_Graph(history):\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    #plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "Accuracy_Graph(history)\n",
        "Dice_coefficient_Graph(history)\n",
        "Loss_Graph(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud1HIkCpPTHr",
        "colab_type": "text"
      },
      "source": [
        "# 3D INTERSECTION MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmvROeTuSH5e",
        "colab_type": "text"
      },
      "source": [
        "## Function Definitions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyQ-v7mlRhzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "    \n",
        "def modality(Path,index):\n",
        "    X = []\n",
        "    X_per_paitent = []\n",
        "    p=os.listdir(Path) \n",
        "    recs_in=[]\n",
        "    counter=0\n",
        "    counter_2=0\n",
        "    #recs_segmented=[]\n",
        "    for i in p[:14]:                                                                      # Loading all the folders in the given path\n",
        "        q = os.listdir(os.path.join(Path,i))     \n",
        "\n",
        "        x = nib.load(os.path.join(Path,i,q[index]))         \n",
        "        f = x.get_fdata()\n",
        "        f = np.asarray(f,'float32')\n",
        "        \n",
        "        ct=0\n",
        "        recs_in.append(f.shape[2])\n",
        "        #print(counter_2)\n",
        "        counter_2+=1\n",
        "        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n",
        "            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n",
        "            if(index not in [3,4,5,6,7,8,9] and np.sum(_slice) != 0 ): \n",
        "                if index==1:\n",
        "                  ct+=1 \n",
        "                  counter+=1 \n",
        "                 # print(counter)                                      # To check whether the slice is null or not\n",
        "              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n",
        "                  _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001)\n",
        "                else:\n",
        "                                              # To check whether the slice is null or not\n",
        "              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n",
        "                  _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n",
        "            elif(index in [3,4,5,6,7,8,9]):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n",
        "                _slice = np.array(_slice)\n",
        "                _slice[_slice > 0] = 1.0\n",
        "                _slice[_slice < 0] = 0.0\n",
        "            _slice = _slice.T\n",
        "            _slice = _slice[:,:,np.newaxis]\n",
        "            X.append(_slice)\n",
        "       \n",
        "   # X=np.array(X,dtype='float32')\n",
        "    return X,recs_in"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh8WvCM6Rvc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual,recs): \n",
        "     \n",
        "    X=[]\n",
        "    Y=[]\n",
        "    counter=0\n",
        "    counter_2=0\n",
        "    mult=0;\n",
        "    count=0\n",
        "    rec=[]\n",
        "    keep_count=[]\n",
        "    keep=[]\n",
        "    print(recs)\n",
        "    r=np.array(recs,dtype='float32')\n",
        "    print(np.sum(r))\n",
        "    print(len(X_Dp))\n",
        "\n",
        "    for i in range(len(X_Dp)):  \n",
        "        if counter==(recs[mult]):\n",
        "          print(counter)\n",
        "          mult+=1\n",
        "          rec.append(count)\n",
        "          counter=0\n",
        "          print(counter_2)\n",
        "          count=0\n",
        "        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n",
        "        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n",
        "            X.append(final_slice)\n",
        "            Y.append(Y_Manual[i])\n",
        "            \n",
        "            count+=1\n",
        "        counter+=1\n",
        "        counter_2+=1\n",
        "\n",
        "    \n",
        "    rec.append(count)\n",
        "#   Converting the list into array  \n",
        "    X=np.array(X,dtype='float32')\n",
        "    Y=np.array(Y,dtype='float32')\n",
        "    rec=np.array(rec,dtype='float32')\n",
        "    \n",
        "    return X,Y,rec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOrg6LD0R3Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_data(X,Y,rec):\n",
        "    np.save(\"drive/My Drive/MS_data/X_intersection_new.npy\",X)\n",
        "    np.save(\"drive/My Drive/MS_data/Y_intersection_new.npy\",Y)\n",
        "    np.save(\"drive/My Drive/MS_data/intersection_new_rec_after_removal.npy\",rec)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlnJR53dR4kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def intersection(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7):\n",
        "  Y=[]\n",
        "  sum2=[]\n",
        "  flag=0\n",
        "  #y=np.array()\n",
        "  print(\"A\")\n",
        "  for i in range (len(Y_1)):\n",
        "    #print(Y_1[i])\n",
        "    \n",
        "        f=np.concatenate((Y_1[i],Y_2[i],Y_3[i],Y_4[i],Y_5[i],Y_6[i],Y_7[i]),axis=-1)\n",
        "        sum=np.sum(f,axis=2)\n",
        "       # print(sum)\n",
        "        \n",
        "          #print(j)\n",
        "        sum_1=np.divide(sum,7)\n",
        "        sum_1=np.floor(sum_1)\n",
        "        sum2.append(sum_1)\n",
        "\n",
        "    #sum2=np.array(sum2,dtype='float32')\n",
        "    \n",
        "        \n",
        "  return sum2\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3hNDIxwSX4J",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Dataets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qM2zYTjSl9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import dataPrepare as process\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n",
        "#import Modified_UNet \n",
        "#import plots\n",
        "#import Metrics\n",
        "\n",
        "# Setting the path\n",
        "Path='drive/My Drive/Pre-processed'\n",
        "\n",
        "\n",
        "\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n",
        "X_Dp_t,rec      =   modality(Path,0)\n",
        "X_Flair_t,rec_1   =   modality(Path,1)\n",
        "X_Gado_t,rec    =   modality(Path,2)\n",
        "X_T1_t,rec      =   modality(Path,10)\n",
        "X_T2_t,rec      =   modality(Path,11)\n",
        "rec=np.array(rec_1,dtype='float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9P3h43oZteL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/intersection_new_rec_before_removal.npy\",rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB1AxsoSSrxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import dataPrepare as process\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n",
        "#import Modified_UNet \n",
        "#import plots\n",
        "#import Metrics\n",
        "\n",
        "# Setting the path\n",
        "Path='drive/My Drive/Pre-processed'\n",
        "Y_1,rec  =   modality(Path,3)\n",
        "Y_2,rec  =   modality(Path,4)\n",
        "Y_3,rec  =   modality(Path,5)\n",
        "Y_4,rec  =   modality(Path,6)\n",
        "Y_5,rec  =   modality(Path,7)\n",
        "Y_6,rec  =   modality(Path,8)\n",
        "Y_7,rec  =   modality(Path,9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt0mDku3Swi4",
        "colab_type": "code",
        "outputId": "9bdca397-b6f6-4e48-d0dd-d70527881bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_Manual=intersection(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skSYFgHCS2lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.save(\"drive/My Drive/MS_data/Y_manual_new.npy\",Y_Manual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPlpIR0OS6WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_manual=list(Y_Manual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqeU43y-S_d6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=np.load(\"drive/My Drive/MS_data/Y_manual_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7sIw6-4TB3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y,rec = remove_null_samples(X_Dp_t, X_Flair_t, X_Gado_t, X_T1_t, X_T2_t, Y_manual,rec_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9py5OvudTG3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "store_data(X,Y,rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0so_JBe9TJ0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "Y=np.load(\"drive/My Drive/MS_data/Y_intersection_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRilncgoTK4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WufXGmSlc7ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_1=Y_Manual[:1401]\n",
        "Y_2=Y_Manual[1401:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6YV9IFnTQhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p=[]\n",
        "y=[]\n",
        "z=[]\n",
        "a=[]\n",
        "n=1\n",
        "for i in Y_1:\n",
        "  print(n)\n",
        "  for j in i:\n",
        "    for k in j:\n",
        "      #print(k)\n",
        "      a.append(k)\n",
        "     # print(a)\n",
        "      z.append(a)\n",
        "      a=[]\n",
        "    #print(z)\n",
        "    y.append(z)\n",
        "    z=[]\n",
        "  p.append(y)\n",
        "  y=[]\n",
        "  n+=1\n",
        "\n",
        "\n",
        "#print(p)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJupG3TdTT2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=np.array(p)\n",
        "np.save(\"drive/My Drive/MS_data/temp_1_new.npy\",temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec9Yp1XWTWX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q=[]\n",
        "y=[]\n",
        "z=[]\n",
        "a=[]\n",
        "n=1401\n",
        "for i in Y_2:\n",
        "  print(n)\n",
        "  for j in i:\n",
        "    for k in j:\n",
        "      #print(k)\n",
        "      a.append(k)\n",
        "     # print(a)\n",
        "      z.append(a)\n",
        "      a=[]\n",
        "    #print(z)\n",
        "    y.append(z)\n",
        "    z=[]\n",
        "  q.append(y)\n",
        "  y=[]\n",
        "  n+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v8ptaWZTapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp2=np.array(q)\n",
        "np.save(\"drive/My Drive/MS_data/temp_2_new.npy\",temp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYzwa1JDTdlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=np.load(\"drive/My Drive/MS_data/temp_1_new.npy\")\n",
        "p=list(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgpmzyQoTjnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp2=np.load(\"drive/My Drive/MS_data/temp_2_new.npy\")\n",
        "q=list(temp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEJnr9t_TmWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j=1401\n",
        "for i in q:\n",
        "  print(j)\n",
        "  p.append(i)\n",
        "  j+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1eKtKdATnCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\",p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TnpbTn-TpvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "P=np.load(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vePsq8EDiTIu",
        "colab_type": "code",
        "outputId": "3be99bf2-89ad-454b-851a-6ac50623decf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(np.min(P))\n",
        "print(np.max(P))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbFqeXA6TtJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z37Yi2LVTwfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Lcqva2TzLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y=[]\n",
        "d_temp_1=[]\n",
        "d_temp_2=[]\n",
        "for i in range(len(Y[0])):\n",
        "  d_temp_1=[]\n",
        "  for j in range(len(Y[0][0])):\n",
        "    d_temp_2=[]\n",
        "    for k in range(len(Y[0][0][0])):\n",
        "      d_temp_2.append(0.)\n",
        "    d_temp_1.append(d_temp_2)\n",
        "  dummy_y.append(d_temp_1)\n",
        "Y_dummy=np.array(dummy_y, dtype='float32')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80q5ZB5YT3fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.load(\"drive/My Drive/MS_data/X_intersection_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5weQ3OjST6f8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVk7ufe5T9pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_x=[]\n",
        "d_temp_1=[]\n",
        "d_temp_2=[]\n",
        "for i in range(len(X[0])):\n",
        "  d_temp_1=[]\n",
        "  for j in range(len(X[0][0])):\n",
        "    d_temp_2=[]\n",
        "    for k in range(len(X[0][0][0])):\n",
        "      d_temp_2.append(0.)\n",
        "    d_temp_1.append(d_temp_2)\n",
        "  dummy_x.append(d_temp_1)\n",
        "X_dummy=np.array(dummy_x, dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CfsfWM0UAyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Y=np.load(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\")\n",
        "X=np.load(\"drive/My Drive/MS_data/X_union_new.npy\")\n",
        "#r=np.load(\"drive/My Drive/MS_data/union_new_rec_after_removal.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGZBRDBbUFGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)\n",
        "#Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuJOvI_8UJtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=Y.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia-ANHGjUM6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extra=[0,1,6,4,6,0,5,0,4,3,1,3,3,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpgh-iNJUQMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext=np.array(extra,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh9dTbVVUS52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s=np.sum(ext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEXrU1CjUWsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r=np.load(\"drive/My Drive/MS_data/intersection_new_rec_after_removal.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCgM4ov4UaTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec=list(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5NRMCT0Uc5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j=0\n",
        "index=0\n",
        "for i in extra:\n",
        "  k=0\n",
        "  \n",
        "  print(i)\n",
        "  index=index+rec[j]\n",
        "  j+=1\n",
        "  while(k<i):\n",
        "    index=index+k\n",
        "    print(index)\n",
        "    index=int(index)\n",
        "    Y.insert(index,Y_dummy)\n",
        "    X.insert(index,X_dummy)\n",
        "\n",
        "    k+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7hAwceEUgPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec=list(r)\n",
        "X=list(X)\n",
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgHAWN3rUkpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.array(X,dtype='float32')\n",
        "Y=np.array(Y,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7kYU-2hjAmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.min(P))\n",
        "print(np.max(P))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyIjH26WUlhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/Actual_X.npy\",X)\n",
        "np.save(\"drive/My Drive/MS_data/Actual_Y.npy\",Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH9_TIyEUoxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "Y=np.load(\"drive/My Drive/MS_data/Actual_X.npy\")\n",
        "X=np.load(\"drive/My Drive/MS_data/Actual_Y.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4QBEj-CUsHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_1=[]\n",
        "Y_1=[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFnnTdpuUvW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)\n",
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ0jyI6qUysG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_x_p=0\n",
        "length=8\n",
        "index_x=length\n",
        "index_y_p=0\n",
        "index_y=length\n",
        "x_temp=[]\n",
        "y_temp=[]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quPRZOghU1rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while index_x<=len(X) and index_y<=len(Y):\n",
        "  x_temp=X[index_x_p:index_x]\n",
        "  y_temp=Y[index_y_p:index_y]\n",
        "  x_temp_1=np.array(x_temp,dtype='float32')\n",
        "  y_temp_1=np.array(y_temp,dtype='float32')\n",
        "  X_1.append(x_temp_1)\n",
        "  Y_1.append(y_temp_1)\n",
        "  index_y_p=index_y_p+length\n",
        "  index_x_p=index_x_p+length\n",
        "  index_x=index_x+length\n",
        "  index_y=index_y+length\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaHtBBAXU47J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_1=np.array(X_1,dtype='float32')\n",
        "Y_1=np.array(Y_1,dtype='float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuHMmP-yh3k1",
        "colab_type": "code",
        "outputId": "c74fa908-e405-4f10-d3ea-5fd30aa00717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(np.min(Y_1))\n",
        "print(np.max(Y_1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mibkwfGfU7ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/train_X.npy\",X_1)\n",
        "np.save(\"drive/My Drive/MS_data/train_Y.npy\",Y_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF3LzwBBU-yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_1=np.load(\"drive/My Drive/MS_data/train_X.npy\")\n",
        "Y_1=np.load(\"drive/My Drive/MS_data/train_Y.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nda6LWATVBa1",
        "colab_type": "text"
      },
      "source": [
        "## Modelling And Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfQr86ZMVvwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input ,BatchNormalization , Activation \n",
        "from keras.layers.convolutional import Conv3D, UpSampling3D\n",
        "from keras.layers.pooling import MaxPooling3D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "\n",
        "def Convolution(input_tensor,filters):\n",
        "    \n",
        "    x = Conv3D(filters=filters,kernel_size=(3, 3, 3),padding = 'same',strides=(1, 1, 1))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x) \n",
        "    return x\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "def model(input_shape):\n",
        "    \n",
        "    inputs = Input((input_shape))\n",
        "    \n",
        "    conv_1 = Convolution(inputs,32)                                                                                         # 8,256,256,32\n",
        "    \n",
        "    maxp_1 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_1)                            # 4,128,128,32    \n",
        "    conv_2 = Convolution(maxp_1,64)                                                                                         # 4,128,128,64\n",
        "    maxp_2 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_2)                            # 2,64,64,64\n",
        "    \n",
        "    conv_3 = Convolution(maxp_2,128)                                                                                        # 2,64,64,128\n",
        "    \n",
        "    maxp_3 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_3)                            # 1,32,32,128 \n",
        "    \n",
        "    \n",
        "    conv_4 = Convolution(maxp_3,256)                                                                                        # 1,32,32,256\n",
        "   \n",
        "    upsample_5 = UpSampling3D((2, 2, 2)) (conv_4)                                                                           # 2,64,64,256\n",
        "\n",
        "    upsample_5 = concatenate([upsample_5, conv_3])                                                                          # 2,64,64,256+128\n",
        "    \n",
        "    conv_5 = Convolution(upsample_5,128)                                                                                    # 2,64,64,128\n",
        "    upsample_6 = UpSampling3D((2, 2, 2)) (conv_5)                                                                           # 4,128,128,128                                                                                \n",
        "    \n",
        "    upsample_6 = concatenate([upsample_6, conv_2])                                                                          # 4,128,128,128+64\n",
        "    \n",
        "    conv_6 = Convolution(upsample_6,64)                                                                                     # 4,128,128,64        \n",
        "    upsample_7 = UpSampling3D((2, 2, 2)) (conv_6)                                                                           # 8,256,256,64   \n",
        "    \n",
        "    upsample_7 = concatenate([upsample_7, conv_1])                                                                          # 8,256,256,64+32  \n",
        "\n",
        "    conv_8 = Convolution(upsample_7,32)                                                                                     # 8,256,256,32\n",
        "    \n",
        "    \n",
        "    outputs = Conv3D(1, (1, 1, 1), activation='sigmoid') (conv_8)\n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[outputs]) \n",
        "    \n",
        "    return model\n",
        "     \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1D3Hs4XWJ6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Computing Dice_Coefficient\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Computing Precision \n",
        "def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "# Computing Sensitivity      \n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "# Computing Specificity\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7seWhqZ4WM5x",
        "colab_type": "text"
      },
      "source": [
        "## TRAINING "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed9vNKxVWgNa",
        "colab_type": "code",
        "outputId": "bb623c0d-58ed-40ca-9a7b-c943b366e51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv3D, UpSampling3D\n",
        "from tensorflow.keras.layers import MaxPooling3D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train , X_test, Y_train, Y_test = train_test_split(X_1, Y_1, test_size=0.15, random_state=32)\n",
        "\n",
        "\n",
        "# Loding the modified U-net \n",
        "model = model(input_shape = (8,256,256,5))\n",
        "model.summary()\n",
        "\n",
        "checkpointer = ModelCheckpoint('drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5', verbose=1)\n",
        "callback_list=[checkpointer]\n",
        "\n",
        "# Compiling the model\n",
        "k_adam=Adam(lr=0.001)\n",
        "model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n",
        "# Fitting the model over the data\n",
        "history = model.fit(X_train,Y_train,batch_size=8,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n",
        "\n",
        "# Saving the model\n",
        "model.save('drive/My Drive/MS_data/Modified_UNet_3D_Intersection.h5')\n",
        "history.history\n",
        "\n",
        "# Evaluating the model on the training and testing data \n",
        "model.evaluate(x=X_train, y=Y_train, batch_size=8 , verbose=1, sample_weight=None, steps=None)\n",
        "model.evaluate(x=X_test, y=Y_test, batch_size=8, verbose=1, sample_weight=None, steps=None)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 8, 256, 256, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 8, 256, 256,  4352        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 8, 256, 256,  128         conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 256, 256,  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3D)  (None, 4, 128, 128,  0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 4, 128, 128,  55360       max_pooling3d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 4, 128, 128,  256         conv3d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 4, 128, 128,  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_4 (MaxPooling3D)  (None, 2, 64, 64, 64 0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_10 (Conv3D)              (None, 2, 64, 64, 12 221312      max_pooling3d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 2, 64, 64, 12 512         conv3d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 2, 64, 64, 12 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3D)  (None, 1, 32, 32, 12 0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_11 (Conv3D)              (None, 1, 32, 32, 25 884992      max_pooling3d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 1, 32, 32, 25 1024        conv3d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 1, 32, 32, 25 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_3 (UpSampling3D)  (None, 2, 64, 64, 25 0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 2, 64, 64, 38 0           up_sampling3d_3[0][0]            \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_12 (Conv3D)              (None, 2, 64, 64, 12 1327232     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 2, 64, 64, 12 512         conv3d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 2, 64, 64, 12 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_4 (UpSampling3D)  (None, 4, 128, 128,  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 4, 128, 128,  0           up_sampling3d_4[0][0]            \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_13 (Conv3D)              (None, 4, 128, 128,  331840      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 4, 128, 128,  256         conv3d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 4, 128, 128,  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_5 (UpSampling3D)  (None, 8, 256, 256,  0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8, 256, 256,  0           up_sampling3d_5[0][0]            \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_14 (Conv3D)              (None, 8, 256, 256,  82976       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 256, 256,  128         conv3d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 256, 256,  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_15 (Conv3D)              (None, 8, 256, 256,  33          activation_13[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,910,913\n",
            "Trainable params: 2,909,505\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9902 - dice_coef: 0.0124 - precision: 0.2382 - sensitivity: 0.7655 - specificity: 0.9908\n",
            "Epoch 00001: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.2289 - accuracy: 0.9902 - dice_coef: 0.0124 - precision: 0.2382 - sensitivity: 0.7655 - specificity: 0.9908 - val_loss: 0.1299 - val_accuracy: 0.9978 - val_dice_coef: 8.0577e-04 - val_precision: 0.2874 - val_sensitivity: 3.9198e-04 - val_specificity: 1.0000\n",
            "Epoch 2/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9980 - dice_coef: 0.0206 - precision: 0.4230 - sensitivity: 0.6472 - specificity: 0.9987\n",
            "Epoch 00002: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0994 - accuracy: 0.9980 - dice_coef: 0.0206 - precision: 0.4230 - sensitivity: 0.6472 - specificity: 0.9987 - val_loss: 0.1088 - val_accuracy: 0.9979 - val_dice_coef: 0.0073 - val_precision: 0.4963 - val_sensitivity: 0.0684 - val_specificity: 0.9999\n",
            "Epoch 3/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9986 - dice_coef: 0.0299 - precision: 0.5240 - sensitivity: 0.5758 - specificity: 0.9993\n",
            "Epoch 00003: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0642 - accuracy: 0.9986 - dice_coef: 0.0299 - precision: 0.5240 - sensitivity: 0.5758 - specificity: 0.9993 - val_loss: 0.0862 - val_accuracy: 0.9980 - val_dice_coef: 0.0140 - val_precision: 0.6755 - val_sensitivity: 0.1184 - val_specificity: 0.9999\n",
            "Epoch 4/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9986 - dice_coef: 0.0366 - precision: 0.5461 - sensitivity: 0.5678 - specificity: 0.9994\n",
            "Epoch 00004: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0458 - accuracy: 0.9986 - dice_coef: 0.0366 - precision: 0.5461 - sensitivity: 0.5678 - specificity: 0.9994 - val_loss: 0.0634 - val_accuracy: 0.9981 - val_dice_coef: 0.0157 - val_precision: 0.6881 - val_sensitivity: 0.1098 - val_specificity: 0.9999\n",
            "Epoch 5/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9988 - dice_coef: 0.0526 - precision: 0.5978 - sensitivity: 0.5334 - specificity: 0.9995\n",
            "Epoch 00005: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0342 - accuracy: 0.9988 - dice_coef: 0.0526 - precision: 0.5978 - sensitivity: 0.5334 - specificity: 0.9995 - val_loss: 0.0367 - val_accuracy: 0.9985 - val_dice_coef: 0.0516 - val_precision: 0.7601 - val_sensitivity: 0.4264 - val_specificity: 0.9997\n",
            "Epoch 6/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9990 - dice_coef: 0.0695 - precision: 0.6398 - sensitivity: 0.6349 - specificity: 0.9996\n",
            "Epoch 00006: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0259 - accuracy: 0.9990 - dice_coef: 0.0695 - precision: 0.6398 - sensitivity: 0.6349 - specificity: 0.9996 - val_loss: 0.0335 - val_accuracy: 0.9980 - val_dice_coef: 0.0249 - val_precision: 0.8535 - val_sensitivity: 0.0497 - val_specificity: 1.0000\n",
            "Epoch 7/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9989 - dice_coef: 0.0762 - precision: 0.6386 - sensitivity: 0.6107 - specificity: 0.9996\n",
            "Epoch 00007: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0208 - accuracy: 0.9989 - dice_coef: 0.0762 - precision: 0.6386 - sensitivity: 0.6107 - specificity: 0.9996 - val_loss: 0.0264 - val_accuracy: 0.9986 - val_dice_coef: 0.1150 - val_precision: 0.6150 - val_sensitivity: 0.8822 - val_specificity: 0.9989\n",
            "Epoch 8/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9989 - dice_coef: 0.0929 - precision: 0.6215 - sensitivity: 0.5891 - specificity: 0.9996\n",
            "Epoch 00008: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0175 - accuracy: 0.9989 - dice_coef: 0.0929 - precision: 0.6215 - sensitivity: 0.5891 - specificity: 0.9996 - val_loss: 0.0200 - val_accuracy: 0.9988 - val_dice_coef: 0.1363 - val_precision: 0.6685 - val_sensitivity: 0.8460 - val_specificity: 0.9992\n",
            "Epoch 9/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9990 - dice_coef: 0.1191 - precision: 0.6483 - sensitivity: 0.6541 - specificity: 0.9995\n",
            "Epoch 00009: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0147 - accuracy: 0.9990 - dice_coef: 0.1191 - precision: 0.6483 - sensitivity: 0.6541 - specificity: 0.9995 - val_loss: 0.0145 - val_accuracy: 0.9989 - val_dice_coef: 0.1669 - val_precision: 0.7191 - val_sensitivity: 0.8240 - val_specificity: 0.9993\n",
            "Epoch 10/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9990 - dice_coef: 0.1291 - precision: 0.6564 - sensitivity: 0.6780 - specificity: 0.9996\n",
            "Epoch 00010: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0122 - accuracy: 0.9990 - dice_coef: 0.1291 - precision: 0.6564 - sensitivity: 0.6780 - specificity: 0.9996 - val_loss: 0.0127 - val_accuracy: 0.9990 - val_dice_coef: 0.1687 - val_precision: 0.8121 - val_sensitivity: 0.7091 - val_specificity: 0.9996\n",
            "Epoch 11/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9991 - dice_coef: 0.1551 - precision: 0.6928 - sensitivity: 0.6698 - specificity: 0.9996\n",
            "Epoch 00011: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0105 - accuracy: 0.9991 - dice_coef: 0.1551 - precision: 0.6928 - sensitivity: 0.6698 - specificity: 0.9996 - val_loss: 0.0119 - val_accuracy: 0.9988 - val_dice_coef: 0.2169 - val_precision: 0.6719 - val_sensitivity: 0.8778 - val_specificity: 0.9991\n",
            "Epoch 12/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9990 - dice_coef: 0.1586 - precision: 0.6476 - sensitivity: 0.6268 - specificity: 0.9996\n",
            "Epoch 00012: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0095 - accuracy: 0.9990 - dice_coef: 0.1586 - precision: 0.6476 - sensitivity: 0.6268 - specificity: 0.9996 - val_loss: 0.0097 - val_accuracy: 0.9989 - val_dice_coef: 0.2452 - val_precision: 0.7179 - val_sensitivity: 0.8486 - val_specificity: 0.9993\n",
            "Epoch 13/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9990 - dice_coef: 0.1785 - precision: 0.7075 - sensitivity: 0.6206 - specificity: 0.9996\n",
            "Epoch 00013: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0086 - accuracy: 0.9990 - dice_coef: 0.1785 - precision: 0.7075 - sensitivity: 0.6206 - specificity: 0.9996 - val_loss: 0.0087 - val_accuracy: 0.9988 - val_dice_coef: 0.2673 - val_precision: 0.6909 - val_sensitivity: 0.8230 - val_specificity: 0.9992\n",
            "Epoch 14/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9990 - dice_coef: 0.1902 - precision: 0.6763 - sensitivity: 0.6196 - specificity: 0.9996\n",
            "Epoch 00014: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0077 - accuracy: 0.9990 - dice_coef: 0.1902 - precision: 0.6763 - sensitivity: 0.6196 - specificity: 0.9996 - val_loss: 0.0077 - val_accuracy: 0.9990 - val_dice_coef: 0.2582 - val_precision: 0.7929 - val_sensitivity: 0.6941 - val_specificity: 0.9996\n",
            "Epoch 15/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9991 - dice_coef: 0.2086 - precision: 0.7003 - sensitivity: 0.6678 - specificity: 0.9996\n",
            "Epoch 00015: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0069 - accuracy: 0.9991 - dice_coef: 0.2086 - precision: 0.7003 - sensitivity: 0.6678 - specificity: 0.9996 - val_loss: 0.0069 - val_accuracy: 0.9990 - val_dice_coef: 0.3081 - val_precision: 0.7467 - val_sensitivity: 0.8325 - val_specificity: 0.9994\n",
            "Epoch 16/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9991 - dice_coef: 0.2347 - precision: 0.7154 - sensitivity: 0.6294 - specificity: 0.9996\n",
            "Epoch 00016: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0063 - accuracy: 0.9991 - dice_coef: 0.2347 - precision: 0.7154 - sensitivity: 0.6294 - specificity: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9990 - val_dice_coef: 0.3190 - val_precision: 0.7655 - val_sensitivity: 0.7897 - val_specificity: 0.9995\n",
            "Epoch 17/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9991 - dice_coef: 0.2426 - precision: 0.6557 - sensitivity: 0.6492 - specificity: 0.9996\n",
            "Epoch 00017: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0058 - accuracy: 0.9991 - dice_coef: 0.2426 - precision: 0.6557 - sensitivity: 0.6492 - specificity: 0.9996 - val_loss: 0.0058 - val_accuracy: 0.9990 - val_dice_coef: 0.3394 - val_precision: 0.7794 - val_sensitivity: 0.7911 - val_specificity: 0.9995\n",
            "Epoch 18/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9990 - dice_coef: 0.2439 - precision: 0.7298 - sensitivity: 0.5975 - specificity: 0.9996\n",
            "Epoch 00018: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0056 - accuracy: 0.9990 - dice_coef: 0.2439 - precision: 0.7298 - sensitivity: 0.5975 - specificity: 0.9996 - val_loss: 0.0056 - val_accuracy: 0.9988 - val_dice_coef: 0.2889 - val_precision: 0.8671 - val_sensitivity: 0.5265 - val_specificity: 0.9998\n",
            "Epoch 19/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9991 - dice_coef: 0.2708 - precision: 0.6993 - sensitivity: 0.6984 - specificity: 0.9996\n",
            "Epoch 00019: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0051 - accuracy: 0.9991 - dice_coef: 0.2708 - precision: 0.6993 - sensitivity: 0.6984 - specificity: 0.9996 - val_loss: 0.0049 - val_accuracy: 0.9990 - val_dice_coef: 0.3724 - val_precision: 0.8009 - val_sensitivity: 0.7347 - val_specificity: 0.9996\n",
            "Epoch 20/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9991 - dice_coef: 0.2652 - precision: 0.6767 - sensitivity: 0.6508 - specificity: 0.9996\n",
            "Epoch 00020: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0049 - accuracy: 0.9991 - dice_coef: 0.2652 - precision: 0.6767 - sensitivity: 0.6508 - specificity: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9990 - val_dice_coef: 0.3748 - val_precision: 0.8039 - val_sensitivity: 0.7382 - val_specificity: 0.9996\n",
            "Epoch 21/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9990 - dice_coef: 0.2734 - precision: 0.7029 - sensitivity: 0.6521 - specificity: 0.9996\n",
            "Epoch 00021: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0047 - accuracy: 0.9990 - dice_coef: 0.2734 - precision: 0.7029 - sensitivity: 0.6521 - specificity: 0.9996 - val_loss: 0.0052 - val_accuracy: 0.9985 - val_dice_coef: 0.4451 - val_precision: 0.5812 - val_sensitivity: 0.9391 - val_specificity: 0.9986\n",
            "Epoch 22/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9991 - dice_coef: 0.2745 - precision: 0.6952 - sensitivity: 0.6450 - specificity: 0.9996\n",
            "Epoch 00022: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0046 - accuracy: 0.9991 - dice_coef: 0.2745 - precision: 0.6952 - sensitivity: 0.6450 - specificity: 0.9996 - val_loss: 0.0050 - val_accuracy: 0.9988 - val_dice_coef: 0.4195 - val_precision: 0.6747 - val_sensitivity: 0.8866 - val_specificity: 0.9991\n",
            "Epoch 23/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9991 - dice_coef: 0.3072 - precision: 0.6729 - sensitivity: 0.6578 - specificity: 0.9996\n",
            "Epoch 00023: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0043 - accuracy: 0.9991 - dice_coef: 0.3072 - precision: 0.6729 - sensitivity: 0.6578 - specificity: 0.9996 - val_loss: 0.0042 - val_accuracy: 0.9990 - val_dice_coef: 0.3975 - val_precision: 0.8179 - val_sensitivity: 0.7171 - val_specificity: 0.9996\n",
            "Epoch 24/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9992 - dice_coef: 0.3495 - precision: 0.7329 - sensitivity: 0.7086 - specificity: 0.9996\n",
            "Epoch 00024: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0039 - accuracy: 0.9992 - dice_coef: 0.3495 - precision: 0.7329 - sensitivity: 0.7086 - specificity: 0.9996 - val_loss: 0.0040 - val_accuracy: 0.9990 - val_dice_coef: 0.4483 - val_precision: 0.7790 - val_sensitivity: 0.7723 - val_specificity: 0.9995\n",
            "Epoch 25/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9991 - dice_coef: 0.3244 - precision: 0.7221 - sensitivity: 0.6707 - specificity: 0.9996\n",
            "Epoch 00025: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0039 - accuracy: 0.9991 - dice_coef: 0.3244 - precision: 0.7221 - sensitivity: 0.6707 - specificity: 0.9996 - val_loss: 0.0039 - val_accuracy: 0.9990 - val_dice_coef: 0.4301 - val_precision: 0.8269 - val_sensitivity: 0.7179 - val_specificity: 0.9997\n",
            "Epoch 26/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9992 - dice_coef: 0.3437 - precision: 0.6744 - sensitivity: 0.6979 - specificity: 0.9996\n",
            "Epoch 00026: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0037 - accuracy: 0.9992 - dice_coef: 0.3437 - precision: 0.6744 - sensitivity: 0.6979 - specificity: 0.9996 - val_loss: 0.0039 - val_accuracy: 0.9989 - val_dice_coef: 0.4908 - val_precision: 0.7183 - val_sensitivity: 0.8288 - val_specificity: 0.9993\n",
            "Epoch 27/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9991 - dice_coef: 0.3521 - precision: 0.7427 - sensitivity: 0.6582 - specificity: 0.9996\n",
            "Epoch 00027: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0036 - accuracy: 0.9991 - dice_coef: 0.3521 - precision: 0.7427 - sensitivity: 0.6582 - specificity: 0.9996 - val_loss: 0.0037 - val_accuracy: 0.9990 - val_dice_coef: 0.4902 - val_precision: 0.7298 - val_sensitivity: 0.8561 - val_specificity: 0.9993\n",
            "Epoch 28/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9992 - dice_coef: 0.3803 - precision: 0.7425 - sensitivity: 0.7323 - specificity: 0.9996\n",
            "Epoch 00028: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0036 - accuracy: 0.9992 - dice_coef: 0.3803 - precision: 0.7425 - sensitivity: 0.7323 - specificity: 0.9996 - val_loss: 0.0037 - val_accuracy: 0.9990 - val_dice_coef: 0.4378 - val_precision: 0.8666 - val_sensitivity: 0.6237 - val_specificity: 0.9998\n",
            "Epoch 29/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9991 - dice_coef: 0.3276 - precision: 0.7188 - sensitivity: 0.6318 - specificity: 0.9996\n",
            "Epoch 00029: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0036 - accuracy: 0.9991 - dice_coef: 0.3276 - precision: 0.7188 - sensitivity: 0.6318 - specificity: 0.9996 - val_loss: 0.0037 - val_accuracy: 0.9989 - val_dice_coef: 0.5204 - val_precision: 0.6746 - val_sensitivity: 0.9030 - val_specificity: 0.9991\n",
            "Epoch 30/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991 - dice_coef: 0.3842 - precision: 0.7392 - sensitivity: 0.6841 - specificity: 0.9996\n",
            "Epoch 00030: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0033 - accuracy: 0.9991 - dice_coef: 0.3842 - precision: 0.7392 - sensitivity: 0.6841 - specificity: 0.9996 - val_loss: 0.0036 - val_accuracy: 0.9989 - val_dice_coef: 0.5131 - val_precision: 0.7027 - val_sensitivity: 0.8804 - val_specificity: 0.9992\n",
            "Epoch 31/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9991 - dice_coef: 0.3608 - precision: 0.6938 - sensitivity: 0.6224 - specificity: 0.9996\n",
            "Epoch 00031: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0032 - accuracy: 0.9991 - dice_coef: 0.3608 - precision: 0.6938 - sensitivity: 0.6224 - specificity: 0.9996 - val_loss: 0.0036 - val_accuracy: 0.9989 - val_dice_coef: 0.4994 - val_precision: 0.7149 - val_sensitivity: 0.8435 - val_specificity: 0.9993\n",
            "Epoch 32/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992 - dice_coef: 0.3856 - precision: 0.6599 - sensitivity: 0.6694 - specificity: 0.9996\n",
            "Epoch 00032: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0031 - accuracy: 0.9992 - dice_coef: 0.3856 - precision: 0.6599 - sensitivity: 0.6694 - specificity: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9990 - val_dice_coef: 0.4448 - val_precision: 0.8815 - val_sensitivity: 0.6049 - val_specificity: 0.9998\n",
            "Epoch 33/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991 - dice_coef: 0.3650 - precision: 0.7181 - sensitivity: 0.6530 - specificity: 0.9996\n",
            "Epoch 00033: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0031 - accuracy: 0.9991 - dice_coef: 0.3650 - precision: 0.7181 - sensitivity: 0.6530 - specificity: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9989 - val_dice_coef: 0.5490 - val_precision: 0.6761 - val_sensitivity: 0.9027 - val_specificity: 0.9991\n",
            "Epoch 34/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991 - dice_coef: 0.4178 - precision: 0.7337 - sensitivity: 0.7112 - specificity: 0.9996\n",
            "Epoch 00034: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0030 - accuracy: 0.9991 - dice_coef: 0.4178 - precision: 0.7337 - sensitivity: 0.7112 - specificity: 0.9996 - val_loss: 0.0033 - val_accuracy: 0.9990 - val_dice_coef: 0.4934 - val_precision: 0.8623 - val_sensitivity: 0.6709 - val_specificity: 0.9997\n",
            "Epoch 35/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991 - dice_coef: 0.3492 - precision: 0.6730 - sensitivity: 0.6369 - specificity: 0.9996\n",
            "Epoch 00035: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 37s 1s/step - loss: 0.0030 - accuracy: 0.9991 - dice_coef: 0.3492 - precision: 0.6730 - sensitivity: 0.6369 - specificity: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9989 - val_dice_coef: 0.5500 - val_precision: 0.6950 - val_sensitivity: 0.8793 - val_specificity: 0.9991\n",
            "Epoch 36/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992 - dice_coef: 0.4105 - precision: 0.7352 - sensitivity: 0.6557 - specificity: 0.9996\n",
            "Epoch 00036: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0028 - accuracy: 0.9992 - dice_coef: 0.4105 - precision: 0.7352 - sensitivity: 0.6557 - specificity: 0.9996 - val_loss: 0.0033 - val_accuracy: 0.9989 - val_dice_coef: 0.4500 - val_precision: 0.8954 - val_sensitivity: 0.5110 - val_specificity: 0.9999\n",
            "Epoch 37/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991 - dice_coef: 0.3938 - precision: 0.7266 - sensitivity: 0.6515 - specificity: 0.9996\n",
            "Epoch 00037: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0028 - accuracy: 0.9991 - dice_coef: 0.3938 - precision: 0.7266 - sensitivity: 0.6515 - specificity: 0.9996 - val_loss: 0.0030 - val_accuracy: 0.9991 - val_dice_coef: 0.5389 - val_precision: 0.7930 - val_sensitivity: 0.7894 - val_specificity: 0.9996\n",
            "Epoch 38/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992 - dice_coef: 0.4095 - precision: 0.7497 - sensitivity: 0.6515 - specificity: 0.9997\n",
            "Epoch 00038: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0028 - accuracy: 0.9992 - dice_coef: 0.4095 - precision: 0.7497 - sensitivity: 0.6515 - specificity: 0.9997 - val_loss: 0.0032 - val_accuracy: 0.9990 - val_dice_coef: 0.4883 - val_precision: 0.8609 - val_sensitivity: 0.6416 - val_specificity: 0.9997\n",
            "Epoch 39/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992 - dice_coef: 0.3977 - precision: 0.7254 - sensitivity: 0.6699 - specificity: 0.9996\n",
            "Epoch 00039: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0027 - accuracy: 0.9992 - dice_coef: 0.3977 - precision: 0.7254 - sensitivity: 0.6699 - specificity: 0.9996 - val_loss: 0.0030 - val_accuracy: 0.9991 - val_dice_coef: 0.5431 - val_precision: 0.7998 - val_sensitivity: 0.7770 - val_specificity: 0.9996\n",
            "Epoch 40/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992 - dice_coef: 0.4291 - precision: 0.7435 - sensitivity: 0.6697 - specificity: 0.9996\n",
            "Epoch 00040: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0027 - accuracy: 0.9992 - dice_coef: 0.4291 - precision: 0.7435 - sensitivity: 0.6697 - specificity: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9991 - val_dice_coef: 0.5557 - val_precision: 0.8215 - val_sensitivity: 0.7510 - val_specificity: 0.9996\n",
            "Epoch 41/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992 - dice_coef: 0.3990 - precision: 0.7339 - sensitivity: 0.6444 - specificity: 0.9997\n",
            "Epoch 00041: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0026 - accuracy: 0.9992 - dice_coef: 0.3990 - precision: 0.7339 - sensitivity: 0.6444 - specificity: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9990 - val_dice_coef: 0.5747 - val_precision: 0.7508 - val_sensitivity: 0.8269 - val_specificity: 0.9994\n",
            "Epoch 42/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992 - dice_coef: 0.4451 - precision: 0.7390 - sensitivity: 0.6710 - specificity: 0.9996\n",
            "Epoch 00042: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0026 - accuracy: 0.9992 - dice_coef: 0.4451 - precision: 0.7390 - sensitivity: 0.6710 - specificity: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9990 - val_dice_coef: 0.5959 - val_precision: 0.7362 - val_sensitivity: 0.8313 - val_specificity: 0.9993\n",
            "Epoch 43/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992 - dice_coef: 0.4198 - precision: 0.6687 - sensitivity: 0.6750 - specificity: 0.9996\n",
            "Epoch 00043: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0027 - accuracy: 0.9992 - dice_coef: 0.4198 - precision: 0.6687 - sensitivity: 0.6750 - specificity: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9990 - val_dice_coef: 0.5987 - val_precision: 0.7347 - val_sensitivity: 0.8488 - val_specificity: 0.9993\n",
            "Epoch 44/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992 - dice_coef: 0.4496 - precision: 0.7095 - sensitivity: 0.6603 - specificity: 0.9996\n",
            "Epoch 00044: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0025 - accuracy: 0.9992 - dice_coef: 0.4496 - precision: 0.7095 - sensitivity: 0.6603 - specificity: 0.9996 - val_loss: 0.0027 - val_accuracy: 0.9991 - val_dice_coef: 0.5659 - val_precision: 0.8447 - val_sensitivity: 0.7045 - val_specificity: 0.9997\n",
            "Epoch 45/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4292 - precision: 0.7144 - sensitivity: 0.6425 - specificity: 0.9997\n",
            "Epoch 00045: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4292 - precision: 0.7144 - sensitivity: 0.6425 - specificity: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9990 - val_dice_coef: 0.6162 - val_precision: 0.7377 - val_sensitivity: 0.8543 - val_specificity: 0.9993\n",
            "Epoch 46/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4781 - precision: 0.7676 - sensitivity: 0.6629 - specificity: 0.9997\n",
            "Epoch 00046: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4781 - precision: 0.7676 - sensitivity: 0.6629 - specificity: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9991 - val_dice_coef: 0.6025 - val_precision: 0.7603 - val_sensitivity: 0.8360 - val_specificity: 0.9994\n",
            "Epoch 47/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991 - dice_coef: 0.4627 - precision: 0.7153 - sensitivity: 0.6749 - specificity: 0.9996\n",
            "Epoch 00047: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0024 - accuracy: 0.9991 - dice_coef: 0.4627 - precision: 0.7153 - sensitivity: 0.6749 - specificity: 0.9996 - val_loss: 0.0031 - val_accuracy: 0.9988 - val_dice_coef: 0.6113 - val_precision: 0.6596 - val_sensitivity: 0.9035 - val_specificity: 0.9990\n",
            "Epoch 48/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4770 - precision: 0.7124 - sensitivity: 0.7057 - specificity: 0.9996\n",
            "Epoch 00048: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4770 - precision: 0.7124 - sensitivity: 0.7057 - specificity: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9991 - val_dice_coef: 0.5835 - val_precision: 0.8458 - val_sensitivity: 0.6970 - val_specificity: 0.9997\n",
            "Epoch 49/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992 - dice_coef: 0.4991 - precision: 0.7732 - sensitivity: 0.6620 - specificity: 0.9997\n",
            "Epoch 00049: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0023 - accuracy: 0.9992 - dice_coef: 0.4991 - precision: 0.7732 - sensitivity: 0.6620 - specificity: 0.9997 - val_loss: 0.0026 - val_accuracy: 0.9991 - val_dice_coef: 0.6314 - val_precision: 0.7697 - val_sensitivity: 0.8223 - val_specificity: 0.9995\n",
            "Epoch 50/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4772 - precision: 0.7151 - sensitivity: 0.6763 - specificity: 0.9997\n",
            "Epoch 00050: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4772 - precision: 0.7151 - sensitivity: 0.6763 - specificity: 0.9997 - val_loss: 0.0026 - val_accuracy: 0.9991 - val_dice_coef: 0.5841 - val_precision: 0.8594 - val_sensitivity: 0.6786 - val_specificity: 0.9997\n",
            "Epoch 51/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991 - dice_coef: 0.4432 - precision: 0.6963 - sensitivity: 0.6129 - specificity: 0.9996\n",
            "Epoch 00051: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0025 - accuracy: 0.9991 - dice_coef: 0.4432 - precision: 0.6963 - sensitivity: 0.6129 - specificity: 0.9996 - val_loss: 0.0027 - val_accuracy: 0.9990 - val_dice_coef: 0.5881 - val_precision: 0.7985 - val_sensitivity: 0.7509 - val_specificity: 0.9996\n",
            "Epoch 52/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4812 - precision: 0.7479 - sensitivity: 0.6457 - specificity: 0.9996\n",
            "Epoch 00052: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0024 - accuracy: 0.9992 - dice_coef: 0.4812 - precision: 0.7479 - sensitivity: 0.6457 - specificity: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9991 - val_dice_coef: 0.5814 - val_precision: 0.8287 - val_sensitivity: 0.7399 - val_specificity: 0.9996\n",
            "Epoch 53/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - dice_coef: 0.4930 - precision: 0.7144 - sensitivity: 0.6916 - specificity: 0.9996\n",
            "Epoch 00053: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0022 - accuracy: 0.9992 - dice_coef: 0.4930 - precision: 0.7144 - sensitivity: 0.6916 - specificity: 0.9996 - val_loss: 0.0031 - val_accuracy: 0.9989 - val_dice_coef: 0.5884 - val_precision: 0.7007 - val_sensitivity: 0.8633 - val_specificity: 0.9992\n",
            "Epoch 54/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9991 - dice_coef: 0.4376 - precision: 0.6995 - sensitivity: 0.6388 - specificity: 0.9996\n",
            "Epoch 00054: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0023 - accuracy: 0.9991 - dice_coef: 0.4376 - precision: 0.6995 - sensitivity: 0.6388 - specificity: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9990 - val_dice_coef: 0.6462 - val_precision: 0.7271 - val_sensitivity: 0.8674 - val_specificity: 0.9993\n",
            "Epoch 55/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992 - dice_coef: 0.4921 - precision: 0.7481 - sensitivity: 0.6583 - specificity: 0.9997\n",
            "Epoch 00055: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0021 - accuracy: 0.9992 - dice_coef: 0.4921 - precision: 0.7481 - sensitivity: 0.6583 - specificity: 0.9997 - val_loss: 0.0026 - val_accuracy: 0.9991 - val_dice_coef: 0.5872 - val_precision: 0.8097 - val_sensitivity: 0.7685 - val_specificity: 0.9996\n",
            "Epoch 56/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993 - dice_coef: 0.4847 - precision: 0.7156 - sensitivity: 0.6487 - specificity: 0.9997\n",
            "Epoch 00056: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0021 - accuracy: 0.9993 - dice_coef: 0.4847 - precision: 0.7156 - sensitivity: 0.6487 - specificity: 0.9997 - val_loss: 0.0030 - val_accuracy: 0.9989 - val_dice_coef: 0.6188 - val_precision: 0.6880 - val_sensitivity: 0.8921 - val_specificity: 0.9991\n",
            "Epoch 57/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - dice_coef: 0.4846 - precision: 0.7093 - sensitivity: 0.6339 - specificity: 0.9997\n",
            "Epoch 00057: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0022 - accuracy: 0.9992 - dice_coef: 0.4846 - precision: 0.7093 - sensitivity: 0.6339 - specificity: 0.9997 - val_loss: 0.0026 - val_accuracy: 0.9991 - val_dice_coef: 0.5919 - val_precision: 0.8071 - val_sensitivity: 0.7645 - val_specificity: 0.9996\n",
            "Epoch 58/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993 - dice_coef: 0.4848 - precision: 0.7151 - sensitivity: 0.6519 - specificity: 0.9997\n",
            "Epoch 00058: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0020 - accuracy: 0.9993 - dice_coef: 0.4848 - precision: 0.7151 - sensitivity: 0.6519 - specificity: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9991 - val_dice_coef: 0.6372 - val_precision: 0.7535 - val_sensitivity: 0.8429 - val_specificity: 0.9994\n",
            "Epoch 59/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993 - dice_coef: 0.5512 - precision: 0.7680 - sensitivity: 0.7028 - specificity: 0.9997\n",
            "Epoch 00059: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0020 - accuracy: 0.9993 - dice_coef: 0.5512 - precision: 0.7680 - sensitivity: 0.7028 - specificity: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9990 - val_dice_coef: 0.5537 - val_precision: 0.8441 - val_sensitivity: 0.6283 - val_specificity: 0.9997\n",
            "Epoch 60/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992 - dice_coef: 0.4996 - precision: 0.7313 - sensitivity: 0.6888 - specificity: 0.9996\n",
            "Epoch 00060: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Intersection_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0021 - accuracy: 0.9992 - dice_coef: 0.4996 - precision: 0.7313 - sensitivity: 0.6888 - specificity: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9988 - val_dice_coef: 0.4898 - val_precision: 0.9147 - val_sensitivity: 0.4912 - val_specificity: 0.9999\n",
            "40/40 [==============================] - 12s 301ms/step - loss: 0.0024 - accuracy: 0.9990 - dice_coef: 0.4181 - precision: 0.9033 - sensitivity: 0.3852 - specificity: 0.9999\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0038 - accuracy: 0.9984 - dice_coef: 0.5160 - precision: 0.8746 - sensitivity: 0.5039 - specificity: 0.9998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0037747330497950315,\n",
              " 0.998433530330658,\n",
              " 0.5160220265388489,\n",
              " 0.8746342062950134,\n",
              " 0.5038745403289795,\n",
              " 0.9998205900192261]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p_ovHSDWmnM",
        "colab_type": "text"
      },
      "source": [
        "##  Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh8QcH0fWuF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy vs Epoch\n",
        "def Accuracy_Graph(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    #plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "    \n",
        "# Dice Similarity Coefficient vs Epoch\n",
        "def Dice_coefficient_Graph(history):\n",
        "\n",
        "    plt.plot(history.history['dice_coef'])\n",
        "    plt.plot(history.history['val_dice_coef'])\n",
        "    #plt.title('Dice_Coefficient')\n",
        "    plt.ylabel('Dice_Coefficient')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "# Loss vs Epoch\n",
        "def Loss_Graph(history):\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    #plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "Accuracy_Graph(history)\n",
        "Dice_coefficient_Graph(history)\n",
        "Loss_Graph(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Fofhc7AO00",
        "colab_type": "text"
      },
      "source": [
        "# 3D MAJOR MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTJnwfZMAvNI",
        "colab_type": "text"
      },
      "source": [
        "## Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN-vJDMyAx3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "    \n",
        "def modality(Path,index):\n",
        "    X = []\n",
        "    X_per_paitent = []\n",
        "    p=os.listdir(Path) \n",
        "    recs_in=[]\n",
        "    counter=0\n",
        "    counter_2=0\n",
        "    #recs_segmented=[]\n",
        "    for i in p[:14]:                                                                      # Loading all the folders in the given path\n",
        "        q = os.listdir(os.path.join(Path,i))     \n",
        "\n",
        "        x = nib.load(os.path.join(Path,i,q[index]))         \n",
        "        f = x.get_fdata()\n",
        "        f = np.asarray(f,'float32')\n",
        "        \n",
        "        ct=0\n",
        "        recs_in.append(f.shape[2])\n",
        "        #print(counter_2)\n",
        "        counter_2+=1\n",
        "        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n",
        "            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n",
        "            if(index not in [3,4,5,6,7,8,9] and np.sum(_slice) != 0 ): \n",
        "                if index==1:\n",
        "                  ct+=1 \n",
        "                  counter+=1 \n",
        "                 # print(counter)                                      # To check whether the slice is null or not\n",
        "              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n",
        "                  _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001)\n",
        "                else:\n",
        "                                              # To check whether the slice is null or not\n",
        "              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n",
        "                  _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n",
        "            elif(index in [3,4,5,6,7,8,9]):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n",
        "                _slice = np.array(_slice)\n",
        "                _slice[_slice > 0] = 1.0\n",
        "                _slice[_slice < 0] = 0.0\n",
        "            _slice = _slice.T\n",
        "            _slice = _slice[:,:,np.newaxis]\n",
        "            X.append(_slice)\n",
        "       \n",
        "   # X=np.array(X,dtype='float32')\n",
        "    return X,recs_in"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFTtY0bGBQNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual,recs): \n",
        "     \n",
        "    X=[]\n",
        "    Y=[]\n",
        "    counter=0\n",
        "    counter_2=0\n",
        "    mult=0;\n",
        "    count=0\n",
        "    rec=[]\n",
        "    keep_count=[]\n",
        "    keep=[]\n",
        "    print(recs)\n",
        "    r=np.array(recs,dtype='float32')\n",
        "    print(np.sum(r))\n",
        "    print(len(X_Dp))\n",
        "\n",
        "    for i in range(len(X_Dp)):  \n",
        "        if counter==(recs[mult]):\n",
        "          print(counter)\n",
        "          mult+=1\n",
        "          rec.append(count)\n",
        "          counter=0\n",
        "          print(counter_2)\n",
        "          count=0\n",
        "        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n",
        "        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n",
        "            X.append(final_slice)\n",
        "            Y.append(Y_Manual[i])\n",
        "            \n",
        "            count+=1\n",
        "        counter+=1\n",
        "        counter_2+=1\n",
        "\n",
        "    \n",
        "    rec.append(count)\n",
        "#   Converting the list into array  \n",
        "    X=np.array(X,dtype='float32')\n",
        "    Y=np.array(Y,dtype='float32')\n",
        "    rec=np.array(rec,dtype='float32')\n",
        "    \n",
        "    return X,Y,rec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkE8cf9vBVqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_data(X,Y,rec):\n",
        "    np.save(\"drive/My Drive/MS_data/X_major_new.npy\",X)\n",
        "    np.save(\"drive/My Drive/MS_data/Y_major_new.npy\",Y)\n",
        "    np.save(\"drive/My Drive/MS_data/major_new_rec_after_removal.npy\",rec)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajc6PWiKBnPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def Major(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7):\n",
        "  Y=[]\n",
        "  sum2=[]\n",
        "  flag=0\n",
        "  #y=np.array()\n",
        "  print(\"A\")\n",
        "  for i in range (len(Y_1)):\n",
        "    #print(Y_1[i])\n",
        "    \n",
        "        f=np.concatenate((Y_1[i],Y_2[i],Y_3[i],Y_4[i],Y_5[i],Y_6[i],Y_7[i]),axis=-1)\n",
        "        sum=np.sum(f,axis=2)\n",
        "       # print(sum)\n",
        "        \n",
        "          #print(j)\n",
        "        sum_1=np.divide(sum,4)\n",
        "        sum_1=np.floor(sum_1)\n",
        "        sum2.append(sum_1)\n",
        "\n",
        "    #sum2=np.array(sum2,dtype='float32')\n",
        "    \n",
        "        \n",
        "  return sum2\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FBkhxuyCYBm",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO2N7LRMCiET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import dataPrepare as process\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n",
        "#import Modified_UNet \n",
        "#import plots\n",
        "#import Metrics\n",
        "\n",
        "# Setting the path\n",
        "Path='drive/My Drive/Pre-processed'\n",
        "\n",
        "\n",
        "\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n",
        "X_Dp_t,rec      =   modality(Path,0)\n",
        "X_Flair_t,rec_1   =   modality(Path,1)\n",
        "X_Gado_t,rec    =   modality(Path,2)\n",
        "X_T1_t,rec      =   modality(Path,10)\n",
        "X_T2_t,rec      =   modality(Path,11)\n",
        "rec=np.array(rec_1,dtype='float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUH978HhHoqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/major_new_rec_before_removal.npy\",rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOu8G84CHuK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import dataPrepare as process\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n",
        "#import Modified_UNet \n",
        "#import plots\n",
        "#import Metrics\n",
        "\n",
        "# Setting the path\n",
        "Path='drive/My Drive/Pre-processed'\n",
        "Y_1,rec  =   modality(Path,3)\n",
        "Y_2,rec  =   modality(Path,4)\n",
        "Y_3,rec  =   modality(Path,5)\n",
        "Y_4,rec  =   modality(Path,6)\n",
        "Y_5,rec  =   modality(Path,7)\n",
        "Y_6,rec  =   modality(Path,8)\n",
        "Y_7,rec  =   modality(Path,9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d47dSXGQJFZM",
        "colab_type": "code",
        "outputId": "f633e025-355e-40cf-97ec-cb2a06797440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_Manual=Major(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItzVDJX0JITB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.save(\"drive/My Drive/MS_data/Y_manual_new.npy\",Y_Manual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tocHY1jJLeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_manual=list(Y_Manual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-GpCGg0PEH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=np.load(\"drive/My Drive/MS_data/Y_manual_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUYHOUX-PHqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y,rec = remove_null_samples(X_Dp_t, X_Flair_t, X_Gado_t, X_T1_t, X_T2_t, Y_manual,rec_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBj3PENvPObL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "store_data(X,Y,rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfJ9EynNPQ1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "Y=np.load(\"drive/My Drive/MS_data/Y_major_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cwkVly4PV1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esdhrCWrPbh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_1=Y_Manual[:1401]\n",
        "Y_2=Y_Manual[1401:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp326ta3PiKG",
        "colab_type": "code",
        "outputId": "ffc5ec16-d99c-46ee-81e9-4bd7d67e57d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "p=[]\n",
        "y=[]\n",
        "z=[]\n",
        "a=[]\n",
        "n=1\n",
        "for i in Y_1:\n",
        "  print(n)\n",
        "  for j in i:\n",
        "    for k in j:\n",
        "      #print(k)\n",
        "      a.append(k)\n",
        "     # print(a)\n",
        "      z.append(a)\n",
        "      a=[]\n",
        "    #print(z)\n",
        "    y.append(z)\n",
        "    z=[]\n",
        "  p.append(y)\n",
        "  y=[]\n",
        "  n+=1\n",
        "\n",
        "\n",
        "#print(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n",
            "1293\n",
            "1294\n",
            "1295\n",
            "1296\n",
            "1297\n",
            "1298\n",
            "1299\n",
            "1300\n",
            "1301\n",
            "1302\n",
            "1303\n",
            "1304\n",
            "1305\n",
            "1306\n",
            "1307\n",
            "1308\n",
            "1309\n",
            "1310\n",
            "1311\n",
            "1312\n",
            "1313\n",
            "1314\n",
            "1315\n",
            "1316\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1320\n",
            "1321\n",
            "1322\n",
            "1323\n",
            "1324\n",
            "1325\n",
            "1326\n",
            "1327\n",
            "1328\n",
            "1329\n",
            "1330\n",
            "1331\n",
            "1332\n",
            "1333\n",
            "1334\n",
            "1335\n",
            "1336\n",
            "1337\n",
            "1338\n",
            "1339\n",
            "1340\n",
            "1341\n",
            "1342\n",
            "1343\n",
            "1344\n",
            "1345\n",
            "1346\n",
            "1347\n",
            "1348\n",
            "1349\n",
            "1350\n",
            "1351\n",
            "1352\n",
            "1353\n",
            "1354\n",
            "1355\n",
            "1356\n",
            "1357\n",
            "1358\n",
            "1359\n",
            "1360\n",
            "1361\n",
            "1362\n",
            "1363\n",
            "1364\n",
            "1365\n",
            "1366\n",
            "1367\n",
            "1368\n",
            "1369\n",
            "1370\n",
            "1371\n",
            "1372\n",
            "1373\n",
            "1374\n",
            "1375\n",
            "1376\n",
            "1377\n",
            "1378\n",
            "1379\n",
            "1380\n",
            "1381\n",
            "1382\n",
            "1383\n",
            "1384\n",
            "1385\n",
            "1386\n",
            "1387\n",
            "1388\n",
            "1389\n",
            "1390\n",
            "1391\n",
            "1392\n",
            "1393\n",
            "1394\n",
            "1395\n",
            "1396\n",
            "1397\n",
            "1398\n",
            "1399\n",
            "1400\n",
            "1401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4neeD9sMPnhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=np.array(p)\n",
        "np.save(\"drive/My Drive/MS_data/temp_1_new.npy\",temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdAtluQ2PsSB",
        "colab_type": "code",
        "outputId": "2a7f784d-d1d2-4cd0-9544-a8b70b7ff383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "q=[]\n",
        "y=[]\n",
        "z=[]\n",
        "a=[]\n",
        "n=1401\n",
        "for i in Y_2:\n",
        "  print(n)\n",
        "  for j in i:\n",
        "    for k in j:\n",
        "      #print(k)\n",
        "      a.append(k)\n",
        "     # print(a)\n",
        "      z.append(a)\n",
        "      a=[]\n",
        "    #print(z)\n",
        "    y.append(z)\n",
        "    z=[]\n",
        "  q.append(y)\n",
        "  y=[]\n",
        "  n+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n",
            "1441\n",
            "1442\n",
            "1443\n",
            "1444\n",
            "1445\n",
            "1446\n",
            "1447\n",
            "1448\n",
            "1449\n",
            "1450\n",
            "1451\n",
            "1452\n",
            "1453\n",
            "1454\n",
            "1455\n",
            "1456\n",
            "1457\n",
            "1458\n",
            "1459\n",
            "1460\n",
            "1461\n",
            "1462\n",
            "1463\n",
            "1464\n",
            "1465\n",
            "1466\n",
            "1467\n",
            "1468\n",
            "1469\n",
            "1470\n",
            "1471\n",
            "1472\n",
            "1473\n",
            "1474\n",
            "1475\n",
            "1476\n",
            "1477\n",
            "1478\n",
            "1479\n",
            "1480\n",
            "1481\n",
            "1482\n",
            "1483\n",
            "1484\n",
            "1485\n",
            "1486\n",
            "1487\n",
            "1488\n",
            "1489\n",
            "1490\n",
            "1491\n",
            "1492\n",
            "1493\n",
            "1494\n",
            "1495\n",
            "1496\n",
            "1497\n",
            "1498\n",
            "1499\n",
            "1500\n",
            "1501\n",
            "1502\n",
            "1503\n",
            "1504\n",
            "1505\n",
            "1506\n",
            "1507\n",
            "1508\n",
            "1509\n",
            "1510\n",
            "1511\n",
            "1512\n",
            "1513\n",
            "1514\n",
            "1515\n",
            "1516\n",
            "1517\n",
            "1518\n",
            "1519\n",
            "1520\n",
            "1521\n",
            "1522\n",
            "1523\n",
            "1524\n",
            "1525\n",
            "1526\n",
            "1527\n",
            "1528\n",
            "1529\n",
            "1530\n",
            "1531\n",
            "1532\n",
            "1533\n",
            "1534\n",
            "1535\n",
            "1536\n",
            "1537\n",
            "1538\n",
            "1539\n",
            "1540\n",
            "1541\n",
            "1542\n",
            "1543\n",
            "1544\n",
            "1545\n",
            "1546\n",
            "1547\n",
            "1548\n",
            "1549\n",
            "1550\n",
            "1551\n",
            "1552\n",
            "1553\n",
            "1554\n",
            "1555\n",
            "1556\n",
            "1557\n",
            "1558\n",
            "1559\n",
            "1560\n",
            "1561\n",
            "1562\n",
            "1563\n",
            "1564\n",
            "1565\n",
            "1566\n",
            "1567\n",
            "1568\n",
            "1569\n",
            "1570\n",
            "1571\n",
            "1572\n",
            "1573\n",
            "1574\n",
            "1575\n",
            "1576\n",
            "1577\n",
            "1578\n",
            "1579\n",
            "1580\n",
            "1581\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1585\n",
            "1586\n",
            "1587\n",
            "1588\n",
            "1589\n",
            "1590\n",
            "1591\n",
            "1592\n",
            "1593\n",
            "1594\n",
            "1595\n",
            "1596\n",
            "1597\n",
            "1598\n",
            "1599\n",
            "1600\n",
            "1601\n",
            "1602\n",
            "1603\n",
            "1604\n",
            "1605\n",
            "1606\n",
            "1607\n",
            "1608\n",
            "1609\n",
            "1610\n",
            "1611\n",
            "1612\n",
            "1613\n",
            "1614\n",
            "1615\n",
            "1616\n",
            "1617\n",
            "1618\n",
            "1619\n",
            "1620\n",
            "1621\n",
            "1622\n",
            "1623\n",
            "1624\n",
            "1625\n",
            "1626\n",
            "1627\n",
            "1628\n",
            "1629\n",
            "1630\n",
            "1631\n",
            "1632\n",
            "1633\n",
            "1634\n",
            "1635\n",
            "1636\n",
            "1637\n",
            "1638\n",
            "1639\n",
            "1640\n",
            "1641\n",
            "1642\n",
            "1643\n",
            "1644\n",
            "1645\n",
            "1646\n",
            "1647\n",
            "1648\n",
            "1649\n",
            "1650\n",
            "1651\n",
            "1652\n",
            "1653\n",
            "1654\n",
            "1655\n",
            "1656\n",
            "1657\n",
            "1658\n",
            "1659\n",
            "1660\n",
            "1661\n",
            "1662\n",
            "1663\n",
            "1664\n",
            "1665\n",
            "1666\n",
            "1667\n",
            "1668\n",
            "1669\n",
            "1670\n",
            "1671\n",
            "1672\n",
            "1673\n",
            "1674\n",
            "1675\n",
            "1676\n",
            "1677\n",
            "1678\n",
            "1679\n",
            "1680\n",
            "1681\n",
            "1682\n",
            "1683\n",
            "1684\n",
            "1685\n",
            "1686\n",
            "1687\n",
            "1688\n",
            "1689\n",
            "1690\n",
            "1691\n",
            "1692\n",
            "1693\n",
            "1694\n",
            "1695\n",
            "1696\n",
            "1697\n",
            "1698\n",
            "1699\n",
            "1700\n",
            "1701\n",
            "1702\n",
            "1703\n",
            "1704\n",
            "1705\n",
            "1706\n",
            "1707\n",
            "1708\n",
            "1709\n",
            "1710\n",
            "1711\n",
            "1712\n",
            "1713\n",
            "1714\n",
            "1715\n",
            "1716\n",
            "1717\n",
            "1718\n",
            "1719\n",
            "1720\n",
            "1721\n",
            "1722\n",
            "1723\n",
            "1724\n",
            "1725\n",
            "1726\n",
            "1727\n",
            "1728\n",
            "1729\n",
            "1730\n",
            "1731\n",
            "1732\n",
            "1733\n",
            "1734\n",
            "1735\n",
            "1736\n",
            "1737\n",
            "1738\n",
            "1739\n",
            "1740\n",
            "1741\n",
            "1742\n",
            "1743\n",
            "1744\n",
            "1745\n",
            "1746\n",
            "1747\n",
            "1748\n",
            "1749\n",
            "1750\n",
            "1751\n",
            "1752\n",
            "1753\n",
            "1754\n",
            "1755\n",
            "1756\n",
            "1757\n",
            "1758\n",
            "1759\n",
            "1760\n",
            "1761\n",
            "1762\n",
            "1763\n",
            "1764\n",
            "1765\n",
            "1766\n",
            "1767\n",
            "1768\n",
            "1769\n",
            "1770\n",
            "1771\n",
            "1772\n",
            "1773\n",
            "1774\n",
            "1775\n",
            "1776\n",
            "1777\n",
            "1778\n",
            "1779\n",
            "1780\n",
            "1781\n",
            "1782\n",
            "1783\n",
            "1784\n",
            "1785\n",
            "1786\n",
            "1787\n",
            "1788\n",
            "1789\n",
            "1790\n",
            "1791\n",
            "1792\n",
            "1793\n",
            "1794\n",
            "1795\n",
            "1796\n",
            "1797\n",
            "1798\n",
            "1799\n",
            "1800\n",
            "1801\n",
            "1802\n",
            "1803\n",
            "1804\n",
            "1805\n",
            "1806\n",
            "1807\n",
            "1808\n",
            "1809\n",
            "1810\n",
            "1811\n",
            "1812\n",
            "1813\n",
            "1814\n",
            "1815\n",
            "1816\n",
            "1817\n",
            "1818\n",
            "1819\n",
            "1820\n",
            "1821\n",
            "1822\n",
            "1823\n",
            "1824\n",
            "1825\n",
            "1826\n",
            "1827\n",
            "1828\n",
            "1829\n",
            "1830\n",
            "1831\n",
            "1832\n",
            "1833\n",
            "1834\n",
            "1835\n",
            "1836\n",
            "1837\n",
            "1838\n",
            "1839\n",
            "1840\n",
            "1841\n",
            "1842\n",
            "1843\n",
            "1844\n",
            "1845\n",
            "1846\n",
            "1847\n",
            "1848\n",
            "1849\n",
            "1850\n",
            "1851\n",
            "1852\n",
            "1853\n",
            "1854\n",
            "1855\n",
            "1856\n",
            "1857\n",
            "1858\n",
            "1859\n",
            "1860\n",
            "1861\n",
            "1862\n",
            "1863\n",
            "1864\n",
            "1865\n",
            "1866\n",
            "1867\n",
            "1868\n",
            "1869\n",
            "1870\n",
            "1871\n",
            "1872\n",
            "1873\n",
            "1874\n",
            "1875\n",
            "1876\n",
            "1877\n",
            "1878\n",
            "1879\n",
            "1880\n",
            "1881\n",
            "1882\n",
            "1883\n",
            "1884\n",
            "1885\n",
            "1886\n",
            "1887\n",
            "1888\n",
            "1889\n",
            "1890\n",
            "1891\n",
            "1892\n",
            "1893\n",
            "1894\n",
            "1895\n",
            "1896\n",
            "1897\n",
            "1898\n",
            "1899\n",
            "1900\n",
            "1901\n",
            "1902\n",
            "1903\n",
            "1904\n",
            "1905\n",
            "1906\n",
            "1907\n",
            "1908\n",
            "1909\n",
            "1910\n",
            "1911\n",
            "1912\n",
            "1913\n",
            "1914\n",
            "1915\n",
            "1916\n",
            "1917\n",
            "1918\n",
            "1919\n",
            "1920\n",
            "1921\n",
            "1922\n",
            "1923\n",
            "1924\n",
            "1925\n",
            "1926\n",
            "1927\n",
            "1928\n",
            "1929\n",
            "1930\n",
            "1931\n",
            "1932\n",
            "1933\n",
            "1934\n",
            "1935\n",
            "1936\n",
            "1937\n",
            "1938\n",
            "1939\n",
            "1940\n",
            "1941\n",
            "1942\n",
            "1943\n",
            "1944\n",
            "1945\n",
            "1946\n",
            "1947\n",
            "1948\n",
            "1949\n",
            "1950\n",
            "1951\n",
            "1952\n",
            "1953\n",
            "1954\n",
            "1955\n",
            "1956\n",
            "1957\n",
            "1958\n",
            "1959\n",
            "1960\n",
            "1961\n",
            "1962\n",
            "1963\n",
            "1964\n",
            "1965\n",
            "1966\n",
            "1967\n",
            "1968\n",
            "1969\n",
            "1970\n",
            "1971\n",
            "1972\n",
            "1973\n",
            "1974\n",
            "1975\n",
            "1976\n",
            "1977\n",
            "1978\n",
            "1979\n",
            "1980\n",
            "1981\n",
            "1982\n",
            "1983\n",
            "1984\n",
            "1985\n",
            "1986\n",
            "1987\n",
            "1988\n",
            "1989\n",
            "1990\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "2021\n",
            "2022\n",
            "2023\n",
            "2024\n",
            "2025\n",
            "2026\n",
            "2027\n",
            "2028\n",
            "2029\n",
            "2030\n",
            "2031\n",
            "2032\n",
            "2033\n",
            "2034\n",
            "2035\n",
            "2036\n",
            "2037\n",
            "2038\n",
            "2039\n",
            "2040\n",
            "2041\n",
            "2042\n",
            "2043\n",
            "2044\n",
            "2045\n",
            "2046\n",
            "2047\n",
            "2048\n",
            "2049\n",
            "2050\n",
            "2051\n",
            "2052\n",
            "2053\n",
            "2054\n",
            "2055\n",
            "2056\n",
            "2057\n",
            "2058\n",
            "2059\n",
            "2060\n",
            "2061\n",
            "2062\n",
            "2063\n",
            "2064\n",
            "2065\n",
            "2066\n",
            "2067\n",
            "2068\n",
            "2069\n",
            "2070\n",
            "2071\n",
            "2072\n",
            "2073\n",
            "2074\n",
            "2075\n",
            "2076\n",
            "2077\n",
            "2078\n",
            "2079\n",
            "2080\n",
            "2081\n",
            "2082\n",
            "2083\n",
            "2084\n",
            "2085\n",
            "2086\n",
            "2087\n",
            "2088\n",
            "2089\n",
            "2090\n",
            "2091\n",
            "2092\n",
            "2093\n",
            "2094\n",
            "2095\n",
            "2096\n",
            "2097\n",
            "2098\n",
            "2099\n",
            "2100\n",
            "2101\n",
            "2102\n",
            "2103\n",
            "2104\n",
            "2105\n",
            "2106\n",
            "2107\n",
            "2108\n",
            "2109\n",
            "2110\n",
            "2111\n",
            "2112\n",
            "2113\n",
            "2114\n",
            "2115\n",
            "2116\n",
            "2117\n",
            "2118\n",
            "2119\n",
            "2120\n",
            "2121\n",
            "2122\n",
            "2123\n",
            "2124\n",
            "2125\n",
            "2126\n",
            "2127\n",
            "2128\n",
            "2129\n",
            "2130\n",
            "2131\n",
            "2132\n",
            "2133\n",
            "2134\n",
            "2135\n",
            "2136\n",
            "2137\n",
            "2138\n",
            "2139\n",
            "2140\n",
            "2141\n",
            "2142\n",
            "2143\n",
            "2144\n",
            "2145\n",
            "2146\n",
            "2147\n",
            "2148\n",
            "2149\n",
            "2150\n",
            "2151\n",
            "2152\n",
            "2153\n",
            "2154\n",
            "2155\n",
            "2156\n",
            "2157\n",
            "2158\n",
            "2159\n",
            "2160\n",
            "2161\n",
            "2162\n",
            "2163\n",
            "2164\n",
            "2165\n",
            "2166\n",
            "2167\n",
            "2168\n",
            "2169\n",
            "2170\n",
            "2171\n",
            "2172\n",
            "2173\n",
            "2174\n",
            "2175\n",
            "2176\n",
            "2177\n",
            "2178\n",
            "2179\n",
            "2180\n",
            "2181\n",
            "2182\n",
            "2183\n",
            "2184\n",
            "2185\n",
            "2186\n",
            "2187\n",
            "2188\n",
            "2189\n",
            "2190\n",
            "2191\n",
            "2192\n",
            "2193\n",
            "2194\n",
            "2195\n",
            "2196\n",
            "2197\n",
            "2198\n",
            "2199\n",
            "2200\n",
            "2201\n",
            "2202\n",
            "2203\n",
            "2204\n",
            "2205\n",
            "2206\n",
            "2207\n",
            "2208\n",
            "2209\n",
            "2210\n",
            "2211\n",
            "2212\n",
            "2213\n",
            "2214\n",
            "2215\n",
            "2216\n",
            "2217\n",
            "2218\n",
            "2219\n",
            "2220\n",
            "2221\n",
            "2222\n",
            "2223\n",
            "2224\n",
            "2225\n",
            "2226\n",
            "2227\n",
            "2228\n",
            "2229\n",
            "2230\n",
            "2231\n",
            "2232\n",
            "2233\n",
            "2234\n",
            "2235\n",
            "2236\n",
            "2237\n",
            "2238\n",
            "2239\n",
            "2240\n",
            "2241\n",
            "2242\n",
            "2243\n",
            "2244\n",
            "2245\n",
            "2246\n",
            "2247\n",
            "2248\n",
            "2249\n",
            "2250\n",
            "2251\n",
            "2252\n",
            "2253\n",
            "2254\n",
            "2255\n",
            "2256\n",
            "2257\n",
            "2258\n",
            "2259\n",
            "2260\n",
            "2261\n",
            "2262\n",
            "2263\n",
            "2264\n",
            "2265\n",
            "2266\n",
            "2267\n",
            "2268\n",
            "2269\n",
            "2270\n",
            "2271\n",
            "2272\n",
            "2273\n",
            "2274\n",
            "2275\n",
            "2276\n",
            "2277\n",
            "2278\n",
            "2279\n",
            "2280\n",
            "2281\n",
            "2282\n",
            "2283\n",
            "2284\n",
            "2285\n",
            "2286\n",
            "2287\n",
            "2288\n",
            "2289\n",
            "2290\n",
            "2291\n",
            "2292\n",
            "2293\n",
            "2294\n",
            "2295\n",
            "2296\n",
            "2297\n",
            "2298\n",
            "2299\n",
            "2300\n",
            "2301\n",
            "2302\n",
            "2303\n",
            "2304\n",
            "2305\n",
            "2306\n",
            "2307\n",
            "2308\n",
            "2309\n",
            "2310\n",
            "2311\n",
            "2312\n",
            "2313\n",
            "2314\n",
            "2315\n",
            "2316\n",
            "2317\n",
            "2318\n",
            "2319\n",
            "2320\n",
            "2321\n",
            "2322\n",
            "2323\n",
            "2324\n",
            "2325\n",
            "2326\n",
            "2327\n",
            "2328\n",
            "2329\n",
            "2330\n",
            "2331\n",
            "2332\n",
            "2333\n",
            "2334\n",
            "2335\n",
            "2336\n",
            "2337\n",
            "2338\n",
            "2339\n",
            "2340\n",
            "2341\n",
            "2342\n",
            "2343\n",
            "2344\n",
            "2345\n",
            "2346\n",
            "2347\n",
            "2348\n",
            "2349\n",
            "2350\n",
            "2351\n",
            "2352\n",
            "2353\n",
            "2354\n",
            "2355\n",
            "2356\n",
            "2357\n",
            "2358\n",
            "2359\n",
            "2360\n",
            "2361\n",
            "2362\n",
            "2363\n",
            "2364\n",
            "2365\n",
            "2366\n",
            "2367\n",
            "2368\n",
            "2369\n",
            "2370\n",
            "2371\n",
            "2372\n",
            "2373\n",
            "2374\n",
            "2375\n",
            "2376\n",
            "2377\n",
            "2378\n",
            "2379\n",
            "2380\n",
            "2381\n",
            "2382\n",
            "2383\n",
            "2384\n",
            "2385\n",
            "2386\n",
            "2387\n",
            "2388\n",
            "2389\n",
            "2390\n",
            "2391\n",
            "2392\n",
            "2393\n",
            "2394\n",
            "2395\n",
            "2396\n",
            "2397\n",
            "2398\n",
            "2399\n",
            "2400\n",
            "2401\n",
            "2402\n",
            "2403\n",
            "2404\n",
            "2405\n",
            "2406\n",
            "2407\n",
            "2408\n",
            "2409\n",
            "2410\n",
            "2411\n",
            "2412\n",
            "2413\n",
            "2414\n",
            "2415\n",
            "2416\n",
            "2417\n",
            "2418\n",
            "2419\n",
            "2420\n",
            "2421\n",
            "2422\n",
            "2423\n",
            "2424\n",
            "2425\n",
            "2426\n",
            "2427\n",
            "2428\n",
            "2429\n",
            "2430\n",
            "2431\n",
            "2432\n",
            "2433\n",
            "2434\n",
            "2435\n",
            "2436\n",
            "2437\n",
            "2438\n",
            "2439\n",
            "2440\n",
            "2441\n",
            "2442\n",
            "2443\n",
            "2444\n",
            "2445\n",
            "2446\n",
            "2447\n",
            "2448\n",
            "2449\n",
            "2450\n",
            "2451\n",
            "2452\n",
            "2453\n",
            "2454\n",
            "2455\n",
            "2456\n",
            "2457\n",
            "2458\n",
            "2459\n",
            "2460\n",
            "2461\n",
            "2462\n",
            "2463\n",
            "2464\n",
            "2465\n",
            "2466\n",
            "2467\n",
            "2468\n",
            "2469\n",
            "2470\n",
            "2471\n",
            "2472\n",
            "2473\n",
            "2474\n",
            "2475\n",
            "2476\n",
            "2477\n",
            "2478\n",
            "2479\n",
            "2480\n",
            "2481\n",
            "2482\n",
            "2483\n",
            "2484\n",
            "2485\n",
            "2486\n",
            "2487\n",
            "2488\n",
            "2489\n",
            "2490\n",
            "2491\n",
            "2492\n",
            "2493\n",
            "2494\n",
            "2495\n",
            "2496\n",
            "2497\n",
            "2498\n",
            "2499\n",
            "2500\n",
            "2501\n",
            "2502\n",
            "2503\n",
            "2504\n",
            "2505\n",
            "2506\n",
            "2507\n",
            "2508\n",
            "2509\n",
            "2510\n",
            "2511\n",
            "2512\n",
            "2513\n",
            "2514\n",
            "2515\n",
            "2516\n",
            "2517\n",
            "2518\n",
            "2519\n",
            "2520\n",
            "2521\n",
            "2522\n",
            "2523\n",
            "2524\n",
            "2525\n",
            "2526\n",
            "2527\n",
            "2528\n",
            "2529\n",
            "2530\n",
            "2531\n",
            "2532\n",
            "2533\n",
            "2534\n",
            "2535\n",
            "2536\n",
            "2537\n",
            "2538\n",
            "2539\n",
            "2540\n",
            "2541\n",
            "2542\n",
            "2543\n",
            "2544\n",
            "2545\n",
            "2546\n",
            "2547\n",
            "2548\n",
            "2549\n",
            "2550\n",
            "2551\n",
            "2552\n",
            "2553\n",
            "2554\n",
            "2555\n",
            "2556\n",
            "2557\n",
            "2558\n",
            "2559\n",
            "2560\n",
            "2561\n",
            "2562\n",
            "2563\n",
            "2564\n",
            "2565\n",
            "2566\n",
            "2567\n",
            "2568\n",
            "2569\n",
            "2570\n",
            "2571\n",
            "2572\n",
            "2573\n",
            "2574\n",
            "2575\n",
            "2576\n",
            "2577\n",
            "2578\n",
            "2579\n",
            "2580\n",
            "2581\n",
            "2582\n",
            "2583\n",
            "2584\n",
            "2585\n",
            "2586\n",
            "2587\n",
            "2588\n",
            "2589\n",
            "2590\n",
            "2591\n",
            "2592\n",
            "2593\n",
            "2594\n",
            "2595\n",
            "2596\n",
            "2597\n",
            "2598\n",
            "2599\n",
            "2600\n",
            "2601\n",
            "2602\n",
            "2603\n",
            "2604\n",
            "2605\n",
            "2606\n",
            "2607\n",
            "2608\n",
            "2609\n",
            "2610\n",
            "2611\n",
            "2612\n",
            "2613\n",
            "2614\n",
            "2615\n",
            "2616\n",
            "2617\n",
            "2618\n",
            "2619\n",
            "2620\n",
            "2621\n",
            "2622\n",
            "2623\n",
            "2624\n",
            "2625\n",
            "2626\n",
            "2627\n",
            "2628\n",
            "2629\n",
            "2630\n",
            "2631\n",
            "2632\n",
            "2633\n",
            "2634\n",
            "2635\n",
            "2636\n",
            "2637\n",
            "2638\n",
            "2639\n",
            "2640\n",
            "2641\n",
            "2642\n",
            "2643\n",
            "2644\n",
            "2645\n",
            "2646\n",
            "2647\n",
            "2648\n",
            "2649\n",
            "2650\n",
            "2651\n",
            "2652\n",
            "2653\n",
            "2654\n",
            "2655\n",
            "2656\n",
            "2657\n",
            "2658\n",
            "2659\n",
            "2660\n",
            "2661\n",
            "2662\n",
            "2663\n",
            "2664\n",
            "2665\n",
            "2666\n",
            "2667\n",
            "2668\n",
            "2669\n",
            "2670\n",
            "2671\n",
            "2672\n",
            "2673\n",
            "2674\n",
            "2675\n",
            "2676\n",
            "2677\n",
            "2678\n",
            "2679\n",
            "2680\n",
            "2681\n",
            "2682\n",
            "2683\n",
            "2684\n",
            "2685\n",
            "2686\n",
            "2687\n",
            "2688\n",
            "2689\n",
            "2690\n",
            "2691\n",
            "2692\n",
            "2693\n",
            "2694\n",
            "2695\n",
            "2696\n",
            "2697\n",
            "2698\n",
            "2699\n",
            "2700\n",
            "2701\n",
            "2702\n",
            "2703\n",
            "2704\n",
            "2705\n",
            "2706\n",
            "2707\n",
            "2708\n",
            "2709\n",
            "2710\n",
            "2711\n",
            "2712\n",
            "2713\n",
            "2714\n",
            "2715\n",
            "2716\n",
            "2717\n",
            "2718\n",
            "2719\n",
            "2720\n",
            "2721\n",
            "2722\n",
            "2723\n",
            "2724\n",
            "2725\n",
            "2726\n",
            "2727\n",
            "2728\n",
            "2729\n",
            "2730\n",
            "2731\n",
            "2732\n",
            "2733\n",
            "2734\n",
            "2735\n",
            "2736\n",
            "2737\n",
            "2738\n",
            "2739\n",
            "2740\n",
            "2741\n",
            "2742\n",
            "2743\n",
            "2744\n",
            "2745\n",
            "2746\n",
            "2747\n",
            "2748\n",
            "2749\n",
            "2750\n",
            "2751\n",
            "2752\n",
            "2753\n",
            "2754\n",
            "2755\n",
            "2756\n",
            "2757\n",
            "2758\n",
            "2759\n",
            "2760\n",
            "2761\n",
            "2762\n",
            "2763\n",
            "2764\n",
            "2765\n",
            "2766\n",
            "2767\n",
            "2768\n",
            "2769\n",
            "2770\n",
            "2771\n",
            "2772\n",
            "2773\n",
            "2774\n",
            "2775\n",
            "2776\n",
            "2777\n",
            "2778\n",
            "2779\n",
            "2780\n",
            "2781\n",
            "2782\n",
            "2783\n",
            "2784\n",
            "2785\n",
            "2786\n",
            "2787\n",
            "2788\n",
            "2789\n",
            "2790\n",
            "2791\n",
            "2792\n",
            "2793\n",
            "2794\n",
            "2795\n",
            "2796\n",
            "2797\n",
            "2798\n",
            "2799\n",
            "2800\n",
            "2801\n",
            "2802\n",
            "2803\n",
            "2804\n",
            "2805\n",
            "2806\n",
            "2807\n",
            "2808\n",
            "2809\n",
            "2810\n",
            "2811\n",
            "2812\n",
            "2813\n",
            "2814\n",
            "2815\n",
            "2816\n",
            "2817\n",
            "2818\n",
            "2819\n",
            "2820\n",
            "2821\n",
            "2822\n",
            "2823\n",
            "2824\n",
            "2825\n",
            "2826\n",
            "2827\n",
            "2828\n",
            "2829\n",
            "2830\n",
            "2831\n",
            "2832\n",
            "2833\n",
            "2834\n",
            "2835\n",
            "2836\n",
            "2837\n",
            "2838\n",
            "2839\n",
            "2840\n",
            "2841\n",
            "2842\n",
            "2843\n",
            "2844\n",
            "2845\n",
            "2846\n",
            "2847\n",
            "2848\n",
            "2849\n",
            "2850\n",
            "2851\n",
            "2852\n",
            "2853\n",
            "2854\n",
            "2855\n",
            "2856\n",
            "2857\n",
            "2858\n",
            "2859\n",
            "2860\n",
            "2861\n",
            "2862\n",
            "2863\n",
            "2864\n",
            "2865\n",
            "2866\n",
            "2867\n",
            "2868\n",
            "2869\n",
            "2870\n",
            "2871\n",
            "2872\n",
            "2873\n",
            "2874\n",
            "2875\n",
            "2876\n",
            "2877\n",
            "2878\n",
            "2879\n",
            "2880\n",
            "2881\n",
            "2882\n",
            "2883\n",
            "2884\n",
            "2885\n",
            "2886\n",
            "2887\n",
            "2888\n",
            "2889\n",
            "2890\n",
            "2891\n",
            "2892\n",
            "2893\n",
            "2894\n",
            "2895\n",
            "2896\n",
            "2897\n",
            "2898\n",
            "2899\n",
            "2900\n",
            "2901\n",
            "2902\n",
            "2903\n",
            "2904\n",
            "2905\n",
            "2906\n",
            "2907\n",
            "2908\n",
            "2909\n",
            "2910\n",
            "2911\n",
            "2912\n",
            "2913\n",
            "2914\n",
            "2915\n",
            "2916\n",
            "2917\n",
            "2918\n",
            "2919\n",
            "2920\n",
            "2921\n",
            "2922\n",
            "2923\n",
            "2924\n",
            "2925\n",
            "2926\n",
            "2927\n",
            "2928\n",
            "2929\n",
            "2930\n",
            "2931\n",
            "2932\n",
            "2933\n",
            "2934\n",
            "2935\n",
            "2936\n",
            "2937\n",
            "2938\n",
            "2939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sug8JlOFPwkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp2=np.array(q)\n",
        "np.save(\"drive/My Drive/MS_data/temp_2_new.npy\",temp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLOQgCefP2w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=np.load(\"drive/My Drive/MS_data/temp_1_new.npy\")\n",
        "p=list(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjF4cYI7P7V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp2=np.load(\"drive/My Drive/MS_data/temp_2_new.npy\")\n",
        "q=list(temp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCeKtqTIP-uq",
        "colab_type": "code",
        "outputId": "a2ddcffa-eb66-4cd5-f06e-5161fdff0772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "j=1401\n",
        "for i in q:\n",
        "  print(j)\n",
        "  p.append(i)\n",
        "  j+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n",
            "1441\n",
            "1442\n",
            "1443\n",
            "1444\n",
            "1445\n",
            "1446\n",
            "1447\n",
            "1448\n",
            "1449\n",
            "1450\n",
            "1451\n",
            "1452\n",
            "1453\n",
            "1454\n",
            "1455\n",
            "1456\n",
            "1457\n",
            "1458\n",
            "1459\n",
            "1460\n",
            "1461\n",
            "1462\n",
            "1463\n",
            "1464\n",
            "1465\n",
            "1466\n",
            "1467\n",
            "1468\n",
            "1469\n",
            "1470\n",
            "1471\n",
            "1472\n",
            "1473\n",
            "1474\n",
            "1475\n",
            "1476\n",
            "1477\n",
            "1478\n",
            "1479\n",
            "1480\n",
            "1481\n",
            "1482\n",
            "1483\n",
            "1484\n",
            "1485\n",
            "1486\n",
            "1487\n",
            "1488\n",
            "1489\n",
            "1490\n",
            "1491\n",
            "1492\n",
            "1493\n",
            "1494\n",
            "1495\n",
            "1496\n",
            "1497\n",
            "1498\n",
            "1499\n",
            "1500\n",
            "1501\n",
            "1502\n",
            "1503\n",
            "1504\n",
            "1505\n",
            "1506\n",
            "1507\n",
            "1508\n",
            "1509\n",
            "1510\n",
            "1511\n",
            "1512\n",
            "1513\n",
            "1514\n",
            "1515\n",
            "1516\n",
            "1517\n",
            "1518\n",
            "1519\n",
            "1520\n",
            "1521\n",
            "1522\n",
            "1523\n",
            "1524\n",
            "1525\n",
            "1526\n",
            "1527\n",
            "1528\n",
            "1529\n",
            "1530\n",
            "1531\n",
            "1532\n",
            "1533\n",
            "1534\n",
            "1535\n",
            "1536\n",
            "1537\n",
            "1538\n",
            "1539\n",
            "1540\n",
            "1541\n",
            "1542\n",
            "1543\n",
            "1544\n",
            "1545\n",
            "1546\n",
            "1547\n",
            "1548\n",
            "1549\n",
            "1550\n",
            "1551\n",
            "1552\n",
            "1553\n",
            "1554\n",
            "1555\n",
            "1556\n",
            "1557\n",
            "1558\n",
            "1559\n",
            "1560\n",
            "1561\n",
            "1562\n",
            "1563\n",
            "1564\n",
            "1565\n",
            "1566\n",
            "1567\n",
            "1568\n",
            "1569\n",
            "1570\n",
            "1571\n",
            "1572\n",
            "1573\n",
            "1574\n",
            "1575\n",
            "1576\n",
            "1577\n",
            "1578\n",
            "1579\n",
            "1580\n",
            "1581\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1585\n",
            "1586\n",
            "1587\n",
            "1588\n",
            "1589\n",
            "1590\n",
            "1591\n",
            "1592\n",
            "1593\n",
            "1594\n",
            "1595\n",
            "1596\n",
            "1597\n",
            "1598\n",
            "1599\n",
            "1600\n",
            "1601\n",
            "1602\n",
            "1603\n",
            "1604\n",
            "1605\n",
            "1606\n",
            "1607\n",
            "1608\n",
            "1609\n",
            "1610\n",
            "1611\n",
            "1612\n",
            "1613\n",
            "1614\n",
            "1615\n",
            "1616\n",
            "1617\n",
            "1618\n",
            "1619\n",
            "1620\n",
            "1621\n",
            "1622\n",
            "1623\n",
            "1624\n",
            "1625\n",
            "1626\n",
            "1627\n",
            "1628\n",
            "1629\n",
            "1630\n",
            "1631\n",
            "1632\n",
            "1633\n",
            "1634\n",
            "1635\n",
            "1636\n",
            "1637\n",
            "1638\n",
            "1639\n",
            "1640\n",
            "1641\n",
            "1642\n",
            "1643\n",
            "1644\n",
            "1645\n",
            "1646\n",
            "1647\n",
            "1648\n",
            "1649\n",
            "1650\n",
            "1651\n",
            "1652\n",
            "1653\n",
            "1654\n",
            "1655\n",
            "1656\n",
            "1657\n",
            "1658\n",
            "1659\n",
            "1660\n",
            "1661\n",
            "1662\n",
            "1663\n",
            "1664\n",
            "1665\n",
            "1666\n",
            "1667\n",
            "1668\n",
            "1669\n",
            "1670\n",
            "1671\n",
            "1672\n",
            "1673\n",
            "1674\n",
            "1675\n",
            "1676\n",
            "1677\n",
            "1678\n",
            "1679\n",
            "1680\n",
            "1681\n",
            "1682\n",
            "1683\n",
            "1684\n",
            "1685\n",
            "1686\n",
            "1687\n",
            "1688\n",
            "1689\n",
            "1690\n",
            "1691\n",
            "1692\n",
            "1693\n",
            "1694\n",
            "1695\n",
            "1696\n",
            "1697\n",
            "1698\n",
            "1699\n",
            "1700\n",
            "1701\n",
            "1702\n",
            "1703\n",
            "1704\n",
            "1705\n",
            "1706\n",
            "1707\n",
            "1708\n",
            "1709\n",
            "1710\n",
            "1711\n",
            "1712\n",
            "1713\n",
            "1714\n",
            "1715\n",
            "1716\n",
            "1717\n",
            "1718\n",
            "1719\n",
            "1720\n",
            "1721\n",
            "1722\n",
            "1723\n",
            "1724\n",
            "1725\n",
            "1726\n",
            "1727\n",
            "1728\n",
            "1729\n",
            "1730\n",
            "1731\n",
            "1732\n",
            "1733\n",
            "1734\n",
            "1735\n",
            "1736\n",
            "1737\n",
            "1738\n",
            "1739\n",
            "1740\n",
            "1741\n",
            "1742\n",
            "1743\n",
            "1744\n",
            "1745\n",
            "1746\n",
            "1747\n",
            "1748\n",
            "1749\n",
            "1750\n",
            "1751\n",
            "1752\n",
            "1753\n",
            "1754\n",
            "1755\n",
            "1756\n",
            "1757\n",
            "1758\n",
            "1759\n",
            "1760\n",
            "1761\n",
            "1762\n",
            "1763\n",
            "1764\n",
            "1765\n",
            "1766\n",
            "1767\n",
            "1768\n",
            "1769\n",
            "1770\n",
            "1771\n",
            "1772\n",
            "1773\n",
            "1774\n",
            "1775\n",
            "1776\n",
            "1777\n",
            "1778\n",
            "1779\n",
            "1780\n",
            "1781\n",
            "1782\n",
            "1783\n",
            "1784\n",
            "1785\n",
            "1786\n",
            "1787\n",
            "1788\n",
            "1789\n",
            "1790\n",
            "1791\n",
            "1792\n",
            "1793\n",
            "1794\n",
            "1795\n",
            "1796\n",
            "1797\n",
            "1798\n",
            "1799\n",
            "1800\n",
            "1801\n",
            "1802\n",
            "1803\n",
            "1804\n",
            "1805\n",
            "1806\n",
            "1807\n",
            "1808\n",
            "1809\n",
            "1810\n",
            "1811\n",
            "1812\n",
            "1813\n",
            "1814\n",
            "1815\n",
            "1816\n",
            "1817\n",
            "1818\n",
            "1819\n",
            "1820\n",
            "1821\n",
            "1822\n",
            "1823\n",
            "1824\n",
            "1825\n",
            "1826\n",
            "1827\n",
            "1828\n",
            "1829\n",
            "1830\n",
            "1831\n",
            "1832\n",
            "1833\n",
            "1834\n",
            "1835\n",
            "1836\n",
            "1837\n",
            "1838\n",
            "1839\n",
            "1840\n",
            "1841\n",
            "1842\n",
            "1843\n",
            "1844\n",
            "1845\n",
            "1846\n",
            "1847\n",
            "1848\n",
            "1849\n",
            "1850\n",
            "1851\n",
            "1852\n",
            "1853\n",
            "1854\n",
            "1855\n",
            "1856\n",
            "1857\n",
            "1858\n",
            "1859\n",
            "1860\n",
            "1861\n",
            "1862\n",
            "1863\n",
            "1864\n",
            "1865\n",
            "1866\n",
            "1867\n",
            "1868\n",
            "1869\n",
            "1870\n",
            "1871\n",
            "1872\n",
            "1873\n",
            "1874\n",
            "1875\n",
            "1876\n",
            "1877\n",
            "1878\n",
            "1879\n",
            "1880\n",
            "1881\n",
            "1882\n",
            "1883\n",
            "1884\n",
            "1885\n",
            "1886\n",
            "1887\n",
            "1888\n",
            "1889\n",
            "1890\n",
            "1891\n",
            "1892\n",
            "1893\n",
            "1894\n",
            "1895\n",
            "1896\n",
            "1897\n",
            "1898\n",
            "1899\n",
            "1900\n",
            "1901\n",
            "1902\n",
            "1903\n",
            "1904\n",
            "1905\n",
            "1906\n",
            "1907\n",
            "1908\n",
            "1909\n",
            "1910\n",
            "1911\n",
            "1912\n",
            "1913\n",
            "1914\n",
            "1915\n",
            "1916\n",
            "1917\n",
            "1918\n",
            "1919\n",
            "1920\n",
            "1921\n",
            "1922\n",
            "1923\n",
            "1924\n",
            "1925\n",
            "1926\n",
            "1927\n",
            "1928\n",
            "1929\n",
            "1930\n",
            "1931\n",
            "1932\n",
            "1933\n",
            "1934\n",
            "1935\n",
            "1936\n",
            "1937\n",
            "1938\n",
            "1939\n",
            "1940\n",
            "1941\n",
            "1942\n",
            "1943\n",
            "1944\n",
            "1945\n",
            "1946\n",
            "1947\n",
            "1948\n",
            "1949\n",
            "1950\n",
            "1951\n",
            "1952\n",
            "1953\n",
            "1954\n",
            "1955\n",
            "1956\n",
            "1957\n",
            "1958\n",
            "1959\n",
            "1960\n",
            "1961\n",
            "1962\n",
            "1963\n",
            "1964\n",
            "1965\n",
            "1966\n",
            "1967\n",
            "1968\n",
            "1969\n",
            "1970\n",
            "1971\n",
            "1972\n",
            "1973\n",
            "1974\n",
            "1975\n",
            "1976\n",
            "1977\n",
            "1978\n",
            "1979\n",
            "1980\n",
            "1981\n",
            "1982\n",
            "1983\n",
            "1984\n",
            "1985\n",
            "1986\n",
            "1987\n",
            "1988\n",
            "1989\n",
            "1990\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "2021\n",
            "2022\n",
            "2023\n",
            "2024\n",
            "2025\n",
            "2026\n",
            "2027\n",
            "2028\n",
            "2029\n",
            "2030\n",
            "2031\n",
            "2032\n",
            "2033\n",
            "2034\n",
            "2035\n",
            "2036\n",
            "2037\n",
            "2038\n",
            "2039\n",
            "2040\n",
            "2041\n",
            "2042\n",
            "2043\n",
            "2044\n",
            "2045\n",
            "2046\n",
            "2047\n",
            "2048\n",
            "2049\n",
            "2050\n",
            "2051\n",
            "2052\n",
            "2053\n",
            "2054\n",
            "2055\n",
            "2056\n",
            "2057\n",
            "2058\n",
            "2059\n",
            "2060\n",
            "2061\n",
            "2062\n",
            "2063\n",
            "2064\n",
            "2065\n",
            "2066\n",
            "2067\n",
            "2068\n",
            "2069\n",
            "2070\n",
            "2071\n",
            "2072\n",
            "2073\n",
            "2074\n",
            "2075\n",
            "2076\n",
            "2077\n",
            "2078\n",
            "2079\n",
            "2080\n",
            "2081\n",
            "2082\n",
            "2083\n",
            "2084\n",
            "2085\n",
            "2086\n",
            "2087\n",
            "2088\n",
            "2089\n",
            "2090\n",
            "2091\n",
            "2092\n",
            "2093\n",
            "2094\n",
            "2095\n",
            "2096\n",
            "2097\n",
            "2098\n",
            "2099\n",
            "2100\n",
            "2101\n",
            "2102\n",
            "2103\n",
            "2104\n",
            "2105\n",
            "2106\n",
            "2107\n",
            "2108\n",
            "2109\n",
            "2110\n",
            "2111\n",
            "2112\n",
            "2113\n",
            "2114\n",
            "2115\n",
            "2116\n",
            "2117\n",
            "2118\n",
            "2119\n",
            "2120\n",
            "2121\n",
            "2122\n",
            "2123\n",
            "2124\n",
            "2125\n",
            "2126\n",
            "2127\n",
            "2128\n",
            "2129\n",
            "2130\n",
            "2131\n",
            "2132\n",
            "2133\n",
            "2134\n",
            "2135\n",
            "2136\n",
            "2137\n",
            "2138\n",
            "2139\n",
            "2140\n",
            "2141\n",
            "2142\n",
            "2143\n",
            "2144\n",
            "2145\n",
            "2146\n",
            "2147\n",
            "2148\n",
            "2149\n",
            "2150\n",
            "2151\n",
            "2152\n",
            "2153\n",
            "2154\n",
            "2155\n",
            "2156\n",
            "2157\n",
            "2158\n",
            "2159\n",
            "2160\n",
            "2161\n",
            "2162\n",
            "2163\n",
            "2164\n",
            "2165\n",
            "2166\n",
            "2167\n",
            "2168\n",
            "2169\n",
            "2170\n",
            "2171\n",
            "2172\n",
            "2173\n",
            "2174\n",
            "2175\n",
            "2176\n",
            "2177\n",
            "2178\n",
            "2179\n",
            "2180\n",
            "2181\n",
            "2182\n",
            "2183\n",
            "2184\n",
            "2185\n",
            "2186\n",
            "2187\n",
            "2188\n",
            "2189\n",
            "2190\n",
            "2191\n",
            "2192\n",
            "2193\n",
            "2194\n",
            "2195\n",
            "2196\n",
            "2197\n",
            "2198\n",
            "2199\n",
            "2200\n",
            "2201\n",
            "2202\n",
            "2203\n",
            "2204\n",
            "2205\n",
            "2206\n",
            "2207\n",
            "2208\n",
            "2209\n",
            "2210\n",
            "2211\n",
            "2212\n",
            "2213\n",
            "2214\n",
            "2215\n",
            "2216\n",
            "2217\n",
            "2218\n",
            "2219\n",
            "2220\n",
            "2221\n",
            "2222\n",
            "2223\n",
            "2224\n",
            "2225\n",
            "2226\n",
            "2227\n",
            "2228\n",
            "2229\n",
            "2230\n",
            "2231\n",
            "2232\n",
            "2233\n",
            "2234\n",
            "2235\n",
            "2236\n",
            "2237\n",
            "2238\n",
            "2239\n",
            "2240\n",
            "2241\n",
            "2242\n",
            "2243\n",
            "2244\n",
            "2245\n",
            "2246\n",
            "2247\n",
            "2248\n",
            "2249\n",
            "2250\n",
            "2251\n",
            "2252\n",
            "2253\n",
            "2254\n",
            "2255\n",
            "2256\n",
            "2257\n",
            "2258\n",
            "2259\n",
            "2260\n",
            "2261\n",
            "2262\n",
            "2263\n",
            "2264\n",
            "2265\n",
            "2266\n",
            "2267\n",
            "2268\n",
            "2269\n",
            "2270\n",
            "2271\n",
            "2272\n",
            "2273\n",
            "2274\n",
            "2275\n",
            "2276\n",
            "2277\n",
            "2278\n",
            "2279\n",
            "2280\n",
            "2281\n",
            "2282\n",
            "2283\n",
            "2284\n",
            "2285\n",
            "2286\n",
            "2287\n",
            "2288\n",
            "2289\n",
            "2290\n",
            "2291\n",
            "2292\n",
            "2293\n",
            "2294\n",
            "2295\n",
            "2296\n",
            "2297\n",
            "2298\n",
            "2299\n",
            "2300\n",
            "2301\n",
            "2302\n",
            "2303\n",
            "2304\n",
            "2305\n",
            "2306\n",
            "2307\n",
            "2308\n",
            "2309\n",
            "2310\n",
            "2311\n",
            "2312\n",
            "2313\n",
            "2314\n",
            "2315\n",
            "2316\n",
            "2317\n",
            "2318\n",
            "2319\n",
            "2320\n",
            "2321\n",
            "2322\n",
            "2323\n",
            "2324\n",
            "2325\n",
            "2326\n",
            "2327\n",
            "2328\n",
            "2329\n",
            "2330\n",
            "2331\n",
            "2332\n",
            "2333\n",
            "2334\n",
            "2335\n",
            "2336\n",
            "2337\n",
            "2338\n",
            "2339\n",
            "2340\n",
            "2341\n",
            "2342\n",
            "2343\n",
            "2344\n",
            "2345\n",
            "2346\n",
            "2347\n",
            "2348\n",
            "2349\n",
            "2350\n",
            "2351\n",
            "2352\n",
            "2353\n",
            "2354\n",
            "2355\n",
            "2356\n",
            "2357\n",
            "2358\n",
            "2359\n",
            "2360\n",
            "2361\n",
            "2362\n",
            "2363\n",
            "2364\n",
            "2365\n",
            "2366\n",
            "2367\n",
            "2368\n",
            "2369\n",
            "2370\n",
            "2371\n",
            "2372\n",
            "2373\n",
            "2374\n",
            "2375\n",
            "2376\n",
            "2377\n",
            "2378\n",
            "2379\n",
            "2380\n",
            "2381\n",
            "2382\n",
            "2383\n",
            "2384\n",
            "2385\n",
            "2386\n",
            "2387\n",
            "2388\n",
            "2389\n",
            "2390\n",
            "2391\n",
            "2392\n",
            "2393\n",
            "2394\n",
            "2395\n",
            "2396\n",
            "2397\n",
            "2398\n",
            "2399\n",
            "2400\n",
            "2401\n",
            "2402\n",
            "2403\n",
            "2404\n",
            "2405\n",
            "2406\n",
            "2407\n",
            "2408\n",
            "2409\n",
            "2410\n",
            "2411\n",
            "2412\n",
            "2413\n",
            "2414\n",
            "2415\n",
            "2416\n",
            "2417\n",
            "2418\n",
            "2419\n",
            "2420\n",
            "2421\n",
            "2422\n",
            "2423\n",
            "2424\n",
            "2425\n",
            "2426\n",
            "2427\n",
            "2428\n",
            "2429\n",
            "2430\n",
            "2431\n",
            "2432\n",
            "2433\n",
            "2434\n",
            "2435\n",
            "2436\n",
            "2437\n",
            "2438\n",
            "2439\n",
            "2440\n",
            "2441\n",
            "2442\n",
            "2443\n",
            "2444\n",
            "2445\n",
            "2446\n",
            "2447\n",
            "2448\n",
            "2449\n",
            "2450\n",
            "2451\n",
            "2452\n",
            "2453\n",
            "2454\n",
            "2455\n",
            "2456\n",
            "2457\n",
            "2458\n",
            "2459\n",
            "2460\n",
            "2461\n",
            "2462\n",
            "2463\n",
            "2464\n",
            "2465\n",
            "2466\n",
            "2467\n",
            "2468\n",
            "2469\n",
            "2470\n",
            "2471\n",
            "2472\n",
            "2473\n",
            "2474\n",
            "2475\n",
            "2476\n",
            "2477\n",
            "2478\n",
            "2479\n",
            "2480\n",
            "2481\n",
            "2482\n",
            "2483\n",
            "2484\n",
            "2485\n",
            "2486\n",
            "2487\n",
            "2488\n",
            "2489\n",
            "2490\n",
            "2491\n",
            "2492\n",
            "2493\n",
            "2494\n",
            "2495\n",
            "2496\n",
            "2497\n",
            "2498\n",
            "2499\n",
            "2500\n",
            "2501\n",
            "2502\n",
            "2503\n",
            "2504\n",
            "2505\n",
            "2506\n",
            "2507\n",
            "2508\n",
            "2509\n",
            "2510\n",
            "2511\n",
            "2512\n",
            "2513\n",
            "2514\n",
            "2515\n",
            "2516\n",
            "2517\n",
            "2518\n",
            "2519\n",
            "2520\n",
            "2521\n",
            "2522\n",
            "2523\n",
            "2524\n",
            "2525\n",
            "2526\n",
            "2527\n",
            "2528\n",
            "2529\n",
            "2530\n",
            "2531\n",
            "2532\n",
            "2533\n",
            "2534\n",
            "2535\n",
            "2536\n",
            "2537\n",
            "2538\n",
            "2539\n",
            "2540\n",
            "2541\n",
            "2542\n",
            "2543\n",
            "2544\n",
            "2545\n",
            "2546\n",
            "2547\n",
            "2548\n",
            "2549\n",
            "2550\n",
            "2551\n",
            "2552\n",
            "2553\n",
            "2554\n",
            "2555\n",
            "2556\n",
            "2557\n",
            "2558\n",
            "2559\n",
            "2560\n",
            "2561\n",
            "2562\n",
            "2563\n",
            "2564\n",
            "2565\n",
            "2566\n",
            "2567\n",
            "2568\n",
            "2569\n",
            "2570\n",
            "2571\n",
            "2572\n",
            "2573\n",
            "2574\n",
            "2575\n",
            "2576\n",
            "2577\n",
            "2578\n",
            "2579\n",
            "2580\n",
            "2581\n",
            "2582\n",
            "2583\n",
            "2584\n",
            "2585\n",
            "2586\n",
            "2587\n",
            "2588\n",
            "2589\n",
            "2590\n",
            "2591\n",
            "2592\n",
            "2593\n",
            "2594\n",
            "2595\n",
            "2596\n",
            "2597\n",
            "2598\n",
            "2599\n",
            "2600\n",
            "2601\n",
            "2602\n",
            "2603\n",
            "2604\n",
            "2605\n",
            "2606\n",
            "2607\n",
            "2608\n",
            "2609\n",
            "2610\n",
            "2611\n",
            "2612\n",
            "2613\n",
            "2614\n",
            "2615\n",
            "2616\n",
            "2617\n",
            "2618\n",
            "2619\n",
            "2620\n",
            "2621\n",
            "2622\n",
            "2623\n",
            "2624\n",
            "2625\n",
            "2626\n",
            "2627\n",
            "2628\n",
            "2629\n",
            "2630\n",
            "2631\n",
            "2632\n",
            "2633\n",
            "2634\n",
            "2635\n",
            "2636\n",
            "2637\n",
            "2638\n",
            "2639\n",
            "2640\n",
            "2641\n",
            "2642\n",
            "2643\n",
            "2644\n",
            "2645\n",
            "2646\n",
            "2647\n",
            "2648\n",
            "2649\n",
            "2650\n",
            "2651\n",
            "2652\n",
            "2653\n",
            "2654\n",
            "2655\n",
            "2656\n",
            "2657\n",
            "2658\n",
            "2659\n",
            "2660\n",
            "2661\n",
            "2662\n",
            "2663\n",
            "2664\n",
            "2665\n",
            "2666\n",
            "2667\n",
            "2668\n",
            "2669\n",
            "2670\n",
            "2671\n",
            "2672\n",
            "2673\n",
            "2674\n",
            "2675\n",
            "2676\n",
            "2677\n",
            "2678\n",
            "2679\n",
            "2680\n",
            "2681\n",
            "2682\n",
            "2683\n",
            "2684\n",
            "2685\n",
            "2686\n",
            "2687\n",
            "2688\n",
            "2689\n",
            "2690\n",
            "2691\n",
            "2692\n",
            "2693\n",
            "2694\n",
            "2695\n",
            "2696\n",
            "2697\n",
            "2698\n",
            "2699\n",
            "2700\n",
            "2701\n",
            "2702\n",
            "2703\n",
            "2704\n",
            "2705\n",
            "2706\n",
            "2707\n",
            "2708\n",
            "2709\n",
            "2710\n",
            "2711\n",
            "2712\n",
            "2713\n",
            "2714\n",
            "2715\n",
            "2716\n",
            "2717\n",
            "2718\n",
            "2719\n",
            "2720\n",
            "2721\n",
            "2722\n",
            "2723\n",
            "2724\n",
            "2725\n",
            "2726\n",
            "2727\n",
            "2728\n",
            "2729\n",
            "2730\n",
            "2731\n",
            "2732\n",
            "2733\n",
            "2734\n",
            "2735\n",
            "2736\n",
            "2737\n",
            "2738\n",
            "2739\n",
            "2740\n",
            "2741\n",
            "2742\n",
            "2743\n",
            "2744\n",
            "2745\n",
            "2746\n",
            "2747\n",
            "2748\n",
            "2749\n",
            "2750\n",
            "2751\n",
            "2752\n",
            "2753\n",
            "2754\n",
            "2755\n",
            "2756\n",
            "2757\n",
            "2758\n",
            "2759\n",
            "2760\n",
            "2761\n",
            "2762\n",
            "2763\n",
            "2764\n",
            "2765\n",
            "2766\n",
            "2767\n",
            "2768\n",
            "2769\n",
            "2770\n",
            "2771\n",
            "2772\n",
            "2773\n",
            "2774\n",
            "2775\n",
            "2776\n",
            "2777\n",
            "2778\n",
            "2779\n",
            "2780\n",
            "2781\n",
            "2782\n",
            "2783\n",
            "2784\n",
            "2785\n",
            "2786\n",
            "2787\n",
            "2788\n",
            "2789\n",
            "2790\n",
            "2791\n",
            "2792\n",
            "2793\n",
            "2794\n",
            "2795\n",
            "2796\n",
            "2797\n",
            "2798\n",
            "2799\n",
            "2800\n",
            "2801\n",
            "2802\n",
            "2803\n",
            "2804\n",
            "2805\n",
            "2806\n",
            "2807\n",
            "2808\n",
            "2809\n",
            "2810\n",
            "2811\n",
            "2812\n",
            "2813\n",
            "2814\n",
            "2815\n",
            "2816\n",
            "2817\n",
            "2818\n",
            "2819\n",
            "2820\n",
            "2821\n",
            "2822\n",
            "2823\n",
            "2824\n",
            "2825\n",
            "2826\n",
            "2827\n",
            "2828\n",
            "2829\n",
            "2830\n",
            "2831\n",
            "2832\n",
            "2833\n",
            "2834\n",
            "2835\n",
            "2836\n",
            "2837\n",
            "2838\n",
            "2839\n",
            "2840\n",
            "2841\n",
            "2842\n",
            "2843\n",
            "2844\n",
            "2845\n",
            "2846\n",
            "2847\n",
            "2848\n",
            "2849\n",
            "2850\n",
            "2851\n",
            "2852\n",
            "2853\n",
            "2854\n",
            "2855\n",
            "2856\n",
            "2857\n",
            "2858\n",
            "2859\n",
            "2860\n",
            "2861\n",
            "2862\n",
            "2863\n",
            "2864\n",
            "2865\n",
            "2866\n",
            "2867\n",
            "2868\n",
            "2869\n",
            "2870\n",
            "2871\n",
            "2872\n",
            "2873\n",
            "2874\n",
            "2875\n",
            "2876\n",
            "2877\n",
            "2878\n",
            "2879\n",
            "2880\n",
            "2881\n",
            "2882\n",
            "2883\n",
            "2884\n",
            "2885\n",
            "2886\n",
            "2887\n",
            "2888\n",
            "2889\n",
            "2890\n",
            "2891\n",
            "2892\n",
            "2893\n",
            "2894\n",
            "2895\n",
            "2896\n",
            "2897\n",
            "2898\n",
            "2899\n",
            "2900\n",
            "2901\n",
            "2902\n",
            "2903\n",
            "2904\n",
            "2905\n",
            "2906\n",
            "2907\n",
            "2908\n",
            "2909\n",
            "2910\n",
            "2911\n",
            "2912\n",
            "2913\n",
            "2914\n",
            "2915\n",
            "2916\n",
            "2917\n",
            "2918\n",
            "2919\n",
            "2920\n",
            "2921\n",
            "2922\n",
            "2923\n",
            "2924\n",
            "2925\n",
            "2926\n",
            "2927\n",
            "2928\n",
            "2929\n",
            "2930\n",
            "2931\n",
            "2932\n",
            "2933\n",
            "2934\n",
            "2935\n",
            "2936\n",
            "2937\n",
            "2938\n",
            "2939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j0louJAQDe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\",p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVVGbLn1QH4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "P=np.load(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfEiK9xQL1y",
        "colab_type": "code",
        "outputId": "ce529b9c-ae93-4efe-8e0a-75cd5bdb4424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(np.min(P))\n",
        "print(np.max(P))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArgXhZ3vQR3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl-8ucoDQVHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVHAm_aRQZF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y=[]\n",
        "d_temp_1=[]\n",
        "d_temp_2=[]\n",
        "for i in range(len(Y[0])):\n",
        "  d_temp_1=[]\n",
        "  for j in range(len(Y[0][0])):\n",
        "    d_temp_2=[]\n",
        "    for k in range(len(Y[0][0][0])):\n",
        "      d_temp_2.append(0.)\n",
        "    d_temp_1.append(d_temp_2)\n",
        "  dummy_y.append(d_temp_1)\n",
        "Y_dummy=np.array(dummy_y, dtype='float32')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBVLaObnQchn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.load(\"drive/My Drive/MS_data/X_major_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAEwrmO_Qho4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GzOdkbBQlOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_x=[]\n",
        "d_temp_1=[]\n",
        "d_temp_2=[]\n",
        "for i in range(len(X[0])):\n",
        "  d_temp_1=[]\n",
        "  for j in range(len(X[0][0])):\n",
        "    d_temp_2=[]\n",
        "    for k in range(len(X[0][0][0])):\n",
        "      d_temp_2.append(0.)\n",
        "    d_temp_1.append(d_temp_2)\n",
        "  dummy_x.append(d_temp_1)\n",
        "X_dummy=np.array(dummy_x, dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9MMfmo0Qpgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Y=np.load(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\")\n",
        "X=np.load(\"drive/My Drive/MS_data/X_union_new.npy\")\n",
        "#r=np.load(\"drive/My Drive/MS_data/union_new_rec_after_removal.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mfUN-PIQsrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)\n",
        "#Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7FKC0iJQyFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extra=[0,1,6,4,6,0,5,0,4,3,1,3,3,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWHT4Z0KQ3ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext=np.array(extra,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpqoAmtnQ7FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s=np.sum(ext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-psePdqRADc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r=np.load(\"drive/My Drive/MS_data/major_new_rec_after_removal.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmZtGA9WREG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec=list(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXuDGYczRIWi",
        "colab_type": "code",
        "outputId": "648cad1b-cb6e-4be1-d7cd-95e3d9e35707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "j=0\n",
        "index=0\n",
        "for i in extra:\n",
        "  k=0\n",
        "  \n",
        "  print(i)\n",
        "  index=index+rec[j]\n",
        "  j+=1\n",
        "  while(k<i):\n",
        "    index=index+k\n",
        "    print(index)\n",
        "    index=int(index)\n",
        "    Y.insert(index,Y_dummy)\n",
        "    X.insert(index,X_dummy)\n",
        "\n",
        "    k+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "279.0\n",
            "6\n",
            "561.0\n",
            "562\n",
            "564\n",
            "567\n",
            "571\n",
            "576\n",
            "4\n",
            "844.0\n",
            "845\n",
            "847\n",
            "850\n",
            "6\n",
            "988.0\n",
            "989\n",
            "991\n",
            "994\n",
            "998\n",
            "1003\n",
            "0\n",
            "5\n",
            "1590.0\n",
            "1591\n",
            "1593\n",
            "1596\n",
            "1600\n",
            "0\n",
            "4\n",
            "2036.0\n",
            "2037\n",
            "2039\n",
            "2042\n",
            "3\n",
            "2183.0\n",
            "2184\n",
            "2186\n",
            "1\n",
            "2377.0\n",
            "3\n",
            "2598.0\n",
            "2599\n",
            "2601\n",
            "3\n",
            "2782.0\n",
            "2783\n",
            "2785\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACoDuskfRMzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec=list(r)\n",
        "X=list(X)\n",
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvBbBVSRSE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.array(X,dtype='float32')\n",
        "Y=np.array(Y,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKYORUg7Rjh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/Actual_X.npy\",X)\n",
        "np.save(\"drive/My Drive/MS_data/Actual_Y.npy\",Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOS6JbRwRXmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "Y=np.load(\"drive/My Drive/MS_data/Actual_X.npy\")\n",
        "X=np.load(\"drive/My Drive/MS_data/Actual_Y.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqFH9lvJRcIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_1=[]\n",
        "Y_1=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI5xa0e9RoEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=list(X)\n",
        "Y=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os1ofZLCRsH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_x_p=0\n",
        "length=8\n",
        "index_x=length\n",
        "index_y_p=0\n",
        "index_y=length\n",
        "x_temp=[]\n",
        "y_temp=[]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jiI2JqfRwWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while index_x<=len(X) and index_y<=len(Y):\n",
        "  x_temp=X[index_x_p:index_x]\n",
        "  y_temp=Y[index_y_p:index_y]\n",
        "  x_temp_1=np.array(x_temp,dtype='float32')\n",
        "  y_temp_1=np.array(y_temp,dtype='float32')\n",
        "  X_1.append(x_temp_1)\n",
        "  Y_1.append(y_temp_1)\n",
        "  index_y_p=index_y_p+length\n",
        "  index_x_p=index_x_p+length\n",
        "  index_x=index_x+length\n",
        "  index_y=index_y+length\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnfgOEloR2Lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_1=np.array(X_1,dtype='float32')\n",
        "Y_1=np.array(Y_1,dtype='float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSRevt5jR6ZQ",
        "colab_type": "code",
        "outputId": "406d1197-a7dd-4e21-fb65-7e16ebe3cfe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(np.min(Y_1))\n",
        "print(np.max(Y_1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xyCCjl1SCSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/train_X.npy\",X_1)\n",
        "np.save(\"drive/My Drive/MS_data/train_Y.npy\",Y_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq48JJRHSJ45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_1=np.load(\"drive/My Drive/MS_data/train_X.npy\")\n",
        "Y_1=np.load(\"drive/My Drive/MS_data/train_Y.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2otmup7LcUua",
        "colab_type": "code",
        "outputId": "828b1163-cce0-41a1-fc3f-81462d1769f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(372, 8, 256, 256, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52QZFyb9SOzV",
        "colab_type": "text"
      },
      "source": [
        "## Modelling and Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lciWn1uFSmIr",
        "colab_type": "code",
        "outputId": "d9e730d6-1e32-4563-b0a3-8f33fd507544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input ,BatchNormalization , Activation \n",
        "from keras.layers.convolutional import Conv3D, UpSampling3D\n",
        "from keras.layers.pooling import MaxPooling3D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "\n",
        "def Convolution(input_tensor,filters):\n",
        "    \n",
        "    x = Conv3D(filters=filters,kernel_size=(3, 3, 3),padding = 'same',strides=(1, 1, 1))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x) \n",
        "    return x\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "def model(input_shape):\n",
        "    \n",
        "    inputs = Input((input_shape))\n",
        "    \n",
        "    conv_1 = Convolution(inputs,32)                                                                                         # 8,256,256,32\n",
        "    \n",
        "    maxp_1 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_1)                            # 4,128,128,32    \n",
        "    conv_2 = Convolution(maxp_1,64)                                                                                         # 4,128,128,64\n",
        "    maxp_2 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_2)                            # 2,64,64,64\n",
        "    \n",
        "    conv_3 = Convolution(maxp_2,128)                                                                                        # 2,64,64,128\n",
        "    \n",
        "    maxp_3 = MaxPooling3D(pool_size = (2, 2, 2), strides = (2, 2, 2), padding = 'same') (conv_3)                            # 1,32,32,128 \n",
        "    \n",
        "    \n",
        "    conv_4 = Convolution(maxp_3,256)                                                                                        # 1,32,32,256\n",
        "   \n",
        "    upsample_5 = UpSampling3D((2, 2, 2)) (conv_4)                                                                           # 2,64,64,256\n",
        "\n",
        "    upsample_5 = concatenate([upsample_5, conv_3])                                                                          # 2,64,64,256+128\n",
        "    \n",
        "    conv_5 = Convolution(upsample_5,128)                                                                                    # 2,64,64,128\n",
        "    upsample_6 = UpSampling3D((2, 2, 2)) (conv_5)                                                                           # 4,128,128,128                                                                                \n",
        "    \n",
        "    upsample_6 = concatenate([upsample_6, conv_2])                                                                          # 4,128,128,128+64\n",
        "    \n",
        "    conv_6 = Convolution(upsample_6,64)                                                                                     # 4,128,128,64        \n",
        "    upsample_7 = UpSampling3D((2, 2, 2)) (conv_6)                                                                           # 8,256,256,64   \n",
        "    \n",
        "    upsample_7 = concatenate([upsample_7, conv_1])                                                                          # 8,256,256,64+32  \n",
        "\n",
        "    conv_8 = Convolution(upsample_7,32)                                                                                     # 8,256,256,32\n",
        "    \n",
        "    \n",
        "    outputs = Conv3D(1, (1, 1, 1), activation='sigmoid') (conv_8)\n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[outputs]) \n",
        "    \n",
        "    return model\n",
        "     \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFHeGHMFS4Do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Computing Dice_Coefficient\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Computing Precision \n",
        "def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "# Computing Sensitivity      \n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "# Computing Specificity\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wAeaan2S_X9",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2tk2hTcTHEK",
        "colab_type": "code",
        "outputId": "3fb3d5a9-e7ff-432d-f26d-94e574561e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv3D, UpSampling3D\n",
        "from tensorflow.keras.layers import MaxPooling3D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train , X_test, Y_train, Y_test = train_test_split(X_1, Y_1, test_size=0.15, random_state=32)\n",
        "\n",
        "\n",
        "# Loding the modified U-net \n",
        "model = model(input_shape = (8,256,256,5))\n",
        "model.summary()\n",
        "\n",
        "checkpointer = ModelCheckpoint('drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5', verbose=1)\n",
        "callback_list=[checkpointer]\n",
        "\n",
        "# Compiling the model\n",
        "k_adam=Adam(lr=0.001)\n",
        "model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n",
        "# Fitting the model over the data\n",
        "history = model.fit(X_train,Y_train,batch_size=8,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n",
        "\n",
        "# Saving the model\n",
        "model.save('drive/My Drive/MS_data/Modified_UNet_3D_Major.h5')\n",
        "history.history\n",
        "\n",
        "# Evaluating the model on the training and testing data \n",
        "model.evaluate(x=X_train, y=Y_train, batch_size=8 , verbose=1, sample_weight=None, steps=None)\n",
        "model.evaluate(x=X_test, y=Y_test, batch_size=8, verbose=1, sample_weight=None, steps=None)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 8, 256, 256, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 8, 256, 256,  4352        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 8, 256, 256,  128         conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 8, 256, 256,  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D)    (None, 4, 128, 128,  0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 4, 128, 128,  55360       max_pooling3d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 4, 128, 128,  256         conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 4, 128, 128,  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 2, 64, 64, 64 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 2, 64, 64, 12 221312      max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2, 64, 64, 12 512         conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 2, 64, 64, 12 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3D)  (None, 1, 32, 32, 12 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 1, 32, 32, 25 884992      max_pooling3d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1, 32, 32, 25 1024        conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1, 32, 32, 25 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d (UpSampling3D)    (None, 2, 64, 64, 25 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2, 64, 64, 38 0           up_sampling3d[0][0]              \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 2, 64, 64, 12 1327232     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 2, 64, 64, 12 512         conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 2, 64, 64, 12 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_1 (UpSampling3D)  (None, 4, 128, 128,  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 128, 128,  0           up_sampling3d_1[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 4, 128, 128,  331840      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 4, 128, 128,  256         conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 4, 128, 128,  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_2 (UpSampling3D)  (None, 8, 256, 256,  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 256, 256,  0           up_sampling3d_2[0][0]            \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 8, 256, 256,  82976       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 256, 256,  128         conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 256, 256,  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 8, 256, 256,  33          activation_6[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,910,913\n",
            "Trainable params: 2,909,505\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.8585 - dice_coef: 0.0220 - precision: 0.3122 - sensitivity: 0.7595 - specificity: 0.8612\n",
            "Epoch 00001: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 36s 1s/step - loss: 0.5052 - accuracy: 0.8585 - dice_coef: 0.0220 - precision: 0.3122 - sensitivity: 0.7595 - specificity: 0.8612 - val_loss: 0.5487 - val_accuracy: 0.8946 - val_dice_coef: 0.0143 - val_precision: 0.0248 - val_sensitivity: 0.3905 - val_specificity: 0.8980\n",
            "Epoch 2/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.9967 - dice_coef: 0.0324 - precision: 0.6214 - sensitivity: 0.7352 - specificity: 0.9981\n",
            "Epoch 00002: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.2741 - accuracy: 0.9967 - dice_coef: 0.0324 - precision: 0.6214 - sensitivity: 0.7352 - specificity: 0.9981 - val_loss: 0.2716 - val_accuracy: 0.9939 - val_dice_coef: 0.0201 - val_precision: 0.5201 - val_sensitivity: 0.3188 - val_specificity: 0.9983\n",
            "Epoch 3/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.9974 - dice_coef: 0.0414 - precision: 0.7010 - sensitivity: 0.7151 - specificity: 0.9988\n",
            "Epoch 00003: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.1872 - accuracy: 0.9974 - dice_coef: 0.0414 - precision: 0.7010 - sensitivity: 0.7151 - specificity: 0.9988 - val_loss: 0.1909 - val_accuracy: 0.9962 - val_dice_coef: 0.0392 - val_precision: 0.8646 - val_sensitivity: 0.4774 - val_specificity: 0.9995\n",
            "Epoch 4/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9977 - dice_coef: 0.0547 - precision: 0.7710 - sensitivity: 0.6617 - specificity: 0.9993\n",
            "Epoch 00004: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.1296 - accuracy: 0.9977 - dice_coef: 0.0547 - precision: 0.7710 - sensitivity: 0.6617 - specificity: 0.9993 - val_loss: 0.1465 - val_accuracy: 0.9969 - val_dice_coef: 0.0609 - val_precision: 0.8358 - val_sensitivity: 0.6668 - val_specificity: 0.9991\n",
            "Epoch 5/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9977 - dice_coef: 0.0723 - precision: 0.8263 - sensitivity: 0.6664 - specificity: 0.9994\n",
            "Epoch 00005: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0946 - accuracy: 0.9977 - dice_coef: 0.0723 - precision: 0.8263 - sensitivity: 0.6664 - specificity: 0.9994 - val_loss: 0.1117 - val_accuracy: 0.9972 - val_dice_coef: 0.0786 - val_precision: 0.8641 - val_sensitivity: 0.6679 - val_specificity: 0.9993\n",
            "Epoch 6/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9978 - dice_coef: 0.0916 - precision: 0.8318 - sensitivity: 0.6662 - specificity: 0.9995\n",
            "Epoch 00006: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0719 - accuracy: 0.9978 - dice_coef: 0.0916 - precision: 0.8318 - sensitivity: 0.6662 - specificity: 0.9995 - val_loss: 0.0861 - val_accuracy: 0.9971 - val_dice_coef: 0.1052 - val_precision: 0.7989 - val_sensitivity: 0.7382 - val_specificity: 0.9988\n",
            "Epoch 7/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9978 - dice_coef: 0.1114 - precision: 0.8278 - sensitivity: 0.6588 - specificity: 0.9994\n",
            "Epoch 00007: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 38s 1s/step - loss: 0.0568 - accuracy: 0.9978 - dice_coef: 0.1114 - precision: 0.8278 - sensitivity: 0.6588 - specificity: 0.9994 - val_loss: 0.0618 - val_accuracy: 0.9972 - val_dice_coef: 0.1408 - val_precision: 0.8085 - val_sensitivity: 0.7492 - val_specificity: 0.9988\n",
            "Epoch 8/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9978 - dice_coef: 0.1322 - precision: 0.8397 - sensitivity: 0.6557 - specificity: 0.9995\n",
            "Epoch 00008: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0460 - accuracy: 0.9978 - dice_coef: 0.1322 - precision: 0.8397 - sensitivity: 0.6557 - specificity: 0.9995 - val_loss: 0.0488 - val_accuracy: 0.9972 - val_dice_coef: 0.1641 - val_precision: 0.8336 - val_sensitivity: 0.7002 - val_specificity: 0.9991\n",
            "Epoch 9/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9978 - dice_coef: 0.1516 - precision: 0.8223 - sensitivity: 0.6658 - specificity: 0.9994\n",
            "Epoch 00009: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0378 - accuracy: 0.9978 - dice_coef: 0.1516 - precision: 0.8223 - sensitivity: 0.6658 - specificity: 0.9994 - val_loss: 0.0380 - val_accuracy: 0.9971 - val_dice_coef: 0.1834 - val_precision: 0.9118 - val_sensitivity: 0.6012 - val_specificity: 0.9996\n",
            "Epoch 10/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9978 - dice_coef: 0.1762 - precision: 0.8442 - sensitivity: 0.6566 - specificity: 0.9995\n",
            "Epoch 00010: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0323 - accuracy: 0.9978 - dice_coef: 0.1762 - precision: 0.8442 - sensitivity: 0.6566 - specificity: 0.9995 - val_loss: 0.0316 - val_accuracy: 0.9973 - val_dice_coef: 0.2364 - val_precision: 0.8530 - val_sensitivity: 0.7054 - val_specificity: 0.9992\n",
            "Epoch 11/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9978 - dice_coef: 0.1915 - precision: 0.8232 - sensitivity: 0.6488 - specificity: 0.9995\n",
            "Epoch 00011: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0276 - accuracy: 0.9978 - dice_coef: 0.1915 - precision: 0.8232 - sensitivity: 0.6488 - specificity: 0.9995 - val_loss: 0.0275 - val_accuracy: 0.9973 - val_dice_coef: 0.2562 - val_precision: 0.8758 - val_sensitivity: 0.6792 - val_specificity: 0.9994\n",
            "Epoch 12/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9979 - dice_coef: 0.2275 - precision: 0.8510 - sensitivity: 0.6649 - specificity: 0.9995\n",
            "Epoch 00012: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0242 - accuracy: 0.9979 - dice_coef: 0.2275 - precision: 0.8510 - sensitivity: 0.6649 - specificity: 0.9995 - val_loss: 0.0247 - val_accuracy: 0.9973 - val_dice_coef: 0.2876 - val_precision: 0.8443 - val_sensitivity: 0.7062 - val_specificity: 0.9991\n",
            "Epoch 13/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9979 - dice_coef: 0.2439 - precision: 0.8445 - sensitivity: 0.6787 - specificity: 0.9995\n",
            "Epoch 00013: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0219 - accuracy: 0.9979 - dice_coef: 0.2439 - precision: 0.8445 - sensitivity: 0.6787 - specificity: 0.9995 - val_loss: 0.0217 - val_accuracy: 0.9973 - val_dice_coef: 0.3238 - val_precision: 0.8304 - val_sensitivity: 0.7281 - val_specificity: 0.9990\n",
            "Epoch 14/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9979 - dice_coef: 0.2537 - precision: 0.8316 - sensitivity: 0.6545 - specificity: 0.9995\n",
            "Epoch 00014: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0197 - accuracy: 0.9979 - dice_coef: 0.2537 - precision: 0.8316 - sensitivity: 0.6545 - specificity: 0.9995 - val_loss: 0.0181 - val_accuracy: 0.9974 - val_dice_coef: 0.3646 - val_precision: 0.8629 - val_sensitivity: 0.7028 - val_specificity: 0.9992\n",
            "Epoch 15/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9979 - dice_coef: 0.2881 - precision: 0.8422 - sensitivity: 0.6590 - specificity: 0.9995\n",
            "Epoch 00015: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0179 - accuracy: 0.9979 - dice_coef: 0.2881 - precision: 0.8422 - sensitivity: 0.6590 - specificity: 0.9995 - val_loss: 0.0162 - val_accuracy: 0.9973 - val_dice_coef: 0.3893 - val_precision: 0.8856 - val_sensitivity: 0.6727 - val_specificity: 0.9994\n",
            "Epoch 16/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9979 - dice_coef: 0.2887 - precision: 0.8278 - sensitivity: 0.6647 - specificity: 0.9995\n",
            "Epoch 00016: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0164 - accuracy: 0.9979 - dice_coef: 0.2887 - precision: 0.8278 - sensitivity: 0.6647 - specificity: 0.9995 - val_loss: 0.0154 - val_accuracy: 0.9974 - val_dice_coef: 0.4002 - val_precision: 0.8907 - val_sensitivity: 0.6821 - val_specificity: 0.9994\n",
            "Epoch 17/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9980 - dice_coef: 0.3218 - precision: 0.8528 - sensitivity: 0.6671 - specificity: 0.9995\n",
            "Epoch 00017: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0151 - accuracy: 0.9980 - dice_coef: 0.3218 - precision: 0.8528 - sensitivity: 0.6671 - specificity: 0.9995 - val_loss: 0.0152 - val_accuracy: 0.9972 - val_dice_coef: 0.4258 - val_precision: 0.8205 - val_sensitivity: 0.7364 - val_specificity: 0.9989\n",
            "Epoch 18/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9979 - dice_coef: 0.3413 - precision: 0.8562 - sensitivity: 0.6716 - specificity: 0.9995\n",
            "Epoch 00018: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0144 - accuracy: 0.9979 - dice_coef: 0.3413 - precision: 0.8562 - sensitivity: 0.6716 - specificity: 0.9995 - val_loss: 0.0138 - val_accuracy: 0.9974 - val_dice_coef: 0.4525 - val_precision: 0.8484 - val_sensitivity: 0.7314 - val_specificity: 0.9991\n",
            "Epoch 19/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9979 - dice_coef: 0.3625 - precision: 0.8458 - sensitivity: 0.6801 - specificity: 0.9995\n",
            "Epoch 00019: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0134 - accuracy: 0.9979 - dice_coef: 0.3625 - precision: 0.8458 - sensitivity: 0.6801 - specificity: 0.9995 - val_loss: 0.0135 - val_accuracy: 0.9973 - val_dice_coef: 0.4329 - val_precision: 0.9029 - val_sensitivity: 0.6444 - val_specificity: 0.9995\n",
            "Epoch 20/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9980 - dice_coef: 0.3698 - precision: 0.8562 - sensitivity: 0.6657 - specificity: 0.9995\n",
            "Epoch 00020: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0126 - accuracy: 0.9980 - dice_coef: 0.3698 - precision: 0.8562 - sensitivity: 0.6657 - specificity: 0.9995 - val_loss: 0.0132 - val_accuracy: 0.9974 - val_dice_coef: 0.4695 - val_precision: 0.8467 - val_sensitivity: 0.7272 - val_specificity: 0.9991\n",
            "Epoch 21/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9979 - dice_coef: 0.3689 - precision: 0.8440 - sensitivity: 0.6643 - specificity: 0.9994\n",
            "Epoch 00021: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0122 - accuracy: 0.9979 - dice_coef: 0.3689 - precision: 0.8440 - sensitivity: 0.6643 - specificity: 0.9994 - val_loss: 0.0129 - val_accuracy: 0.9974 - val_dice_coef: 0.4765 - val_precision: 0.8743 - val_sensitivity: 0.6871 - val_specificity: 0.9993\n",
            "Epoch 22/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9978 - dice_coef: 0.3845 - precision: 0.8356 - sensitivity: 0.6770 - specificity: 0.9994\n",
            "Epoch 00022: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0121 - accuracy: 0.9978 - dice_coef: 0.3845 - precision: 0.8356 - sensitivity: 0.6770 - specificity: 0.9994 - val_loss: 0.0145 - val_accuracy: 0.9966 - val_dice_coef: 0.3913 - val_precision: 0.9618 - val_sensitivity: 0.4802 - val_specificity: 0.9999\n",
            "Epoch 23/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9979 - dice_coef: 0.3969 - precision: 0.8513 - sensitivity: 0.6701 - specificity: 0.9995\n",
            "Epoch 00023: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0115 - accuracy: 0.9979 - dice_coef: 0.3969 - precision: 0.8513 - sensitivity: 0.6701 - specificity: 0.9995 - val_loss: 0.0122 - val_accuracy: 0.9974 - val_dice_coef: 0.4861 - val_precision: 0.8794 - val_sensitivity: 0.6915 - val_specificity: 0.9993\n",
            "Epoch 24/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9980 - dice_coef: 0.4244 - precision: 0.8519 - sensitivity: 0.6885 - specificity: 0.9995\n",
            "Epoch 00024: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0109 - accuracy: 0.9980 - dice_coef: 0.4244 - precision: 0.8519 - sensitivity: 0.6885 - specificity: 0.9995 - val_loss: 0.0119 - val_accuracy: 0.9974 - val_dice_coef: 0.5130 - val_precision: 0.8543 - val_sensitivity: 0.7197 - val_specificity: 0.9992\n",
            "Epoch 25/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9980 - dice_coef: 0.4337 - precision: 0.8469 - sensitivity: 0.6734 - specificity: 0.9995\n",
            "Epoch 00025: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0102 - accuracy: 0.9980 - dice_coef: 0.4337 - precision: 0.8469 - sensitivity: 0.6734 - specificity: 0.9995 - val_loss: 0.0116 - val_accuracy: 0.9974 - val_dice_coef: 0.5072 - val_precision: 0.8479 - val_sensitivity: 0.7313 - val_specificity: 0.9991\n",
            "Epoch 26/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9980 - dice_coef: 0.4721 - precision: 0.8786 - sensitivity: 0.6799 - specificity: 0.9995\n",
            "Epoch 00026: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0099 - accuracy: 0.9980 - dice_coef: 0.4721 - precision: 0.8786 - sensitivity: 0.6799 - specificity: 0.9995 - val_loss: 0.0111 - val_accuracy: 0.9973 - val_dice_coef: 0.5316 - val_precision: 0.8329 - val_sensitivity: 0.7354 - val_specificity: 0.9990\n",
            "Epoch 27/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9980 - dice_coef: 0.4522 - precision: 0.8568 - sensitivity: 0.6794 - specificity: 0.9995\n",
            "Epoch 00027: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0094 - accuracy: 0.9980 - dice_coef: 0.4522 - precision: 0.8568 - sensitivity: 0.6794 - specificity: 0.9995 - val_loss: 0.0102 - val_accuracy: 0.9975 - val_dice_coef: 0.5554 - val_precision: 0.8774 - val_sensitivity: 0.7133 - val_specificity: 0.9993\n",
            "Epoch 28/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9980 - dice_coef: 0.4722 - precision: 0.8582 - sensitivity: 0.6789 - specificity: 0.9995\n",
            "Epoch 00028: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0092 - accuracy: 0.9980 - dice_coef: 0.4722 - precision: 0.8582 - sensitivity: 0.6789 - specificity: 0.9995 - val_loss: 0.0102 - val_accuracy: 0.9975 - val_dice_coef: 0.5422 - val_precision: 0.8776 - val_sensitivity: 0.7215 - val_specificity: 0.9993\n",
            "Epoch 29/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9980 - dice_coef: 0.4634 - precision: 0.8437 - sensitivity: 0.6915 - specificity: 0.9995\n",
            "Epoch 00029: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0090 - accuracy: 0.9980 - dice_coef: 0.4634 - precision: 0.8437 - sensitivity: 0.6915 - specificity: 0.9995 - val_loss: 0.0100 - val_accuracy: 0.9974 - val_dice_coef: 0.5677 - val_precision: 0.8298 - val_sensitivity: 0.7702 - val_specificity: 0.9988\n",
            "Epoch 30/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9979 - dice_coef: 0.4878 - precision: 0.8705 - sensitivity: 0.6597 - specificity: 0.9994\n",
            "Epoch 00030: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0090 - accuracy: 0.9979 - dice_coef: 0.4878 - precision: 0.8705 - sensitivity: 0.6597 - specificity: 0.9994 - val_loss: 0.0097 - val_accuracy: 0.9974 - val_dice_coef: 0.5781 - val_precision: 0.8505 - val_sensitivity: 0.7370 - val_specificity: 0.9991\n",
            "Epoch 31/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9981 - dice_coef: 0.5020 - precision: 0.8394 - sensitivity: 0.6838 - specificity: 0.9995\n",
            "Epoch 00031: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0086 - accuracy: 0.9981 - dice_coef: 0.5020 - precision: 0.8394 - sensitivity: 0.6838 - specificity: 0.9995 - val_loss: 0.0096 - val_accuracy: 0.9974 - val_dice_coef: 0.5729 - val_precision: 0.8678 - val_sensitivity: 0.7295 - val_specificity: 0.9992\n",
            "Epoch 32/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9980 - dice_coef: 0.5159 - precision: 0.8621 - sensitivity: 0.6998 - specificity: 0.9995\n",
            "Epoch 00032: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0086 - accuracy: 0.9980 - dice_coef: 0.5159 - precision: 0.8621 - sensitivity: 0.6998 - specificity: 0.9995 - val_loss: 0.0099 - val_accuracy: 0.9974 - val_dice_coef: 0.5670 - val_precision: 0.8568 - val_sensitivity: 0.7233 - val_specificity: 0.9992\n",
            "Epoch 33/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9981 - dice_coef: 0.5108 - precision: 0.8801 - sensitivity: 0.6690 - specificity: 0.9995\n",
            "Epoch 00033: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0083 - accuracy: 0.9981 - dice_coef: 0.5108 - precision: 0.8801 - sensitivity: 0.6690 - specificity: 0.9995 - val_loss: 0.0094 - val_accuracy: 0.9975 - val_dice_coef: 0.6035 - val_precision: 0.8251 - val_sensitivity: 0.7795 - val_specificity: 0.9989\n",
            "Epoch 34/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9981 - dice_coef: 0.5204 - precision: 0.8511 - sensitivity: 0.7095 - specificity: 0.9994\n",
            "Epoch 00034: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0081 - accuracy: 0.9981 - dice_coef: 0.5204 - precision: 0.8511 - sensitivity: 0.7095 - specificity: 0.9994 - val_loss: 0.0092 - val_accuracy: 0.9975 - val_dice_coef: 0.5985 - val_precision: 0.8734 - val_sensitivity: 0.7222 - val_specificity: 0.9993\n",
            "Epoch 35/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9981 - dice_coef: 0.5433 - precision: 0.8604 - sensitivity: 0.7058 - specificity: 0.9995\n",
            "Epoch 00035: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0079 - accuracy: 0.9981 - dice_coef: 0.5433 - precision: 0.8604 - sensitivity: 0.7058 - specificity: 0.9995 - val_loss: 0.0088 - val_accuracy: 0.9975 - val_dice_coef: 0.6103 - val_precision: 0.8861 - val_sensitivity: 0.7137 - val_specificity: 0.9993\n",
            "Epoch 36/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9981 - dice_coef: 0.5330 - precision: 0.8496 - sensitivity: 0.6986 - specificity: 0.9994\n",
            "Epoch 00036: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0078 - accuracy: 0.9981 - dice_coef: 0.5330 - precision: 0.8496 - sensitivity: 0.6986 - specificity: 0.9994 - val_loss: 0.0087 - val_accuracy: 0.9976 - val_dice_coef: 0.6147 - val_precision: 0.8679 - val_sensitivity: 0.7461 - val_specificity: 0.9992\n",
            "Epoch 37/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9981 - dice_coef: 0.5381 - precision: 0.8659 - sensitivity: 0.7032 - specificity: 0.9995\n",
            "Epoch 00037: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0078 - accuracy: 0.9981 - dice_coef: 0.5381 - precision: 0.8659 - sensitivity: 0.7032 - specificity: 0.9995 - val_loss: 0.0089 - val_accuracy: 0.9975 - val_dice_coef: 0.6193 - val_precision: 0.8974 - val_sensitivity: 0.6989 - val_specificity: 0.9995\n",
            "Epoch 38/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9981 - dice_coef: 0.5559 - precision: 0.8700 - sensitivity: 0.6997 - specificity: 0.9995\n",
            "Epoch 00038: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0074 - accuracy: 0.9981 - dice_coef: 0.5559 - precision: 0.8700 - sensitivity: 0.6997 - specificity: 0.9995 - val_loss: 0.0086 - val_accuracy: 0.9976 - val_dice_coef: 0.6283 - val_precision: 0.8600 - val_sensitivity: 0.7497 - val_specificity: 0.9992\n",
            "Epoch 39/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9981 - dice_coef: 0.5543 - precision: 0.8569 - sensitivity: 0.7125 - specificity: 0.9995\n",
            "Epoch 00039: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 40s 1s/step - loss: 0.0073 - accuracy: 0.9981 - dice_coef: 0.5543 - precision: 0.8569 - sensitivity: 0.7125 - specificity: 0.9995 - val_loss: 0.0085 - val_accuracy: 0.9976 - val_dice_coef: 0.6208 - val_precision: 0.8865 - val_sensitivity: 0.7132 - val_specificity: 0.9994\n",
            "Epoch 40/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9981 - dice_coef: 0.5429 - precision: 0.8522 - sensitivity: 0.6831 - specificity: 0.9995\n",
            "Epoch 00040: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0073 - accuracy: 0.9981 - dice_coef: 0.5429 - precision: 0.8522 - sensitivity: 0.6831 - specificity: 0.9995 - val_loss: 0.0088 - val_accuracy: 0.9975 - val_dice_coef: 0.6073 - val_precision: 0.8888 - val_sensitivity: 0.6952 - val_specificity: 0.9994\n",
            "Epoch 41/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9981 - dice_coef: 0.5566 - precision: 0.8475 - sensitivity: 0.7083 - specificity: 0.9995\n",
            "Epoch 00041: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0073 - accuracy: 0.9981 - dice_coef: 0.5566 - precision: 0.8475 - sensitivity: 0.7083 - specificity: 0.9995 - val_loss: 0.0083 - val_accuracy: 0.9976 - val_dice_coef: 0.6544 - val_precision: 0.8750 - val_sensitivity: 0.7439 - val_specificity: 0.9992\n",
            "Epoch 42/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9982 - dice_coef: 0.5636 - precision: 0.8711 - sensitivity: 0.6973 - specificity: 0.9995\n",
            "Epoch 00042: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0071 - accuracy: 0.9982 - dice_coef: 0.5636 - precision: 0.8711 - sensitivity: 0.6973 - specificity: 0.9995 - val_loss: 0.0086 - val_accuracy: 0.9976 - val_dice_coef: 0.6432 - val_precision: 0.8498 - val_sensitivity: 0.7704 - val_specificity: 0.9991\n",
            "Epoch 43/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9982 - dice_coef: 0.5531 - precision: 0.8499 - sensitivity: 0.7054 - specificity: 0.9995\n",
            "Epoch 00043: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0070 - accuracy: 0.9982 - dice_coef: 0.5531 - precision: 0.8499 - sensitivity: 0.7054 - specificity: 0.9995 - val_loss: 0.0082 - val_accuracy: 0.9976 - val_dice_coef: 0.6382 - val_precision: 0.8672 - val_sensitivity: 0.7469 - val_specificity: 0.9992\n",
            "Epoch 44/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9982 - dice_coef: 0.5749 - precision: 0.8610 - sensitivity: 0.7097 - specificity: 0.9995\n",
            "Epoch 00044: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0069 - accuracy: 0.9982 - dice_coef: 0.5749 - precision: 0.8610 - sensitivity: 0.7097 - specificity: 0.9995 - val_loss: 0.0082 - val_accuracy: 0.9976 - val_dice_coef: 0.6401 - val_precision: 0.8937 - val_sensitivity: 0.7205 - val_specificity: 0.9994\n",
            "Epoch 45/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9982 - dice_coef: 0.5659 - precision: 0.8723 - sensitivity: 0.6952 - specificity: 0.9995\n",
            "Epoch 00045: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0069 - accuracy: 0.9982 - dice_coef: 0.5659 - precision: 0.8723 - sensitivity: 0.6952 - specificity: 0.9995 - val_loss: 0.0085 - val_accuracy: 0.9974 - val_dice_coef: 0.6563 - val_precision: 0.8116 - val_sensitivity: 0.8069 - val_specificity: 0.9987\n",
            "Epoch 46/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982 - dice_coef: 0.5883 - precision: 0.8584 - sensitivity: 0.7210 - specificity: 0.9995\n",
            "Epoch 00046: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0068 - accuracy: 0.9982 - dice_coef: 0.5883 - precision: 0.8584 - sensitivity: 0.7210 - specificity: 0.9995 - val_loss: 0.0086 - val_accuracy: 0.9976 - val_dice_coef: 0.6456 - val_precision: 0.9012 - val_sensitivity: 0.7033 - val_specificity: 0.9995\n",
            "Epoch 47/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9979 - dice_coef: 0.5680 - precision: 0.8445 - sensitivity: 0.6908 - specificity: 0.9994\n",
            "Epoch 00047: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0077 - accuracy: 0.9979 - dice_coef: 0.5680 - precision: 0.8445 - sensitivity: 0.6908 - specificity: 0.9994 - val_loss: 0.0087 - val_accuracy: 0.9975 - val_dice_coef: 0.6282 - val_precision: 0.8695 - val_sensitivity: 0.7226 - val_specificity: 0.9993\n",
            "Epoch 48/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9980 - dice_coef: 0.5608 - precision: 0.8475 - sensitivity: 0.6760 - specificity: 0.9995\n",
            "Epoch 00048: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0072 - accuracy: 0.9980 - dice_coef: 0.5608 - precision: 0.8475 - sensitivity: 0.6760 - specificity: 0.9995 - val_loss: 0.0087 - val_accuracy: 0.9975 - val_dice_coef: 0.5989 - val_precision: 0.8637 - val_sensitivity: 0.7383 - val_specificity: 0.9992\n",
            "Epoch 49/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981 - dice_coef: 0.5660 - precision: 0.8502 - sensitivity: 0.6898 - specificity: 0.9995\n",
            "Epoch 00049: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0067 - accuracy: 0.9981 - dice_coef: 0.5660 - precision: 0.8502 - sensitivity: 0.6898 - specificity: 0.9995 - val_loss: 0.0088 - val_accuracy: 0.9976 - val_dice_coef: 0.5932 - val_precision: 0.8946 - val_sensitivity: 0.7045 - val_specificity: 0.9994\n",
            "Epoch 50/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980 - dice_coef: 0.5723 - precision: 0.8660 - sensitivity: 0.6765 - specificity: 0.9995\n",
            "Epoch 00050: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0069 - accuracy: 0.9980 - dice_coef: 0.5723 - precision: 0.8660 - sensitivity: 0.6765 - specificity: 0.9995 - val_loss: 0.0087 - val_accuracy: 0.9974 - val_dice_coef: 0.6156 - val_precision: 0.9235 - val_sensitivity: 0.6535 - val_specificity: 0.9996\n",
            "Epoch 51/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981 - dice_coef: 0.6014 - precision: 0.8564 - sensitivity: 0.7089 - specificity: 0.9995\n",
            "Epoch 00051: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0066 - accuracy: 0.9981 - dice_coef: 0.6014 - precision: 0.8564 - sensitivity: 0.7089 - specificity: 0.9995 - val_loss: 0.0081 - val_accuracy: 0.9976 - val_dice_coef: 0.6458 - val_precision: 0.8817 - val_sensitivity: 0.7237 - val_specificity: 0.9993\n",
            "Epoch 52/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982 - dice_coef: 0.6088 - precision: 0.8658 - sensitivity: 0.7159 - specificity: 0.9995\n",
            "Epoch 00052: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0064 - accuracy: 0.9982 - dice_coef: 0.6088 - precision: 0.8658 - sensitivity: 0.7159 - specificity: 0.9995 - val_loss: 0.0080 - val_accuracy: 0.9976 - val_dice_coef: 0.6691 - val_precision: 0.8629 - val_sensitivity: 0.7550 - val_specificity: 0.9992\n",
            "Epoch 53/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982 - dice_coef: 0.5827 - precision: 0.8371 - sensitivity: 0.6837 - specificity: 0.9995\n",
            "Epoch 00053: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0061 - accuracy: 0.9982 - dice_coef: 0.5827 - precision: 0.8371 - sensitivity: 0.6837 - specificity: 0.9995 - val_loss: 0.0081 - val_accuracy: 0.9975 - val_dice_coef: 0.6780 - val_precision: 0.8798 - val_sensitivity: 0.7265 - val_specificity: 0.9992\n",
            "Epoch 54/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981 - dice_coef: 0.5972 - precision: 0.8659 - sensitivity: 0.6917 - specificity: 0.9995\n",
            "Epoch 00054: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0067 - accuracy: 0.9981 - dice_coef: 0.5972 - precision: 0.8659 - sensitivity: 0.6917 - specificity: 0.9995 - val_loss: 0.0082 - val_accuracy: 0.9974 - val_dice_coef: 0.6348 - val_precision: 0.8643 - val_sensitivity: 0.7230 - val_specificity: 0.9991\n",
            "Epoch 55/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9980 - dice_coef: 0.5988 - precision: 0.8617 - sensitivity: 0.6882 - specificity: 0.9994\n",
            "Epoch 00055: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0067 - accuracy: 0.9980 - dice_coef: 0.5988 - precision: 0.8617 - sensitivity: 0.6882 - specificity: 0.9994 - val_loss: 0.0081 - val_accuracy: 0.9975 - val_dice_coef: 0.6809 - val_precision: 0.8258 - val_sensitivity: 0.7906 - val_specificity: 0.9989\n",
            "Epoch 56/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9982 - dice_coef: 0.5983 - precision: 0.8615 - sensitivity: 0.7015 - specificity: 0.9995\n",
            "Epoch 00056: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0062 - accuracy: 0.9982 - dice_coef: 0.5983 - precision: 0.8615 - sensitivity: 0.7015 - specificity: 0.9995 - val_loss: 0.0080 - val_accuracy: 0.9976 - val_dice_coef: 0.6707 - val_precision: 0.8506 - val_sensitivity: 0.7784 - val_specificity: 0.9991\n",
            "Epoch 57/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9982 - dice_coef: 0.6140 - precision: 0.8779 - sensitivity: 0.6867 - specificity: 0.9995\n",
            "Epoch 00057: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0060 - accuracy: 0.9982 - dice_coef: 0.6140 - precision: 0.8779 - sensitivity: 0.6867 - specificity: 0.9995 - val_loss: 0.0082 - val_accuracy: 0.9976 - val_dice_coef: 0.6417 - val_precision: 0.8542 - val_sensitivity: 0.7727 - val_specificity: 0.9991\n",
            "Epoch 58/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982 - dice_coef: 0.6026 - precision: 0.8668 - sensitivity: 0.6806 - specificity: 0.9995\n",
            "Epoch 00058: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0061 - accuracy: 0.9982 - dice_coef: 0.6026 - precision: 0.8668 - sensitivity: 0.6806 - specificity: 0.9995 - val_loss: 0.0079 - val_accuracy: 0.9976 - val_dice_coef: 0.6701 - val_precision: 0.8696 - val_sensitivity: 0.7484 - val_specificity: 0.9992\n",
            "Epoch 59/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982 - dice_coef: 0.6376 - precision: 0.8743 - sensitivity: 0.7119 - specificity: 0.9995\n",
            "Epoch 00059: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0058 - accuracy: 0.9982 - dice_coef: 0.6376 - precision: 0.8743 - sensitivity: 0.7119 - specificity: 0.9995 - val_loss: 0.0080 - val_accuracy: 0.9976 - val_dice_coef: 0.6933 - val_precision: 0.8597 - val_sensitivity: 0.7537 - val_specificity: 0.9992\n",
            "Epoch 60/60\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982 - dice_coef: 0.6011 - precision: 0.8651 - sensitivity: 0.6819 - specificity: 0.9995\n",
            "Epoch 00060: saving model to drive/My Drive/MS_data/Modified_UNet_3D_Major_ckpt.h5\n",
            "32/32 [==============================] - 33s 1s/step - loss: 0.0059 - accuracy: 0.9982 - dice_coef: 0.6011 - precision: 0.8651 - sensitivity: 0.6819 - specificity: 0.9995 - val_loss: 0.0078 - val_accuracy: 0.9976 - val_dice_coef: 0.6920 - val_precision: 0.8660 - val_sensitivity: 0.7579 - val_specificity: 0.9992\n",
            "40/40 [==============================] - 12s 301ms/step - loss: 0.0061 - accuracy: 0.9981 - dice_coef: 0.6667 - precision: 0.8776 - sensitivity: 0.7306 - specificity: 0.9995\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0078 - accuracy: 0.9977 - dice_coef: 0.7346 - precision: 0.8734 - sensitivity: 0.8038 - specificity: 0.9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00780336232855916,\n",
              " 0.9977254867553711,\n",
              " 0.7346310019493103,\n",
              " 0.8733747601509094,\n",
              " 0.8037696480751038,\n",
              " 0.9991928339004517]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LopP5OxuceTj",
        "colab_type": "code",
        "outputId": "cf82d0f1-2ce8-4549-d082-f4b58b5be84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(316, 8, 256, 256, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqR3PxQMTShu",
        "colab_type": "text"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h3Xf9_LTcjq",
        "colab_type": "code",
        "outputId": "d0f2888c-296c-42e1-d81e-845a64c5d061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy vs Epoch\n",
        "def Accuracy_Graph(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    #plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "    \n",
        "# Dice Similarity Coefficient vs Epoch\n",
        "def Dice_coefficient_Graph(history):\n",
        "\n",
        "    plt.plot(history.history['dice_coef'])\n",
        "    plt.plot(history.history['val_dice_coef'])\n",
        "    #plt.title('Dice_Coefficient')\n",
        "    plt.ylabel('Dice_Coefficient')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "# Loss vs Epoch\n",
        "def Loss_Graph(history):\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    #plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                        wspace=0.35)\n",
        "    plt.show()\n",
        "Accuracy_Graph(history)\n",
        "Dice_coefficient_Graph(history)\n",
        "Loss_Graph(history)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bda81cf1d8c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                         wspace=0.35)\n\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mAccuracy_Graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mDice_coefficient_Graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mLoss_Graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    }
  ]
}