{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Multiple_sclerosis.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iXEF04sFLd1x","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukd9xzX0Liwy","colab_type":"code","outputId":"d8e18e46-e987-4981-cffd-34b8a13f1d98","executionInfo":{"status":"ok","timestamp":1584073315397,"user_tz":-330,"elapsed":388966,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Jan  7 12:32:05 2019\n","\n","@author: Krishna\n","\"\"\"\n","# Importing neccessary packages\n","import h5py\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import nibabel as nib\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","p=os.listdir(Path)\n","\n","X_Dp=[]          \n","X_Gado=[]\n","X_Flair=[]      \n","X_T1=[]\n","X_T2=[]\n","Y_Man1=[]\n","\n","X=[]\n","Y1=[]\n","\n","# Loading the MRI Scans \n","for i in p[0:14] :\n","    \n","    q=os.listdir(os.path.join(Path,i))  \n","    \n","    x=nib.load(os.path.join(Path,i,q[0]))         \n","    f_Dp=x.get_fdata()\n","    f_Dp=np.asarray(f_Dp,'float32')\n","    for j in range(f_Dp.shape[2]):\n","        slice_Dp=cv.resize(f_Dp[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","        if(np.sum(slice_Dp)!=0):\n","          #  slice_Dp=slice_Dp/(np.max(slice_Dp)+0.00001)\n","            slice_Dp=(slice_Dp-np.mean(slice_Dp)+0.00001)/(np.std(slice_Dp)+0.00001)\n","        X_Dp.append(slice_Dp)\n","    \n","      \n","    \n","    x=nib.load(os.path.join(Path,i,q[1]))\n","    f_Flair=x.get_fdata()\n","    f_Flair=np.asarray(f_Flair,'float32')\n","    for j in range(f_Flair.shape[2]):\n","        slice_Flair=cv.resize(f_Flair[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","        if(np.sum(slice_Flair)!=0):\n","           # slice_Flair=slice_Flair/(np.max(slice_Flair)+0.00001)\n","            slice_Flair=(slice_Flair-np.mean(slice_Flair)+0.00001)/(np.std(slice_Flair)+0.00001)\n","        X_Flair.append(slice_Flair)\n","    \n","    \n","    x=nib.load(os.path.join(Path,i,q[2]))\n","    f_Gado=x.get_fdata()\n","    f_Gado=np.asarray(f_Gado,'float32')\n","    for j in range(f_Gado.shape[2]):\n","        slice_Gado=cv.resize(f_Gado[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","        if(np.sum(slice_Gado)!=0):\n","           # slice_Gado=slice_Gado/(np.max(slice_Gado)+0.00001)\n","            slice_Gado=(slice_Gado-np.mean(slice_Gado)+0.00001)/(np.std(slice_Gado)+0.00001)\n","        X_Gado.append(slice_Gado)\n","    \n","    \n","    x=nib.load(os.path.join(Path,i,q[3]))\n","    f_Man1=x.get_fdata()\n","    f_Man1=np.asarray(f_Man1,'float32')\n","    for j in range(f_Man1.shape[2]):\n","        slice_Man1=cv.resize(f_Man1[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","        slice_Man1=np.array(slice_Man1)\n","        slice_Man1[slice_Man1 > 0] = 1.0\n","        Y_Man1.append(slice_Man1)\n","    \n","    x=nib.load(os.path.join(Path,i,q[10]))\n","    f_T1=x.get_fdata()\n","    f_T1=np.asarray(f_T1,'float32')\n","    for j in range(f_T1.shape[2]):\n","        slice_T1=cv.resize(f_T1[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","        if(np.sum(slice_T1)!=0):\n","        #    slice_T1=slice_T1/(np.max(slice_T1)+0.00001)\n","            slice_T1=(slice_T1-np.mean(slice_T1)+0.00001)/(np.std(slice_T1)+0.00001)\n","        X_T1.append(slice_T1)\n","    \n","    \n","    x=nib.load(os.path.join(Path,i,q[11]))\n","    f_T2=x.get_fdata()\n","    f_T2=np.asarray(f_T2,'float32')\n","    for j in range(f_T2.shape[2]):\n","        slice_T2=cv.resize(f_T2[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","        if(np.sum(slice_T2)!=0):\n","         #   slice_T2=slice_T2/(np.max(slice_T2)+0.00001)\n","            slice_T2=(slice_T2-np.mean(slice_T2)+0.00001)/(np.std(slice_T2)+0.00001)\n","        X_T2.append(slice_T2)\n","\n","for i in range(len(X_Dp)):\n","    X_Dp[i]=X_Dp[i].T\n","    X_Flair[i]=X_Flair[i].T\n","    X_Gado[i]=X_Gado[i].T\n","    X_T1[i]=X_T1[i].T\n","    X_T2[i]=X_T2[i].T\n","    Y_Man1[i]=Y_Man1[i].T\n","\n","\n","for i in range(len(X_Dp)):\n","    slice_Dp=X_Dp[i]\n","    slice_Dp=slice_Dp[:,:,np.newaxis]\n","    \n","    slice_Flair=X_Flair[i]\n","    slice_Flair=slice_Flair[:,:,np.newaxis]\n","    \n","    slice_Gado=X_Gado[i]\n","    slice_Gado=slice_Gado[:,:,np.newaxis]\n","    \n","    slice_T1=X_T1[i]\n","    slice_T1=slice_T1[:,:,np.newaxis]\n","    \n","    slice_T2=X_T2[i]\n","    slice_T2=slice_T2[:,:,np.newaxis]\n","    \n","    final_slice=np.concatenate((slice_Dp,slice_Flair,slice_Gado,slice_T1,slice_T2),axis=-1)\n","    \n","    if(np.sum(final_slice)!=0):\n","        X.append(final_slice)\n","        Y1.append(Y_Man1[i])\n","\n","        \n","        \n","X=np.array(X,dtype='float32')\n","Y1=np.array(Y1,dtype='float32')\n","\n","\n","Y1=Y1[:,:,:,np.newaxis]\n","\n","\n","#np.save(\"X\",X)\n","#np.save(\"Y\",Y1)\n","#\n","#X = np.load(\"G:/Multiple Scelerosis/load_data/X.npy\")\n","#Y = np.load(\"G:/Multiple Scelerosis/load_data/Y.npy\")\n","\n","with h5py.File('preprocessed_axial_data.h5', 'w') as hf:\n","\n","    hf.create_dataset('input_X', data=X[:])\n","    hf.create_dataset('Manual_1', data=Y1[:])\n","\n","#    \n","with h5py.File('inputs_no_null.h5', 'w') as hf:\n","\n","    hf.create_dataset('Dp', data=X_Dp[:])\n","    hf.create_dataset('Flair', data=X_Flair[:])\n","    hf.create_dataset('Gado', data=X_Gado[:])\n","    hf.create_dataset('T1', data=X_T1[:]) \n","    hf.create_dataset('T2', data=X_T2[:])\n","  #  hf.create_dataset('Y_Dp', data=Y_Dp[:])\n","   # hf.create_dataset('Y_Flair', data=Y_Flair[:])\n","   # hf.create_dataset('Y_Gado', data=Y_Gado[:])\n","#    hf.create_dataset('Y_T1', data=Y_T1[:]) \n"," #   hf.create_dataset('Y_T2', data=Y_T2[:])\n","    \n","        \n","\n","\n","    \n","\n","    "],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"YKVZbl_EMWHk","colab_type":"code","outputId":"b94b46c3-32b0-4bd0-9f22-503b4adf9841","executionInfo":{"status":"ok","timestamp":1585223772305,"user_tz":-330,"elapsed":64210,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PTdGxoJeZm97","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 18:56:04 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","import tensorflow as tf\n","import keras\n","from keras.models import Model, load_model\n","from keras.layers import Input ,BatchNormalization , Activation \n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.merge import concatenate\n","\n","\n","def Convolution(input_tensor,filters):\n","    \n","    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x) \n","    return x\n","\n","def model(input_shape):\n","    \n","    inputs = Input((input_shape))\n","    \n","    conv_1 = Convolution(inputs,32)\n","    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n","    \n","    conv_2 = Convolution(maxp_1,64)\n","    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n","    \n","    conv_3 = Convolution(maxp_2,128)\n","    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n","    \n","    conv_4 = Convolution(maxp_3,256)\n","    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n","    \n","    conv_5 = Convolution(maxp_4,512)\n","    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n","    \n","    conv_6 = Convolution(upsample_6,256)\n","    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n","    \n","    upsample_7 = concatenate([upsample_7, conv_3])\n","    \n","    conv_7 = Convolution(upsample_7,128)\n","    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n","    \n","    conv_8 = Convolution(upsample_8,64)\n","    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n","    \n","    upsample_9 = concatenate([upsample_9, conv_1])\n","    \n","    conv_9 = Convolution(upsample_9,32)\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n","    \n","    model = Model(inputs=[inputs], outputs=[outputs]) \n","    \n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U48-R7igZ8ZS","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Jan  7 12:32:05 2019\n","\n","@author: Krishna\n","\"\"\"\n","# Importing neccessary packages\n","import h5py\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import nibabel as nib\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","\n","def process():\n","# Setting the path\n","    Path='drive/My Drive/Pre-processed'\n","    p=os.listdir(Path)\n","\n","    X_Dp=[]          \n","    X_Gado=[]\n","    X_Flair=[]      \n","    X_T1=[]\n","    X_T2=[]\n","    Y_Man1=[]\n","\n","    X=[]\n","    Y1=[]\n","\n","# Loading the MRI Scans \n","    for i in p[0:14] :\n","    \n","        q=os.listdir(os.path.join(Path,i))  \n","    \n","        x=nib.load(os.path.join(Path,i,q[0]))         \n","        f_Dp=x.get_fdata()\n","        f_Dp=np.asarray(f_Dp,'float32')\n","        for j in range(f_Dp.shape[2]):\n","            slice_Dp=cv.resize(f_Dp[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","            if(np.sum(slice_Dp)!=0):\n","          #  slice_Dp=slice_Dp/(np.max(slice_Dp)+0.00001)\n","                slice_Dp=(slice_Dp-np.mean(slice_Dp)+0.00001)/(np.std(slice_Dp)+0.00001)\n","            X_Dp.append(slice_Dp)\n","    \n","      \n","    \n","        x=nib.load(os.path.join(Path,i,q[1]))\n","        f_Flair=x.get_fdata()\n","        f_Flair=np.asarray(f_Flair,'float32')\n","        for j in range(f_Flair.shape[2]):\n","            slice_Flair=cv.resize(f_Flair[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","            if(np.sum(slice_Flair)!=0):\n","           # slice_Flair=slice_Flair/(np.max(slice_Flair)+0.00001)\n","                slice_Flair=(slice_Flair-np.mean(slice_Flair)+0.00001)/(np.std(slice_Flair)+0.00001)\n","            X_Flair.append(slice_Flair)\n","    \n","    \n","        x=nib.load(os.path.join(Path,i,q[2]))\n","        f_Gado=x.get_fdata()\n","        f_Gado=np.asarray(f_Gado,'float32')\n","        for j in range(f_Gado.shape[2]):\n","            slice_Gado=cv.resize(f_Gado[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","            if(np.sum(slice_Gado)!=0):\n","           # slice_Gado=slice_Gado/(np.max(slice_Gado)+0.00001)\n","                slice_Gado=(slice_Gado-np.mean(slice_Gado)+0.00001)/(np.std(slice_Gado)+0.00001)\n","            X_Gado.append(slice_Gado)\n","    \n","    \n","        x=nib.load(os.path.join(Path,i,q[3]))\n","        f_Man1=x.get_fdata()\n","        f_Man1=np.asarray(f_Man1,'float32')\n","        for j in range(f_Man1.shape[2]):\n","            slice_Man1=cv.resize(f_Man1[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","            slice_Man1=np.array(slice_Man1)\n","            slice_Man1[slice_Man1 > 0] = 1.0\n","            Y_Man1.append(slice_Man1)\n","    \n","        x=nib.load(os.path.join(Path,i,q[10]))\n","        f_T1=x.get_fdata()\n","        f_T1=np.asarray(f_T1,'float32')\n","        for j in range(f_T1.shape[2]):\n","            slice_T1=cv.resize(f_T1[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","            if(np.sum(slice_T1)!=0):\n","        #    slice_T1=slice_T1/(np.max(slice_T1)+0.00001)\n","                slice_T1=(slice_T1-np.mean(slice_T1)+0.00001)/(np.std(slice_T1)+0.00001)\n","            X_T1.append(slice_T1)\n","    \n","    \n","        x=nib.load(os.path.join(Path,i,q[11]))\n","        f_T2=x.get_fdata()\n","        f_T2=np.asarray(f_T2,'float32')\n","        for j in range(f_T2.shape[2]):\n","            slice_T2=cv.resize(f_T2[:,:,j],(256,256),interpolation=cv.INTER_AREA)\n","            if(np.sum(slice_T2)!=0):\n","         #   slice_T2=slice_T2/(np.max(slice_T2)+0.00001)\n","                slice_T2=(slice_T2-np.mean(slice_T2)+0.00001)/(np.std(slice_T2)+0.00001)\n","            X_T2.append(slice_T2)\n","\n","    for i in range(len(X_Dp)):\n","        X_Dp[i]=X_Dp[i].T\n","        X_Flair[i]=X_Flair[i].T\n","        X_Gado[i]=X_Gado[i].T\n","        X_T1[i]=X_T1[i].T\n","        X_T2[i]=X_T2[i].T\n","        Y_Man1[i]=Y_Man1[i].T\n","\n","\n","    for i in range(len(X_Dp)):\n","        slice_Dp=X_Dp[i]\n","        slice_Dp=slice_Dp[:,:,np.newaxis]\n","    \n","        slice_Flair=X_Flair[i]\n","        slice_Flair=slice_Flair[:,:,np.newaxis]\n","    \n","        slice_Gado=X_Gado[i]\n","        slice_Gado=slice_Gado[:,:,np.newaxis]\n","    \n","        slice_T1=X_T1[i]\n","        slice_T1=slice_T1[:,:,np.newaxis]\n","    \n","        slice_T2=X_T2[i]\n","        slice_T2=slice_T2[:,:,np.newaxis]\n","    \n","        final_slice=np.concatenate((slice_Dp,slice_Flair,slice_Gado,slice_T1,slice_T2),axis=-1)\n","    \n","        if(np.sum(final_slice)!=0):\n","            X.append(final_slice)\n","            Y1.append(Y_Man1[i])\n","\n","        \n","        \n","    X=np.array(X,dtype='float32')\n","    Y1=np.array(Y1,dtype='float32')\n","\n","\n","    Y1=Y1[:,:,:,np.newaxis]\n","\n","\n","#np.save(\"X\",X)\n","#np.save(\"Y\",Y1)\n","#\n","#X = np.load(\"G:/Multiple Scelerosis/load_data/X.npy\")\n","#Y = np.load(\"G:/Multiple Scelerosis/load_data/Y.npy\")\n","\n","    with h5py.File('preprocessed_axial_data.h5', 'w') as hf:\n","\n","        hf.create_dataset('input_X', data=X[:])\n","        hf.create_dataset('Manual_1', data=Y1[:])\n","\n","#    \n","    with h5py.File('inputs_no_null.h5', 'w') as hf:\n","\n","        hf.create_dataset('Dp', data=Dp[:])\n","        hf.create_dataset('Flair', data=Flair[:])\n","        hf.create_dataset('Gado', data=Gado[:])\n","        hf.create_dataset('T1', data=T1[:]) \n","        hf.create_dataset('T2', data=T2[:])\n","     #   hf.create_dataset('Y_Dp', data=Y_Dp[:])\n","      #  hf.create_dataset('Y_Flair', data=Y_Flair[:])\n","       # hf.create_dataset('Y_Gado', data=Y_Gado[:])\n","       # hf.create_dataset('Y_T1', data=Y_T1[:]) \n","       # hf.create_dataset('Y_T2', data=Y_T2[:])\n","    \n","        \n","\n","\n","    \n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9p-XXWG4auF_","colab_type":"code","outputId":"12b58dfb-2575-419d-cbc5-b76d9dcdc21f","executionInfo":{"status":"ok","timestamp":1584158625729,"user_tz":-330,"elapsed":1233,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 18:52:08 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","\n","from keras import backend as K\n","import numpy as np\n","import tensorflow as tf\n","\n","# Computing Dice_Coefficient\n","def dice_coef(y_true, y_pred, smooth=1.0):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","# Computing Precision \n","def precision(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","# Computing Sensitivity      \n","def sensitivity(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    return true_positives / (possible_positives + K.epsilon())\n","\n","# Computing Specificity\n","def specificity(y_true, y_pred):\n","    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n","    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n","    return true_negatives / (possible_negatives + K.epsilon())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QpDqywWOqonS","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import nibabel as nib\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","    \n","def modality(Path,index):\n","    X = []\n","    p=os.listdir(Path) \n","\n","    for i in p[:14]:                                                                      # Loading all the folders in the given path\n","        q = os.listdir(os.path.join(Path,i))     \n","\n","        x = nib.load(os.path.join(Path,i,q[index]))         \n","        f = x.get_fdata()\n","        f = np.asarray(f,'float32')\n","        \n","        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n","            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n","            if(index != 3 and np.sum(_slice) != 0 ):                                           # To check whether the slice is null or not\n","              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n","                _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n","            elif(index == 3):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n","                _slice = np.array(_slice)\n","                _slice[_slice > 0] = 1.0\n","            _slice = _slice.T\n","            _slice = _slice[:,:,np.newaxis]\n","            X.append(_slice)\n","    return X\n","\n","# Removing the null samples as it contains no information\n","def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual): \n","     \n","    X=[]\n","    Y=[]\n","    \n","    for i in range(len(X_Dp)):        \n","        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n","        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n","            X.append(final_slice)\n","            Y.append(Y_Manual[i])\n"," \n","#   Converting the list into array  \n","    X=np.array(X,dtype='float32')\n","    Y=np.array(Y,dtype='float32')\n","    \n","    return X,Y\n","\n","#   To store the data in numpy format    \n","def store_data(X,Y):\n","    np.save(\"X.npy\",X)\n","    np.save(\"Y.npy\",Y)\n","\n","\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4hIydZE5L7qq","colab_type":"code","colab":{}},"source":["\"\"\"\n","Created on Fri Dec 13 21:23:59 2019\n","@author: Krishna Chandra\n","\"\"\"\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Accuracy vs Epoch\n","def Accuracy_Graph(history):\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    #plt.title('Model accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","    \n","# Dice Similarity Coefficient vs Epoch\n","def Dice_coefficient_Graph(history):\n","\n","    plt.plot(history.history['dice_coef'])\n","    plt.plot(history.history['val_dice_coef'])\n","    #plt.title('Dice_Coefficient')\n","    plt.ylabel('Dice_Coefficient')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","# Loss vs Epoch\n","def Loss_Graph(history):\n","\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    #plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0IpaR9ubA-o","colab_type":"code","outputId":"c90f0710-2174-46b9-f596-1fc1bbb21db8","executionInfo":{"status":"ok","timestamp":1584074564270,"user_tz":-330,"elapsed":1135545,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 20:18:06 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","X_Dp      =   modality(Path,0)\n","X_Flair   =   modality(Path,1)\n","X_Gado    =   modality(Path,2)\n","X_T1      =   modality(Path,10)\n","X_T2      =   modality(Path,11)\n","Y_Manual  =   modality(Path,3)\n","\n","# Removing the null samples and concatenating the 5 modalities along the 3rd dimension\n","X, Y = remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual)\n","\n","\n","# Splitting the Whole data into Training and Testing data\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","\n","# Loding the modified U-net \n","model = model(input_shape = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('Modified_UNet.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('Modified_UNet.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)\n","#Loss_Graph(history)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 5) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 32) 1472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 256)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 16, 16, 512)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 32, 32, 512)  0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 256)  1179904     up_sampling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 64, 64, 384)  0           up_sampling2d_1[0][0]            \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 64, 64, 128)  442496      concatenate[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 128, 128, 64) 73792       up_sampling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_3[0][0]            \n","                                                                 activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 256, 256, 32) 27680       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 256, 256, 32) 128         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 256, 256, 32) 0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 256, 256, 1)  33          activation_8[0][0]               \n","==================================================================================================\n","Total params: 3,298,945\n","Trainable params: 3,296,001\n","Non-trainable params: 2,944\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 1999 samples, validate on 500 samples\n","Epoch 1/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9831 - dice_coef: 0.0389 - precision: 0.5519 - sensitivity: 0.8562 - specificity: 0.9836\n","Epoch 00001: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 28s 14ms/sample - loss: 0.2287 - acc: 0.9832 - dice_coef: 0.0392 - precision: 0.5537 - sensitivity: 0.8571 - specificity: 0.9838 - val_loss: 0.2197 - val_acc: 0.9977 - val_dice_coef: 0.0300 - val_precision: 0.7849 - val_sensitivity: 0.6685 - val_specificity: 0.9992\n","Epoch 2/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9981 - dice_coef: 0.0654 - precision: 0.7769 - sensitivity: 0.7464 - specificity: 0.9991\n","Epoch 00002: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0965 - acc: 0.9981 - dice_coef: 0.0662 - precision: 0.7781 - sensitivity: 0.7454 - specificity: 0.9991 - val_loss: 0.1133 - val_acc: 0.9978 - val_dice_coef: 0.0618 - val_precision: 0.7348 - val_sensitivity: 0.7617 - val_specificity: 0.9988\n","Epoch 3/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9982 - dice_coef: 0.1018 - precision: 0.8105 - sensitivity: 0.7245 - specificity: 0.9993\n","Epoch 00003: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0563 - acc: 0.9982 - dice_coef: 0.1029 - precision: 0.8120 - sensitivity: 0.7250 - specificity: 0.9993 - val_loss: 0.0621 - val_acc: 0.9980 - val_dice_coef: 0.1010 - val_precision: 0.8135 - val_sensitivity: 0.7361 - val_specificity: 0.9992\n","Epoch 4/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9982 - dice_coef: 0.1479 - precision: 0.8243 - sensitivity: 0.7236 - specificity: 0.9994\n","Epoch 00004: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0365 - acc: 0.9982 - dice_coef: 0.1468 - precision: 0.8240 - sensitivity: 0.7215 - specificity: 0.9994 - val_loss: 0.0356 - val_acc: 0.9980 - val_dice_coef: 0.1590 - val_precision: 0.8051 - val_sensitivity: 0.7195 - val_specificity: 0.9992\n","Epoch 5/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9983 - dice_coef: 0.1961 - precision: 0.8220 - sensitivity: 0.7390 - specificity: 0.9994\n","Epoch 00005: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0259 - acc: 0.9983 - dice_coef: 0.1946 - precision: 0.8206 - sensitivity: 0.7387 - specificity: 0.9994 - val_loss: 0.0249 - val_acc: 0.9981 - val_dice_coef: 0.2134 - val_precision: 0.8183 - val_sensitivity: 0.7203 - val_specificity: 0.9993\n","Epoch 6/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9983 - dice_coef: 0.2480 - precision: 0.8256 - sensitivity: 0.7500 - specificity: 0.9993\n","Epoch 00006: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0196 - acc: 0.9983 - dice_coef: 0.2478 - precision: 0.8263 - sensitivity: 0.7485 - specificity: 0.9994 - val_loss: 0.0186 - val_acc: 0.9981 - val_dice_coef: 0.2612 - val_precision: 0.8447 - val_sensitivity: 0.6968 - val_specificity: 0.9994\n","Epoch 7/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9984 - dice_coef: 0.2979 - precision: 0.8335 - sensitivity: 0.7674 - specificity: 0.9993\n","Epoch 00007: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0157 - acc: 0.9984 - dice_coef: 0.2974 - precision: 0.8328 - sensitivity: 0.7690 - specificity: 0.9993 - val_loss: 0.0154 - val_acc: 0.9981 - val_dice_coef: 0.3636 - val_precision: 0.7697 - val_sensitivity: 0.8475 - val_specificity: 0.9988\n","Epoch 8/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9984 - dice_coef: 0.3425 - precision: 0.8234 - sensitivity: 0.7715 - specificity: 0.9993\n","Epoch 00008: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0131 - acc: 0.9984 - dice_coef: 0.3395 - precision: 0.8226 - sensitivity: 0.7699 - specificity: 0.9993 - val_loss: 0.0146 - val_acc: 0.9972 - val_dice_coef: 0.2549 - val_precision: 0.9300 - val_sensitivity: 0.4119 - val_specificity: 0.9998\n","Epoch 9/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9984 - dice_coef: 0.3813 - precision: 0.8279 - sensitivity: 0.7758 - specificity: 0.9993\n","Epoch 00009: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0113 - acc: 0.9984 - dice_coef: 0.3789 - precision: 0.8274 - sensitivity: 0.7746 - specificity: 0.9993 - val_loss: 0.0117 - val_acc: 0.9977 - val_dice_coef: 0.3499 - val_precision: 0.9053 - val_sensitivity: 0.5440 - val_specificity: 0.9997\n","Epoch 10/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9985 - dice_coef: 0.4212 - precision: 0.8233 - sensitivity: 0.7856 - specificity: 0.9993\n","Epoch 00010: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0099 - acc: 0.9984 - dice_coef: 0.4233 - precision: 0.8246 - sensitivity: 0.7859 - specificity: 0.9993 - val_loss: 0.0096 - val_acc: 0.9983 - val_dice_coef: 0.4557 - val_precision: 0.8380 - val_sensitivity: 0.7577 - val_specificity: 0.9993\n","Epoch 11/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9985 - dice_coef: 0.4581 - precision: 0.8271 - sensitivity: 0.7905 - specificity: 0.9993\n","Epoch 00011: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0089 - acc: 0.9985 - dice_coef: 0.4591 - precision: 0.8273 - sensitivity: 0.7920 - specificity: 0.9993 - val_loss: 0.0093 - val_acc: 0.9983 - val_dice_coef: 0.4690 - val_precision: 0.8270 - val_sensitivity: 0.8070 - val_specificity: 0.9992\n","Epoch 12/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9985 - dice_coef: 0.4965 - precision: 0.8349 - sensitivity: 0.8006 - specificity: 0.9993\n","Epoch 00012: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0080 - acc: 0.9985 - dice_coef: 0.4992 - precision: 0.8356 - sensitivity: 0.8020 - specificity: 0.9993 - val_loss: 0.0083 - val_acc: 0.9983 - val_dice_coef: 0.5191 - val_precision: 0.8495 - val_sensitivity: 0.7774 - val_specificity: 0.9994\n","Epoch 13/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9985 - dice_coef: 0.5203 - precision: 0.8367 - sensitivity: 0.8003 - specificity: 0.9994\n","Epoch 00013: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0075 - acc: 0.9985 - dice_coef: 0.5196 - precision: 0.8337 - sensitivity: 0.7998 - specificity: 0.9993 - val_loss: 0.0075 - val_acc: 0.9984 - val_dice_coef: 0.5376 - val_precision: 0.8650 - val_sensitivity: 0.7626 - val_specificity: 0.9994\n","Epoch 14/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9985 - dice_coef: 0.5412 - precision: 0.8401 - sensitivity: 0.7976 - specificity: 0.9994\n","Epoch 00014: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0070 - acc: 0.9986 - dice_coef: 0.5367 - precision: 0.8362 - sensitivity: 0.7944 - specificity: 0.9994 - val_loss: 0.0073 - val_acc: 0.9983 - val_dice_coef: 0.5835 - val_precision: 0.7978 - val_sensitivity: 0.8355 - val_specificity: 0.9990\n","Epoch 15/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9985 - dice_coef: 0.5541 - precision: 0.8373 - sensitivity: 0.7999 - specificity: 0.9994\n","Epoch 00015: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0066 - acc: 0.9985 - dice_coef: 0.5548 - precision: 0.8369 - sensitivity: 0.8009 - specificity: 0.9994 - val_loss: 0.0068 - val_acc: 0.9984 - val_dice_coef: 0.6029 - val_precision: 0.8233 - val_sensitivity: 0.8161 - val_specificity: 0.9992\n","Epoch 16/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9986 - dice_coef: 0.5788 - precision: 0.8429 - sensitivity: 0.8042 - specificity: 0.9994\n","Epoch 00016: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0062 - acc: 0.9986 - dice_coef: 0.5803 - precision: 0.8438 - sensitivity: 0.8056 - specificity: 0.9994 - val_loss: 0.0067 - val_acc: 0.9984 - val_dice_coef: 0.5736 - val_precision: 0.8583 - val_sensitivity: 0.7691 - val_specificity: 0.9994\n","Epoch 17/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9986 - dice_coef: 0.5980 - precision: 0.8469 - sensitivity: 0.8098 - specificity: 0.9994\n","Epoch 00017: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0060 - acc: 0.9986 - dice_coef: 0.5984 - precision: 0.8470 - sensitivity: 0.8116 - specificity: 0.9994 - val_loss: 0.0067 - val_acc: 0.9984 - val_dice_coef: 0.6443 - val_precision: 0.7967 - val_sensitivity: 0.8569 - val_specificity: 0.9990\n","Epoch 18/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9987 - dice_coef: 0.6144 - precision: 0.8516 - sensitivity: 0.8099 - specificity: 0.9994\n","Epoch 00018: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0056 - acc: 0.9987 - dice_coef: 0.6148 - precision: 0.8523 - sensitivity: 0.8093 - specificity: 0.9994 - val_loss: 0.0065 - val_acc: 0.9985 - val_dice_coef: 0.6724 - val_precision: 0.8310 - val_sensitivity: 0.8347 - val_specificity: 0.9992\n","Epoch 19/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9986 - dice_coef: 0.6262 - precision: 0.8505 - sensitivity: 0.8096 - specificity: 0.9994\n","Epoch 00019: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0055 - acc: 0.9986 - dice_coef: 0.6273 - precision: 0.8516 - sensitivity: 0.8108 - specificity: 0.9994 - val_loss: 0.0064 - val_acc: 0.9983 - val_dice_coef: 0.5899 - val_precision: 0.8862 - val_sensitivity: 0.7120 - val_specificity: 0.9996\n","Epoch 20/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9987 - dice_coef: 0.6389 - precision: 0.8560 - sensitivity: 0.8106 - specificity: 0.9994\n","Epoch 00020: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0052 - acc: 0.9987 - dice_coef: 0.6406 - precision: 0.8568 - sensitivity: 0.8123 - specificity: 0.9994 - val_loss: 0.0059 - val_acc: 0.9985 - val_dice_coef: 0.6831 - val_precision: 0.8484 - val_sensitivity: 0.8023 - val_specificity: 0.9994\n","Epoch 21/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9987 - dice_coef: 0.6436 - precision: 0.8570 - sensitivity: 0.8109 - specificity: 0.9995\n","Epoch 00021: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0051 - acc: 0.9987 - dice_coef: 0.6447 - precision: 0.8576 - sensitivity: 0.8106 - specificity: 0.9995 - val_loss: 0.0058 - val_acc: 0.9985 - val_dice_coef: 0.6509 - val_precision: 0.8923 - val_sensitivity: 0.7330 - val_specificity: 0.9996\n","Epoch 22/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987 - dice_coef: 0.6645 - precision: 0.8665 - sensitivity: 0.8158 - specificity: 0.9995\n","Epoch 00022: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0049 - acc: 0.9987 - dice_coef: 0.6637 - precision: 0.8661 - sensitivity: 0.8167 - specificity: 0.9995 - val_loss: 0.0066 - val_acc: 0.9983 - val_dice_coef: 0.6622 - val_precision: 0.7850 - val_sensitivity: 0.8740 - val_specificity: 0.9989\n","Epoch 23/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6784 - precision: 0.8698 - sensitivity: 0.8245 - specificity: 0.9995\n","Epoch 00023: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6778 - precision: 0.8695 - sensitivity: 0.8228 - specificity: 0.9995 - val_loss: 0.0053 - val_acc: 0.9986 - val_dice_coef: 0.6941 - val_precision: 0.8550 - val_sensitivity: 0.8103 - val_specificity: 0.9994\n","Epoch 24/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9988 - dice_coef: 0.6835 - precision: 0.8690 - sensitivity: 0.8207 - specificity: 0.9995\n","Epoch 00024: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0045 - acc: 0.9988 - dice_coef: 0.6845 - precision: 0.8700 - sensitivity: 0.8219 - specificity: 0.9995 - val_loss: 0.0054 - val_acc: 0.9985 - val_dice_coef: 0.6810 - val_precision: 0.8784 - val_sensitivity: 0.7623 - val_specificity: 0.9995\n","Epoch 25/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9988 - dice_coef: 0.6948 - precision: 0.8708 - sensitivity: 0.8250 - specificity: 0.9995\n","Epoch 00025: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0043 - acc: 0.9988 - dice_coef: 0.6942 - precision: 0.8709 - sensitivity: 0.8255 - specificity: 0.9995 - val_loss: 0.0056 - val_acc: 0.9985 - val_dice_coef: 0.7388 - val_precision: 0.8380 - val_sensitivity: 0.8374 - val_specificity: 0.9992\n","Epoch 26/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9988 - dice_coef: 0.7050 - precision: 0.8748 - sensitivity: 0.8289 - specificity: 0.9995\n","Epoch 00026: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0042 - acc: 0.9988 - dice_coef: 0.7050 - precision: 0.8749 - sensitivity: 0.8288 - specificity: 0.9995 - val_loss: 0.0053 - val_acc: 0.9985 - val_dice_coef: 0.6585 - val_precision: 0.8927 - val_sensitivity: 0.7462 - val_specificity: 0.9996\n","Epoch 27/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9989 - dice_coef: 0.7196 - precision: 0.8824 - sensitivity: 0.8360 - specificity: 0.9995\n","Epoch 00027: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0040 - acc: 0.9989 - dice_coef: 0.7198 - precision: 0.8830 - sensitivity: 0.8365 - specificity: 0.9995 - val_loss: 0.0056 - val_acc: 0.9986 - val_dice_coef: 0.7053 - val_precision: 0.8883 - val_sensitivity: 0.7649 - val_specificity: 0.9996\n","Epoch 28/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9989 - dice_coef: 0.7280 - precision: 0.8873 - sensitivity: 0.8418 - specificity: 0.9996\n","Epoch 00028: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0038 - acc: 0.9989 - dice_coef: 0.7276 - precision: 0.8871 - sensitivity: 0.8415 - specificity: 0.9996 - val_loss: 0.0051 - val_acc: 0.9987 - val_dice_coef: 0.7487 - val_precision: 0.8811 - val_sensitivity: 0.8110 - val_specificity: 0.9995\n","Epoch 29/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9989 - dice_coef: 0.7428 - precision: 0.8921 - sensitivity: 0.8464 - specificity: 0.9996\n","Epoch 00029: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0036 - acc: 0.9989 - dice_coef: 0.7412 - precision: 0.8902 - sensitivity: 0.8455 - specificity: 0.9996 - val_loss: 0.0049 - val_acc: 0.9986 - val_dice_coef: 0.6893 - val_precision: 0.8324 - val_sensitivity: 0.8362 - val_specificity: 0.9993\n","Epoch 30/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9989 - dice_coef: 0.7357 - precision: 0.8822 - sensitivity: 0.8399 - specificity: 0.9995\n","Epoch 00030: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0036 - acc: 0.9989 - dice_coef: 0.7348 - precision: 0.8832 - sensitivity: 0.8390 - specificity: 0.9995 - val_loss: 0.0055 - val_acc: 0.9984 - val_dice_coef: 0.7452 - val_precision: 0.8045 - val_sensitivity: 0.8604 - val_specificity: 0.9991\n","Epoch 31/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9990 - dice_coef: 0.7501 - precision: 0.8922 - sensitivity: 0.8486 - specificity: 0.9996\n","Epoch 00031: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0035 - acc: 0.9990 - dice_coef: 0.7521 - precision: 0.8929 - sensitivity: 0.8506 - specificity: 0.9996 - val_loss: 0.0050 - val_acc: 0.9986 - val_dice_coef: 0.7454 - val_precision: 0.8154 - val_sensitivity: 0.8503 - val_specificity: 0.9992\n","Epoch 32/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9990 - dice_coef: 0.7590 - precision: 0.8937 - sensitivity: 0.8544 - specificity: 0.9996\n","Epoch 00032: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0033 - acc: 0.9990 - dice_coef: 0.7592 - precision: 0.8943 - sensitivity: 0.8543 - specificity: 0.9996 - val_loss: 0.0066 - val_acc: 0.9983 - val_dice_coef: 0.7656 - val_precision: 0.7827 - val_sensitivity: 0.8719 - val_specificity: 0.9989\n","Epoch 33/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9990 - dice_coef: 0.7618 - precision: 0.8904 - sensitivity: 0.8543 - specificity: 0.9996\n","Epoch 00033: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0034 - acc: 0.9990 - dice_coef: 0.7597 - precision: 0.8875 - sensitivity: 0.8551 - specificity: 0.9996 - val_loss: 0.0048 - val_acc: 0.9986 - val_dice_coef: 0.7318 - val_precision: 0.8700 - val_sensitivity: 0.7823 - val_specificity: 0.9995\n","Epoch 34/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990 - dice_coef: 0.7762 - precision: 0.9000 - sensitivity: 0.8613 - specificity: 0.9996\n","Epoch 00034: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7718 - precision: 0.8956 - sensitivity: 0.8603 - specificity: 0.9996 - val_loss: 0.0048 - val_acc: 0.9986 - val_dice_coef: 0.7297 - val_precision: 0.8499 - val_sensitivity: 0.8034 - val_specificity: 0.9994\n","Epoch 35/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9991 - dice_coef: 0.7801 - precision: 0.8999 - sensitivity: 0.8668 - specificity: 0.9996\n","Epoch 00035: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0030 - acc: 0.9991 - dice_coef: 0.7801 - precision: 0.8998 - sensitivity: 0.8665 - specificity: 0.9996 - val_loss: 0.0066 - val_acc: 0.9981 - val_dice_coef: 0.7210 - val_precision: 0.7248 - val_sensitivity: 0.9043 - val_specificity: 0.9985\n","Epoch 36/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9990 - dice_coef: 0.7825 - precision: 0.8976 - sensitivity: 0.8650 - specificity: 0.9996\n","Epoch 00036: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0030 - acc: 0.9990 - dice_coef: 0.7837 - precision: 0.8977 - sensitivity: 0.8661 - specificity: 0.9996 - val_loss: 0.0056 - val_acc: 0.9985 - val_dice_coef: 0.7788 - val_precision: 0.8327 - val_sensitivity: 0.8317 - val_specificity: 0.9992\n","Epoch 37/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9991 - dice_coef: 0.7904 - precision: 0.9027 - sensitivity: 0.8656 - specificity: 0.9996\n","Epoch 00037: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0029 - acc: 0.9991 - dice_coef: 0.7919 - precision: 0.9036 - sensitivity: 0.8670 - specificity: 0.9996 - val_loss: 0.0050 - val_acc: 0.9987 - val_dice_coef: 0.7891 - val_precision: 0.8693 - val_sensitivity: 0.8271 - val_specificity: 0.9994\n","Epoch 38/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9991 - dice_coef: 0.7964 - precision: 0.9025 - sensitivity: 0.8723 - specificity: 0.9996\n","Epoch 00038: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0028 - acc: 0.9991 - dice_coef: 0.7972 - precision: 0.9034 - sensitivity: 0.8722 - specificity: 0.9996 - val_loss: 0.0048 - val_acc: 0.9987 - val_dice_coef: 0.7716 - val_precision: 0.8906 - val_sensitivity: 0.7902 - val_specificity: 0.9996\n","Epoch 39/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8009 - precision: 0.9052 - sensitivity: 0.8759 - specificity: 0.9996\n","Epoch 00039: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0027 - acc: 0.9991 - dice_coef: 0.8007 - precision: 0.9049 - sensitivity: 0.8757 - specificity: 0.9996 - val_loss: 0.0053 - val_acc: 0.9986 - val_dice_coef: 0.7932 - val_precision: 0.8660 - val_sensitivity: 0.8232 - val_specificity: 0.9994\n","Epoch 40/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8073 - precision: 0.9060 - sensitivity: 0.8774 - specificity: 0.9996\n","Epoch 00040: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0025 - acc: 0.9991 - dice_coef: 0.8054 - precision: 0.9060 - sensitivity: 0.8762 - specificity: 0.9996 - val_loss: 0.0053 - val_acc: 0.9986 - val_dice_coef: 0.7830 - val_precision: 0.8899 - val_sensitivity: 0.7893 - val_specificity: 0.9996\n","Epoch 41/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992 - dice_coef: 0.8115 - precision: 0.9062 - sensitivity: 0.8824 - specificity: 0.9996\n","Epoch 00041: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0025 - acc: 0.9992 - dice_coef: 0.8086 - precision: 0.9052 - sensitivity: 0.8784 - specificity: 0.9996 - val_loss: 0.0046 - val_acc: 0.9987 - val_dice_coef: 0.7700 - val_precision: 0.9115 - val_sensitivity: 0.7747 - val_specificity: 0.9997\n","Epoch 42/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992 - dice_coef: 0.8191 - precision: 0.9113 - sensitivity: 0.8848 - specificity: 0.9996\n","Epoch 00042: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0024 - acc: 0.9992 - dice_coef: 0.8180 - precision: 0.9098 - sensitivity: 0.8844 - specificity: 0.9996 - val_loss: 0.0045 - val_acc: 0.9985 - val_dice_coef: 0.7483 - val_precision: 0.8441 - val_sensitivity: 0.8287 - val_specificity: 0.9993\n","Epoch 43/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992 - dice_coef: 0.8205 - precision: 0.9103 - sensitivity: 0.8862 - specificity: 0.9996\n","Epoch 00043: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0024 - acc: 0.9992 - dice_coef: 0.8207 - precision: 0.9113 - sensitivity: 0.8859 - specificity: 0.9996 - val_loss: 0.0055 - val_acc: 0.9982 - val_dice_coef: 0.6926 - val_precision: 0.9394 - val_sensitivity: 0.6362 - val_specificity: 0.9998\n","Epoch 44/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8355 - precision: 0.9189 - sensitivity: 0.8941 - specificity: 0.9997\n","Epoch 00044: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8358 - precision: 0.9191 - sensitivity: 0.8941 - specificity: 0.9997 - val_loss: 0.0045 - val_acc: 0.9986 - val_dice_coef: 0.7759 - val_precision: 0.8358 - val_sensitivity: 0.8508 - val_specificity: 0.9993\n","Epoch 45/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8331 - precision: 0.9118 - sensitivity: 0.8952 - specificity: 0.9997\n","Epoch 00045: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8334 - precision: 0.9125 - sensitivity: 0.8952 - specificity: 0.9997 - val_loss: 0.0042 - val_acc: 0.9987 - val_dice_coef: 0.7914 - val_precision: 0.8713 - val_sensitivity: 0.8285 - val_specificity: 0.9994\n","Epoch 46/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8400 - precision: 0.9172 - sensitivity: 0.8962 - specificity: 0.9997\n","Epoch 00046: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8372 - precision: 0.9158 - sensitivity: 0.8949 - specificity: 0.9997 - val_loss: 0.0045 - val_acc: 0.9986 - val_dice_coef: 0.7599 - val_precision: 0.8891 - val_sensitivity: 0.7840 - val_specificity: 0.9996\n","Epoch 47/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993 - dice_coef: 0.8373 - precision: 0.9144 - sensitivity: 0.8962 - specificity: 0.9997\n","Epoch 00047: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0021 - acc: 0.9993 - dice_coef: 0.8364 - precision: 0.9137 - sensitivity: 0.8957 - specificity: 0.9997 - val_loss: 0.0045 - val_acc: 0.9987 - val_dice_coef: 0.8103 - val_precision: 0.8512 - val_sensitivity: 0.8571 - val_specificity: 0.9993\n","Epoch 48/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8494 - precision: 0.9198 - sensitivity: 0.9039 - specificity: 0.9997\n","Epoch 00048: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8495 - precision: 0.9208 - sensitivity: 0.9030 - specificity: 0.9997 - val_loss: 0.0041 - val_acc: 0.9987 - val_dice_coef: 0.7946 - val_precision: 0.8698 - val_sensitivity: 0.8453 - val_specificity: 0.9994\n","Epoch 49/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8524 - precision: 0.9196 - sensitivity: 0.9070 - specificity: 0.9997\n","Epoch 00049: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8502 - precision: 0.9169 - sensitivity: 0.9065 - specificity: 0.9997 - val_loss: 0.0047 - val_acc: 0.9987 - val_dice_coef: 0.8083 - val_precision: 0.8493 - val_sensitivity: 0.8432 - val_specificity: 0.9993\n","Epoch 50/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.8497 - precision: 0.9201 - sensitivity: 0.9021 - specificity: 0.9997\n","Epoch 00050: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.8506 - precision: 0.9209 - sensitivity: 0.9028 - specificity: 0.9997 - val_loss: 0.0053 - val_acc: 0.9986 - val_dice_coef: 0.8172 - val_precision: 0.8359 - val_sensitivity: 0.8659 - val_specificity: 0.9992\n","Epoch 51/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8562 - precision: 0.9213 - sensitivity: 0.9052 - specificity: 0.9997\n","Epoch 00051: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8571 - precision: 0.9221 - sensitivity: 0.9056 - specificity: 0.9997 - val_loss: 0.0054 - val_acc: 0.9986 - val_dice_coef: 0.8024 - val_precision: 0.9197 - val_sensitivity: 0.7661 - val_specificity: 0.9997\n","Epoch 52/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8578 - precision: 0.9212 - sensitivity: 0.9083 - specificity: 0.9997\n","Epoch 00052: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8580 - precision: 0.9213 - sensitivity: 0.9085 - specificity: 0.9997 - val_loss: 0.0049 - val_acc: 0.9987 - val_dice_coef: 0.8230 - val_precision: 0.8840 - val_sensitivity: 0.8309 - val_specificity: 0.9995\n","Epoch 53/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.8649 - precision: 0.9271 - sensitivity: 0.9119 - specificity: 0.9997\n","Epoch 00053: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.8641 - precision: 0.9265 - sensitivity: 0.9116 - specificity: 0.9997 - val_loss: 0.0053 - val_acc: 0.9985 - val_dice_coef: 0.8084 - val_precision: 0.8009 - val_sensitivity: 0.8936 - val_specificity: 0.9990\n","Epoch 54/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9993 - dice_coef: 0.8661 - precision: 0.9266 - sensitivity: 0.9115 - specificity: 0.9997\n","Epoch 00054: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0017 - acc: 0.9993 - dice_coef: 0.8667 - precision: 0.9269 - sensitivity: 0.9122 - specificity: 0.9997 - val_loss: 0.0044 - val_acc: 0.9987 - val_dice_coef: 0.7932 - val_precision: 0.8729 - val_sensitivity: 0.8095 - val_specificity: 0.9995\n","Epoch 55/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.8717 - precision: 0.9281 - sensitivity: 0.9163 - specificity: 0.9997\n","Epoch 00055: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.8686 - precision: 0.9249 - sensitivity: 0.9142 - specificity: 0.9997 - val_loss: 0.0046 - val_acc: 0.9987 - val_dice_coef: 0.8115 - val_precision: 0.8773 - val_sensitivity: 0.8192 - val_specificity: 0.9995\n","Epoch 56/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8758 - precision: 0.9292 - sensitivity: 0.9204 - specificity: 0.9997\n","Epoch 00056: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8758 - precision: 0.9294 - sensitivity: 0.9198 - specificity: 0.9997 - val_loss: 0.0047 - val_acc: 0.9987 - val_dice_coef: 0.8172 - val_precision: 0.8639 - val_sensitivity: 0.8376 - val_specificity: 0.9994\n","Epoch 57/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8753 - precision: 0.9307 - sensitivity: 0.9174 - specificity: 0.9997\n","Epoch 00057: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8754 - precision: 0.9306 - sensitivity: 0.9176 - specificity: 0.9997 - val_loss: 0.0048 - val_acc: 0.9987 - val_dice_coef: 0.8171 - val_precision: 0.9055 - val_sensitivity: 0.8013 - val_specificity: 0.9996\n","Epoch 58/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8822 - precision: 0.9336 - sensitivity: 0.9235 - specificity: 0.9997\n","Epoch 00058: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8829 - precision: 0.9343 - sensitivity: 0.9240 - specificity: 0.9997 - val_loss: 0.0046 - val_acc: 0.9987 - val_dice_coef: 0.8209 - val_precision: 0.8857 - val_sensitivity: 0.8245 - val_specificity: 0.9995\n","Epoch 59/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8833 - precision: 0.9319 - sensitivity: 0.9260 - specificity: 0.9997\n","Epoch 00059: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8837 - precision: 0.9327 - sensitivity: 0.9259 - specificity: 0.9997 - val_loss: 0.0048 - val_acc: 0.9987 - val_dice_coef: 0.8200 - val_precision: 0.8567 - val_sensitivity: 0.8445 - val_specificity: 0.9993\n","Epoch 60/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8870 - precision: 0.9340 - sensitivity: 0.9278 - specificity: 0.9997\n","Epoch 00060: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 17s 9ms/sample - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8858 - precision: 0.9324 - sensitivity: 0.9277 - specificity: 0.9997 - val_loss: 0.0044 - val_acc: 0.9987 - val_dice_coef: 0.8206 - val_precision: 0.8704 - val_sensitivity: 0.8434 - val_specificity: 0.9994\n","2499/2499 [==============================] - 8s 3ms/sample - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.8601 - precision: 0.9068 - sensitivity: 0.9042 - specificity: 0.9997\n","441/441 [==============================] - 2s 4ms/sample - loss: 0.0037 - acc: 0.9989 - dice_coef: 0.8302 - precision: 0.8772 - sensitivity: 0.8549 - specificity: 0.9995\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.0037227980005861074,\n"," 0.99886024,\n"," 0.8301803,\n"," 0.87719697,\n"," 0.85485375,\n"," 0.99949354]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"DW_G-iI3MRED","colab_type":"code","outputId":"6ee35583-8b06-4f76-e66b-e92e27889503","executionInfo":{"status":"error","timestamp":1584081093133,"user_tz":-330,"elapsed":1616,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Accuracy vs Epoch\n","def Accuracy_Graph(history):\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    #plt.title('Model accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","    \n","# Dice Similarity Coefficient vs Epoch\n","def Dice_coefficient_Graph(history):\n","\n","    plt.plot(history.history['dice_coef'])\n","    plt.plot(history.history['val_dice_coef'])\n","    #plt.title('Dice_Coefficient')\n","    plt.ylabel('Dice_Coefficient')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","# Loss vs Epoch\n","def Loss_Graph(history):\n","\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    #plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","Accuracy_Graph(history)\n","Dice_coefficient_Graph(history)\n","Loss_Graph(history)\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-bda81cf1d8c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                         wspace=0.35)\n\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mAccuracy_Graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mDice_coefficient_Graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mLoss_Graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}]},{"cell_type":"code","metadata":{"id":"uwsLtpEGPJcm","colab_type":"code","outputId":"eda812cf-2d43-4f46-ec51-65b91d13603b","executionInfo":{"status":"ok","timestamp":1584158618570,"user_tz":-330,"elapsed":3246,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import nibabel as nib\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","    \n","def modality(Path,index):\n","    X = []\n","    p=os.listdir(Path) \n","\n","    for i in p[:14]:                                                                      # Loading all the folders in the given path\n","        q = os.listdir(os.path.join(Path,i))     \n","\n","        x = nib.load(os.path.join(Path,i,q[index]))         \n","        f = x.get_fdata()\n","        f = np.asarray(f,'float32')\n","        \n","        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n","            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n","            if(index != 3 and np.sum(_slice) != 0 ):                                           # To check whether the slice is null or not\n","              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n","                _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n","            elif(index == 3):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n","                _slice = np.array(_slice)\n","                _slice[_slice > 0] = 1.0\n","            _slice = _slice.T\n","            _slice = _slice[:,:,np.newaxis]\n","            X.append(_slice)\n","    return X\n","\n","# Removing the null samples as it contains no information\n","def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual): \n","     \n","    X=[]\n","    Y=[]\n","    \n","    for i in range(len(X_Dp)):        \n","        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n","        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n","            X.append(final_slice)\n","            Y.append(Y_Manual[i])\n"," \n","#   Converting the list into array  \n","    X=np.array(X,dtype='float32')\n","    Y=np.array(Y,dtype='float32')\n","    \n","    return X,Y\n","\n","#   To store the data in numpy format    \n","def store_data(X,Y):\n","    np.save(\"X.npy\",X)\n","    np.save(\"Y.npy\",Y)\n","\n","\n","        "],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"051Me3H8PNmp","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 18:56:04 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","import tensorflow as tf\n","import keras\n","from keras.models import Model, load_model\n","from keras.layers import Input ,BatchNormalization , Activation \n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.merge import concatenate\n","\n","\n","def Convolution(input_tensor,filters):\n","    \n","    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x) \n","    return x\n","\n","def model(input_shape):\n","    \n","    inputs = Input((input_shape))\n","    \n","    conv_1 = Convolution(inputs,32)\n","    \n","    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n","    \n","    conv_2 = Convolution(maxp_1,64)\n","    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n","    \n","    conv_3 = Convolution(maxp_2,128)\n","    \n","    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n","    \n","    conv_4 = Convolution(maxp_3,256)\n","    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n","    \n","    conv_5 = Convolution(maxp_4,512)\n","   \n","    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n","\n","    upsample_6 = concatenate([upsample_6, conv_4])\n","    \n","    conv_6 = Convolution(upsample_6,256)\n","    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n","    \n","    upsample_7 = concatenate([upsample_7, conv_3])\n","    \n","    conv_7 = Convolution(upsample_7,128)\n","    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n","    \n","    upsample_8 = concatenate([upsample_8, conv_2])\n","\n","    conv_8 = Convolution(upsample_8,64)\n","    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n","    \n","    upsample_9 = concatenate([upsample_9, conv_1])\n","    \n","    conv_9 = Convolution(upsample_9,32)\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n","    \n","    model = Model(inputs=[inputs], outputs=[outputs]) \n","    \n","    return model\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFks2WKAPeaM","colab_type":"code","outputId":"4c248846-a27e-4ebb-a95e-ab63b5cbdfa3","executionInfo":{"status":"ok","timestamp":1584079748534,"user_tz":-330,"elapsed":1202473,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 20:18:06 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","X_Dp      =   modality(Path,0)\n","X_Flair   =   modality(Path,1)\n","X_Gado    =   modality(Path,2)\n","X_T1      =   modality(Path,10)\n","X_T2      =   modality(Path,11)\n","Y_Manual  =   modality(Path,3)\n","\n","# Removing the null samples and concatenating the 5 modalities along the 3rd dimension\n","X, Y = remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual)\n","\n","\n","# Splitting the Whole data into Training and Testing data\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","\n","# Loding the modified U-net \n","model = model(input_shape = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('Modified_UNet.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('Modified_UNet.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)\n","#Loss_Graph(history)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 256, 256, 5) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 256, 256, 32) 1472        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 256, 256, 32) 128         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 256, 256, 32) 0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_12 (MaxPooling2D) (None, 128, 128, 32) 0           activation_23[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 128, 128, 64) 18496       max_pooling2d_12[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 128, 128, 64) 256         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 128, 128, 64) 0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 64)   0           activation_24[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_13[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 64, 64, 128)  512         conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 64, 64, 128)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 128)  0           activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_14[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 32, 32, 256)  1024        conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 32, 32, 256)  0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 256)  0           activation_26[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_15[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 16, 16, 512)  2048        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 16, 16, 512)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_9 (UpSampling2D)  (None, 32, 32, 512)  0           activation_27[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 32, 32, 768)  0           up_sampling2d_9[0][0]            \n","                                                                 activation_26[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 32, 32, 256)  1769728     concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 32, 32, 256)  1024        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 32, 32, 256)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_10 (UpSampling2D) (None, 64, 64, 256)  0           activation_28[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_10[0][0]           \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 64, 64, 128)  512         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 64, 64, 128)  0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_11 (UpSampling2D) (None, 128, 128, 128 0           activation_29[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 128, 128, 192 0           up_sampling2d_11[0][0]           \n","                                                                 activation_24[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 128, 128, 64) 256         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 128, 128, 64) 0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_12 (UpSampling2D) (None, 256, 256, 64) 0           activation_30[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 256, 256, 96) 0           up_sampling2d_12[0][0]           \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 256, 256, 32) 128         conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 256, 256, 32) 0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 256, 256, 1)  33          activation_31[0][0]              \n","==================================================================================================\n","Total params: 3,925,633\n","Trainable params: 3,922,689\n","Non-trainable params: 2,944\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 1999 samples, validate on 500 samples\n","Epoch 1/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9923 - dice_coef: 0.0502 - precision: 0.6127 - sensitivity: 0.8267 - specificity: 0.9930\n","Epoch 00001: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 31s 16ms/sample - loss: 0.1822 - acc: 0.9923 - dice_coef: 0.0500 - precision: 0.6143 - sensitivity: 0.8236 - specificity: 0.9931 - val_loss: 0.2184 - val_acc: 0.9978 - val_dice_coef: 0.0298 - val_precision: 0.8456 - val_sensitivity: 0.6223 - val_specificity: 0.9995\n","Epoch 2/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9981 - dice_coef: 0.0913 - precision: 0.8135 - sensitivity: 0.7134 - specificity: 0.9993\n","Epoch 00002: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0670 - acc: 0.9981 - dice_coef: 0.0919 - precision: 0.8131 - sensitivity: 0.7131 - specificity: 0.9993 - val_loss: 0.0962 - val_acc: 0.9979 - val_dice_coef: 0.0653 - val_precision: 0.8555 - val_sensitivity: 0.6560 - val_specificity: 0.9995\n","Epoch 3/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9982 - dice_coef: 0.1470 - precision: 0.8320 - sensitivity: 0.7023 - specificity: 0.9994\n","Epoch 00003: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0372 - acc: 0.9982 - dice_coef: 0.1475 - precision: 0.8330 - sensitivity: 0.7004 - specificity: 0.9994 - val_loss: 0.0480 - val_acc: 0.9981 - val_dice_coef: 0.1266 - val_precision: 0.8352 - val_sensitivity: 0.7227 - val_specificity: 0.9994\n","Epoch 4/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9982 - dice_coef: 0.2125 - precision: 0.8444 - sensitivity: 0.7114 - specificity: 0.9994\n","Epoch 00004: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0241 - acc: 0.9982 - dice_coef: 0.2106 - precision: 0.8404 - sensitivity: 0.7086 - specificity: 0.9994 - val_loss: 0.0270 - val_acc: 0.9981 - val_dice_coef: 0.2055 - val_precision: 0.8113 - val_sensitivity: 0.7331 - val_specificity: 0.9992\n","Epoch 5/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9983 - dice_coef: 0.2726 - precision: 0.8421 - sensitivity: 0.7220 - specificity: 0.9994\n","Epoch 00005: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0176 - acc: 0.9982 - dice_coef: 0.2722 - precision: 0.8417 - sensitivity: 0.7200 - specificity: 0.9994 - val_loss: 0.0180 - val_acc: 0.9982 - val_dice_coef: 0.2974 - val_precision: 0.8126 - val_sensitivity: 0.7608 - val_specificity: 0.9992\n","Epoch 6/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9983 - dice_coef: 0.3327 - precision: 0.8360 - sensitivity: 0.7387 - specificity: 0.9994\n","Epoch 00006: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0137 - acc: 0.9983 - dice_coef: 0.3339 - precision: 0.8369 - sensitivity: 0.7401 - specificity: 0.9994 - val_loss: 0.0131 - val_acc: 0.9982 - val_dice_coef: 0.3864 - val_precision: 0.8222 - val_sensitivity: 0.7477 - val_specificity: 0.9993\n","Epoch 7/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9984 - dice_coef: 0.3802 - precision: 0.8416 - sensitivity: 0.7360 - specificity: 0.9994\n","Epoch 00007: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0113 - acc: 0.9984 - dice_coef: 0.3809 - precision: 0.8429 - sensitivity: 0.7363 - specificity: 0.9994 - val_loss: 0.0107 - val_acc: 0.9983 - val_dice_coef: 0.4515 - val_precision: 0.8237 - val_sensitivity: 0.7951 - val_specificity: 0.9992\n","Epoch 8/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9984 - dice_coef: 0.4352 - precision: 0.8457 - sensitivity: 0.7538 - specificity: 0.9994\n","Epoch 00008: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0097 - acc: 0.9984 - dice_coef: 0.4351 - precision: 0.8462 - sensitivity: 0.7545 - specificity: 0.9994 - val_loss: 0.0091 - val_acc: 0.9983 - val_dice_coef: 0.5008 - val_precision: 0.8235 - val_sensitivity: 0.7899 - val_specificity: 0.9993\n","Epoch 9/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9984 - dice_coef: 0.4638 - precision: 0.8409 - sensitivity: 0.7512 - specificity: 0.9994\n","Epoch 00009: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0086 - acc: 0.9984 - dice_coef: 0.4647 - precision: 0.8417 - sensitivity: 0.7488 - specificity: 0.9994 - val_loss: 0.0085 - val_acc: 0.9983 - val_dice_coef: 0.5225 - val_precision: 0.8087 - val_sensitivity: 0.8113 - val_specificity: 0.9991\n","Epoch 10/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9985 - dice_coef: 0.5074 - precision: 0.8476 - sensitivity: 0.7695 - specificity: 0.9994\n","Epoch 00010: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0078 - acc: 0.9985 - dice_coef: 0.5096 - precision: 0.8480 - sensitivity: 0.7707 - specificity: 0.9994 - val_loss: 0.0075 - val_acc: 0.9984 - val_dice_coef: 0.5739 - val_precision: 0.8310 - val_sensitivity: 0.8073 - val_specificity: 0.9993\n","Epoch 11/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9985 - dice_coef: 0.5365 - precision: 0.8455 - sensitivity: 0.7741 - specificity: 0.9994\n","Epoch 00011: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0071 - acc: 0.9985 - dice_coef: 0.5365 - precision: 0.8462 - sensitivity: 0.7745 - specificity: 0.9994 - val_loss: 0.0075 - val_acc: 0.9984 - val_dice_coef: 0.5799 - val_precision: 0.8345 - val_sensitivity: 0.7777 - val_specificity: 0.9993\n","Epoch 12/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9985 - dice_coef: 0.5592 - precision: 0.8496 - sensitivity: 0.7795 - specificity: 0.9994\n","Epoch 00012: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0067 - acc: 0.9985 - dice_coef: 0.5588 - precision: 0.8494 - sensitivity: 0.7795 - specificity: 0.9994 - val_loss: 0.0067 - val_acc: 0.9983 - val_dice_coef: 0.6131 - val_precision: 0.8123 - val_sensitivity: 0.8268 - val_specificity: 0.9991\n","Epoch 13/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9986 - dice_coef: 0.5886 - precision: 0.8520 - sensitivity: 0.7848 - specificity: 0.9994\n","Epoch 00013: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0061 - acc: 0.9986 - dice_coef: 0.5865 - precision: 0.8523 - sensitivity: 0.7863 - specificity: 0.9994 - val_loss: 0.0065 - val_acc: 0.9983 - val_dice_coef: 0.5853 - val_precision: 0.8865 - val_sensitivity: 0.7053 - val_specificity: 0.9996\n","Epoch 14/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9986 - dice_coef: 0.5980 - precision: 0.8550 - sensitivity: 0.7813 - specificity: 0.9995\n","Epoch 00014: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0059 - acc: 0.9986 - dice_coef: 0.6007 - precision: 0.8551 - sensitivity: 0.7828 - specificity: 0.9994 - val_loss: 0.0071 - val_acc: 0.9983 - val_dice_coef: 0.6437 - val_precision: 0.8204 - val_sensitivity: 0.8094 - val_specificity: 0.9992\n","Epoch 15/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986 - dice_coef: 0.6263 - precision: 0.8564 - sensitivity: 0.7979 - specificity: 0.9994\n","Epoch 00015: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0056 - acc: 0.9986 - dice_coef: 0.6267 - precision: 0.8561 - sensitivity: 0.7982 - specificity: 0.9994 - val_loss: 0.0060 - val_acc: 0.9984 - val_dice_coef: 0.6193 - val_precision: 0.8512 - val_sensitivity: 0.7792 - val_specificity: 0.9994\n","Epoch 16/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9987 - dice_coef: 0.6326 - precision: 0.8594 - sensitivity: 0.7907 - specificity: 0.9995\n","Epoch 00016: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0052 - acc: 0.9986 - dice_coef: 0.6327 - precision: 0.8577 - sensitivity: 0.7911 - specificity: 0.9995 - val_loss: 0.0062 - val_acc: 0.9984 - val_dice_coef: 0.6509 - val_precision: 0.8616 - val_sensitivity: 0.7768 - val_specificity: 0.9994\n","Epoch 17/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9987 - dice_coef: 0.6498 - precision: 0.8645 - sensitivity: 0.7967 - specificity: 0.9995\n","Epoch 00017: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0051 - acc: 0.9987 - dice_coef: 0.6465 - precision: 0.8654 - sensitivity: 0.7959 - specificity: 0.9995 - val_loss: 0.0061 - val_acc: 0.9984 - val_dice_coef: 0.6887 - val_precision: 0.8457 - val_sensitivity: 0.7915 - val_specificity: 0.9993\n","Epoch 18/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987 - dice_coef: 0.6707 - precision: 0.8670 - sensitivity: 0.8062 - specificity: 0.9995\n","Epoch 00018: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0049 - acc: 0.9987 - dice_coef: 0.6696 - precision: 0.8660 - sensitivity: 0.8041 - specificity: 0.9995 - val_loss: 0.0065 - val_acc: 0.9982 - val_dice_coef: 0.6181 - val_precision: 0.9216 - val_sensitivity: 0.6558 - val_specificity: 0.9997\n","Epoch 19/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6750 - precision: 0.8700 - sensitivity: 0.8052 - specificity: 0.9995\n","Epoch 00019: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6765 - precision: 0.8698 - sensitivity: 0.8063 - specificity: 0.9995 - val_loss: 0.0058 - val_acc: 0.9985 - val_dice_coef: 0.6907 - val_precision: 0.8660 - val_sensitivity: 0.7813 - val_specificity: 0.9994\n","Epoch 20/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9987 - dice_coef: 0.6889 - precision: 0.8765 - sensitivity: 0.8083 - specificity: 0.9995\n","Epoch 00020: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0045 - acc: 0.9987 - dice_coef: 0.6890 - precision: 0.8769 - sensitivity: 0.8074 - specificity: 0.9995 - val_loss: 0.0067 - val_acc: 0.9982 - val_dice_coef: 0.6189 - val_precision: 0.9279 - val_sensitivity: 0.6482 - val_specificity: 0.9998\n","Epoch 21/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9987 - dice_coef: 0.6968 - precision: 0.8743 - sensitivity: 0.8078 - specificity: 0.9995\n","Epoch 00021: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0044 - acc: 0.9987 - dice_coef: 0.6953 - precision: 0.8731 - sensitivity: 0.8067 - specificity: 0.9995 - val_loss: 0.0050 - val_acc: 0.9986 - val_dice_coef: 0.7044 - val_precision: 0.8582 - val_sensitivity: 0.8108 - val_specificity: 0.9994\n","Epoch 22/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9988 - dice_coef: 0.7026 - precision: 0.8734 - sensitivity: 0.8159 - specificity: 0.9995\n","Epoch 00022: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0043 - acc: 0.9988 - dice_coef: 0.7010 - precision: 0.8739 - sensitivity: 0.8140 - specificity: 0.9995 - val_loss: 0.0074 - val_acc: 0.9971 - val_dice_coef: 0.5076 - val_precision: 0.9518 - val_sensitivity: 0.3591 - val_specificity: 0.9999\n","Epoch 23/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7090 - precision: 0.8767 - sensitivity: 0.8140 - specificity: 0.9995\n","Epoch 00023: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7098 - precision: 0.8778 - sensitivity: 0.8137 - specificity: 0.9995 - val_loss: 0.0056 - val_acc: 0.9985 - val_dice_coef: 0.7270 - val_precision: 0.8476 - val_sensitivity: 0.8014 - val_specificity: 0.9994\n","Epoch 24/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988 - dice_coef: 0.7261 - precision: 0.8845 - sensitivity: 0.8240 - specificity: 0.9995\n","Epoch 00024: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0040 - acc: 0.9988 - dice_coef: 0.7237 - precision: 0.8843 - sensitivity: 0.8225 - specificity: 0.9995 - val_loss: 0.0050 - val_acc: 0.9986 - val_dice_coef: 0.7469 - val_precision: 0.8373 - val_sensitivity: 0.8498 - val_specificity: 0.9992\n","Epoch 25/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9989 - dice_coef: 0.7367 - precision: 0.8865 - sensitivity: 0.8288 - specificity: 0.9996\n","Epoch 00025: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0038 - acc: 0.9989 - dice_coef: 0.7371 - precision: 0.8866 - sensitivity: 0.8288 - specificity: 0.9996 - val_loss: 0.0053 - val_acc: 0.9986 - val_dice_coef: 0.7427 - val_precision: 0.8469 - val_sensitivity: 0.8319 - val_specificity: 0.9993\n","Epoch 26/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9989 - dice_coef: 0.7424 - precision: 0.8892 - sensitivity: 0.8294 - specificity: 0.9996\n","Epoch 00026: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0038 - acc: 0.9989 - dice_coef: 0.7426 - precision: 0.8898 - sensitivity: 0.8302 - specificity: 0.9996 - val_loss: 0.0047 - val_acc: 0.9985 - val_dice_coef: 0.7042 - val_precision: 0.9048 - val_sensitivity: 0.7363 - val_specificity: 0.9996\n","Epoch 27/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9989 - dice_coef: 0.7531 - precision: 0.8940 - sensitivity: 0.8388 - specificity: 0.9996\n","Epoch 00027: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0035 - acc: 0.9989 - dice_coef: 0.7514 - precision: 0.8907 - sensitivity: 0.8379 - specificity: 0.9996 - val_loss: 0.0050 - val_acc: 0.9986 - val_dice_coef: 0.7508 - val_precision: 0.8911 - val_sensitivity: 0.7852 - val_specificity: 0.9996\n","Epoch 28/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9989 - dice_coef: 0.7459 - precision: 0.8853 - sensitivity: 0.8335 - specificity: 0.9996\n","Epoch 00028: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0035 - acc: 0.9989 - dice_coef: 0.7480 - precision: 0.8865 - sensitivity: 0.8350 - specificity: 0.9996 - val_loss: 0.0044 - val_acc: 0.9986 - val_dice_coef: 0.7449 - val_precision: 0.8689 - val_sensitivity: 0.8250 - val_specificity: 0.9994\n","Epoch 29/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9990 - dice_coef: 0.7671 - precision: 0.8926 - sensitivity: 0.8496 - specificity: 0.9996\n","Epoch 00029: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0033 - acc: 0.9990 - dice_coef: 0.7683 - precision: 0.8928 - sensitivity: 0.8505 - specificity: 0.9996 - val_loss: 0.0047 - val_acc: 0.9986 - val_dice_coef: 0.7648 - val_precision: 0.8633 - val_sensitivity: 0.8251 - val_specificity: 0.9994\n","Epoch 30/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7762 - precision: 0.8960 - sensitivity: 0.8528 - specificity: 0.9996\n","Epoch 00030: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7747 - precision: 0.8963 - sensitivity: 0.8512 - specificity: 0.9996 - val_loss: 0.0049 - val_acc: 0.9985 - val_dice_coef: 0.7545 - val_precision: 0.8060 - val_sensitivity: 0.8761 - val_specificity: 0.9990\n","Epoch 31/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7816 - precision: 0.9018 - sensitivity: 0.8549 - specificity: 0.9996\n","Epoch 00031: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7824 - precision: 0.9024 - sensitivity: 0.8553 - specificity: 0.9996 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.7517 - val_precision: 0.8524 - val_sensitivity: 0.8402 - val_specificity: 0.9993\n","Epoch 32/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.7846 - precision: 0.8994 - sensitivity: 0.8548 - specificity: 0.9996\n","Epoch 00032: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0030 - acc: 0.9990 - dice_coef: 0.7859 - precision: 0.8994 - sensitivity: 0.8562 - specificity: 0.9996 - val_loss: 0.0051 - val_acc: 0.9986 - val_dice_coef: 0.7793 - val_precision: 0.8723 - val_sensitivity: 0.8014 - val_specificity: 0.9995\n","Epoch 33/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.7914 - precision: 0.9006 - sensitivity: 0.8598 - specificity: 0.9996\n","Epoch 00033: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.7927 - precision: 0.9011 - sensitivity: 0.8610 - specificity: 0.9996 - val_loss: 0.0046 - val_acc: 0.9987 - val_dice_coef: 0.7799 - val_precision: 0.8974 - val_sensitivity: 0.8014 - val_specificity: 0.9996\n","Epoch 34/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9991 - dice_coef: 0.8034 - precision: 0.9076 - sensitivity: 0.8666 - specificity: 0.9996\n","Epoch 00034: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0028 - acc: 0.9991 - dice_coef: 0.8035 - precision: 0.9076 - sensitivity: 0.8667 - specificity: 0.9996 - val_loss: 0.0050 - val_acc: 0.9985 - val_dice_coef: 0.6798 - val_precision: 0.7852 - val_sensitivity: 0.8662 - val_specificity: 0.9990\n","Epoch 35/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8077 - precision: 0.9063 - sensitivity: 0.8703 - specificity: 0.9996\n","Epoch 00035: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8084 - precision: 0.9066 - sensitivity: 0.8704 - specificity: 0.9996 - val_loss: 0.0063 - val_acc: 0.9985 - val_dice_coef: 0.7945 - val_precision: 0.8461 - val_sensitivity: 0.8206 - val_specificity: 0.9993\n","Epoch 36/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8090 - precision: 0.9069 - sensitivity: 0.8723 - specificity: 0.9996\n","Epoch 00036: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8092 - precision: 0.9069 - sensitivity: 0.8724 - specificity: 0.9996 - val_loss: 0.0045 - val_acc: 0.9986 - val_dice_coef: 0.7834 - val_precision: 0.8199 - val_sensitivity: 0.8777 - val_specificity: 0.9991\n","Epoch 37/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9992 - dice_coef: 0.8179 - precision: 0.9102 - sensitivity: 0.8771 - specificity: 0.9996\n","Epoch 00037: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0025 - acc: 0.9992 - dice_coef: 0.8178 - precision: 0.9106 - sensitivity: 0.8767 - specificity: 0.9996 - val_loss: 0.0042 - val_acc: 0.9987 - val_dice_coef: 0.7881 - val_precision: 0.8950 - val_sensitivity: 0.8140 - val_specificity: 0.9996\n","Epoch 38/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8249 - precision: 0.9151 - sensitivity: 0.8806 - specificity: 0.9997\n","Epoch 00038: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8247 - precision: 0.9154 - sensitivity: 0.8800 - specificity: 0.9997 - val_loss: 0.0041 - val_acc: 0.9987 - val_dice_coef: 0.7879 - val_precision: 0.8618 - val_sensitivity: 0.8421 - val_specificity: 0.9994\n","Epoch 39/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8308 - precision: 0.9159 - sensitivity: 0.8849 - specificity: 0.9997\n","Epoch 00039: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8304 - precision: 0.9151 - sensitivity: 0.8845 - specificity: 0.9997 - val_loss: 0.0046 - val_acc: 0.9987 - val_dice_coef: 0.8102 - val_precision: 0.8829 - val_sensitivity: 0.8247 - val_specificity: 0.9995\n","Epoch 40/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8344 - precision: 0.9193 - sensitivity: 0.8868 - specificity: 0.9997\n","Epoch 00040: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8332 - precision: 0.9170 - sensitivity: 0.8867 - specificity: 0.9997 - val_loss: 0.0047 - val_acc: 0.9987 - val_dice_coef: 0.7827 - val_precision: 0.8768 - val_sensitivity: 0.7953 - val_specificity: 0.9995\n","Epoch 41/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8306 - precision: 0.9138 - sensitivity: 0.8832 - specificity: 0.9997\n","Epoch 00041: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8305 - precision: 0.9142 - sensitivity: 0.8827 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.7889 - val_precision: 0.8927 - val_sensitivity: 0.8006 - val_specificity: 0.9996\n","Epoch 42/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8344 - precision: 0.9137 - sensitivity: 0.8874 - specificity: 0.9997\n","Epoch 00042: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8339 - precision: 0.9138 - sensitivity: 0.8864 - specificity: 0.9997 - val_loss: 0.0050 - val_acc: 0.9986 - val_dice_coef: 0.7795 - val_precision: 0.8953 - val_sensitivity: 0.7776 - val_specificity: 0.9996\n","Epoch 43/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8428 - precision: 0.9165 - sensitivity: 0.8935 - specificity: 0.9997\n","Epoch 00043: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8415 - precision: 0.9167 - sensitivity: 0.8912 - specificity: 0.9997 - val_loss: 0.0045 - val_acc: 0.9986 - val_dice_coef: 0.7741 - val_precision: 0.9215 - val_sensitivity: 0.7516 - val_specificity: 0.9997\n","Epoch 44/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.8492 - precision: 0.9193 - sensitivity: 0.8987 - specificity: 0.9997\n","Epoch 00044: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.8498 - precision: 0.9201 - sensitivity: 0.8991 - specificity: 0.9997 - val_loss: 0.0041 - val_acc: 0.9987 - val_dice_coef: 0.7919 - val_precision: 0.8986 - val_sensitivity: 0.8107 - val_specificity: 0.9996\n","Epoch 45/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8569 - precision: 0.9225 - sensitivity: 0.9027 - specificity: 0.9997\n","Epoch 00045: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8568 - precision: 0.9227 - sensitivity: 0.9024 - specificity: 0.9997 - val_loss: 0.0042 - val_acc: 0.9988 - val_dice_coef: 0.8153 - val_precision: 0.8761 - val_sensitivity: 0.8469 - val_specificity: 0.9995\n","Epoch 46/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8547 - precision: 0.9234 - sensitivity: 0.9001 - specificity: 0.9997\n","Epoch 00046: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.8522 - precision: 0.9209 - sensitivity: 0.8994 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.7926 - val_precision: 0.8914 - val_sensitivity: 0.8010 - val_specificity: 0.9996\n","Epoch 47/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9993 - dice_coef: 0.8661 - precision: 0.9294 - sensitivity: 0.9088 - specificity: 0.9997\n","Epoch 00047: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8657 - precision: 0.9297 - sensitivity: 0.9080 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.8054 - val_precision: 0.8822 - val_sensitivity: 0.8196 - val_specificity: 0.9995\n","Epoch 48/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8648 - precision: 0.9245 - sensitivity: 0.9093 - specificity: 0.9997\n","Epoch 00048: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8654 - precision: 0.9247 - sensitivity: 0.9100 - specificity: 0.9997 - val_loss: 0.0042 - val_acc: 0.9987 - val_dice_coef: 0.7792 - val_precision: 0.8813 - val_sensitivity: 0.7942 - val_specificity: 0.9995\n","Epoch 49/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8651 - precision: 0.9257 - sensitivity: 0.9078 - specificity: 0.9997\n","Epoch 00049: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8648 - precision: 0.9246 - sensitivity: 0.9085 - specificity: 0.9997 - val_loss: 0.0042 - val_acc: 0.9988 - val_dice_coef: 0.8035 - val_precision: 0.9126 - val_sensitivity: 0.7929 - val_specificity: 0.9997\n","Epoch 50/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.8689 - precision: 0.9255 - sensitivity: 0.9129 - specificity: 0.9997\n","Epoch 00050: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.8688 - precision: 0.9252 - sensitivity: 0.9130 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.8152 - val_precision: 0.8516 - val_sensitivity: 0.8540 - val_specificity: 0.9993\n","Epoch 51/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8775 - precision: 0.9320 - sensitivity: 0.9164 - specificity: 0.9997\n","Epoch 00051: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8780 - precision: 0.9323 - sensitivity: 0.9167 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9988 - val_dice_coef: 0.8093 - val_precision: 0.8957 - val_sensitivity: 0.8024 - val_specificity: 0.9996\n","Epoch 52/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8764 - precision: 0.9287 - sensitivity: 0.9167 - specificity: 0.9997\n","Epoch 00052: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8766 - precision: 0.9286 - sensitivity: 0.9170 - specificity: 0.9997 - val_loss: 0.0047 - val_acc: 0.9987 - val_dice_coef: 0.8155 - val_precision: 0.9113 - val_sensitivity: 0.7943 - val_specificity: 0.9996\n","Epoch 53/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8774 - precision: 0.9290 - sensitivity: 0.9170 - specificity: 0.9997\n","Epoch 00053: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.8782 - precision: 0.9298 - sensitivity: 0.9174 - specificity: 0.9997 - val_loss: 0.0044 - val_acc: 0.9988 - val_dice_coef: 0.8246 - val_precision: 0.8643 - val_sensitivity: 0.8501 - val_specificity: 0.9994\n","Epoch 54/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8850 - precision: 0.9345 - sensitivity: 0.9214 - specificity: 0.9997\n","Epoch 00054: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8858 - precision: 0.9351 - sensitivity: 0.9220 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.8184 - val_precision: 0.8656 - val_sensitivity: 0.8385 - val_specificity: 0.9994\n","Epoch 55/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8895 - precision: 0.9356 - sensitivity: 0.9244 - specificity: 0.9997\n","Epoch 00055: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8894 - precision: 0.9353 - sensitivity: 0.9248 - specificity: 0.9997 - val_loss: 0.0047 - val_acc: 0.9987 - val_dice_coef: 0.8210 - val_precision: 0.8957 - val_sensitivity: 0.8103 - val_specificity: 0.9996\n","Epoch 56/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8874 - precision: 0.9346 - sensitivity: 0.9232 - specificity: 0.9997\n","Epoch 00056: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.8878 - precision: 0.9346 - sensitivity: 0.9236 - specificity: 0.9997 - val_loss: 0.0046 - val_acc: 0.9987 - val_dice_coef: 0.8292 - val_precision: 0.8449 - val_sensitivity: 0.8711 - val_specificity: 0.9993\n","Epoch 57/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.8942 - precision: 0.9385 - sensitivity: 0.9284 - specificity: 0.9997\n","Epoch 00057: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.8943 - precision: 0.9379 - sensitivity: 0.9291 - specificity: 0.9997 - val_loss: 0.0045 - val_acc: 0.9987 - val_dice_coef: 0.8150 - val_precision: 0.9057 - val_sensitivity: 0.7978 - val_specificity: 0.9996\n","Epoch 58/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.8905 - precision: 0.9351 - sensitivity: 0.9255 - specificity: 0.9997\n","Epoch 00058: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.8908 - precision: 0.9351 - sensitivity: 0.9261 - specificity: 0.9997 - val_loss: 0.0041 - val_acc: 0.9988 - val_dice_coef: 0.8231 - val_precision: 0.8900 - val_sensitivity: 0.8316 - val_specificity: 0.9995\n","Epoch 59/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.8952 - precision: 0.9381 - sensitivity: 0.9280 - specificity: 0.9998\n","Epoch 00059: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.8956 - precision: 0.9382 - sensitivity: 0.9283 - specificity: 0.9998 - val_loss: 0.0043 - val_acc: 0.9988 - val_dice_coef: 0.8247 - val_precision: 0.8943 - val_sensitivity: 0.8256 - val_specificity: 0.9996\n","Epoch 60/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.9001 - precision: 0.9402 - sensitivity: 0.9336 - specificity: 0.9998\n","Epoch 00060: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.8997 - precision: 0.9403 - sensitivity: 0.9330 - specificity: 0.9998 - val_loss: 0.0048 - val_acc: 0.9988 - val_dice_coef: 0.8229 - val_precision: 0.9039 - val_sensitivity: 0.8010 - val_specificity: 0.9996\n","2499/2499 [==============================] - 8s 3ms/sample - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.8755 - precision: 0.9442 - sensitivity: 0.8703 - specificity: 0.9998\n","441/441 [==============================] - 2s 4ms/sample - loss: 0.0040 - acc: 0.9989 - dice_coef: 0.8439 - precision: 0.9198 - sensitivity: 0.8233 - specificity: 0.9997\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.003964840076534319,\n"," 0.9989239,\n"," 0.84387165,\n"," 0.9197561,\n"," 0.82326454,\n"," 0.99969274]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"jbM4w01ljUkk","colab_type":"code","outputId":"70e56d32-6d0e-4849-9cd1-54915d2f1af4","executionInfo":{"status":"ok","timestamp":1584080447824,"user_tz":-330,"elapsed":3873,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Accuracy vs Epoch\n","def Accuracy_Graph(history):\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    #plt.title('Model accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","    \n","# Dice Similarity Coefficient vs Epoch\n","def Dice_coefficient_Graph(history):\n","\n","    plt.plot(history.history['dice_coef'])\n","    plt.plot(history.history['val_dice_coef'])\n","    #plt.title('Dice_Coefficient')\n","    plt.ylabel('Dice_Coefficient')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","# Loss vs Epoch\n","def Loss_Graph(history):\n","\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    #plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","Accuracy_Graph(history)\n","Dice_coefficient_Graph(history)\n","Loss_Graph(history)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdoAAAFNCAYAAACnh65UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAc4AAAFNCAYAAACJwo/GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdQAAAFNCAYAAAC5Tp7nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5RcdZ3v/fe3rl3V3bknJOkQEm65\ncUlCBkQFiaCi4yHiMMjtWeA4w3p49NEzHuccxmctnWEOazFz5vEgZ3wccQR1zgjj6EGj4nAYxduo\nkICAJAGBEKBzJ0mn71237/PH3tVdXVR3VydVqU7X57VWrX2pXbt+u1Lpz/5dam9zd0REROT4RBpd\nABERkelAgSoiIlIDClQREZEaUKCKiIjUgAJVRESkBhSoIiIiNRBrdAFqZd68eb5s2bJGF0NERKax\nJ5988g13n1/puWkTqMuWLWPr1q2NLoaIiExjZvbqWM+pyVdERKQGFKgiIiI1oEAVERGpgWnTh1pJ\nNpuls7OTwcHBRhdlWmlpaWHJkiXE4/FGF0VEZMqY1oHa2dlJe3s7y5Ytw8waXZxpwd05dOgQnZ2d\nLF++vNHFERGZMqZ1k+/g4CBz585VmNaQmTF37lzV+kVEykzrQAUUpnWgz1RE5M2mfaA20qFDh1i7\ndi1r165l4cKFdHR0DC9nMpmq9vHhD3+YF154oc4lFRGR4zWt+1Abbe7cuTz99NMA/MVf/AVtbW18\n6lOfGrWNu+PuRCKVz23uv//+updTRESOn2qoDfDSSy+xevVqbrzxRtasWcPevXu59dZb2bBhA2vW\nrOGOO+4Y3vbtb387Tz/9NLlcjlmzZnH77bdz/vnnc/HFF3PgwIEGHoWIiJRqmhrqX35vG9v3dE+8\nYX4ICgWIpybcdPXiGXz2P6w5pvI8//zzfP3rX2fDhg0A3HXXXcyZM4dcLsfGjRu55pprWL169ajX\nHD16lHe84x3cddddfPKTn+S+++7j9ttvP6b3FxGR2lINtZw7UKj725xxxhnDYQrwwAMPsH79etav\nX8+OHTvYvn37m16TSqV473vfC8AFF1zArl276l5OERGpTtPUUKuuSXa9DgNHYNF5dS1Pa2vr8PyL\nL77I5z//eZ544glmzZrFTTfdVPFnKYlEYng+Go2Sy+XqWkYREameaqjlIhHw+tdQS3V3d9Pe3s6M\nGTPYu3cvjzzyyAl9fxEROX5NU0OtmkUAD5p+T9DvLdevX8/q1atZuXIlp512Gm9729tOyPuKiEjt\nmLs3ugw1sWHDBi+/H+qOHTtYtWrV5HbUux+698DC8yASrWEJp5dj+mxFRE5yZvaku2+o9JyafMtZ\n+JGc4GZfERE5uSlQy1lYK1WgiojIJChQy6mGKiIix0CBWk6BKiIix0CBWq4YqIV8Y8shIiInFQVq\nOdVQRUTkGChQy9U4UDdu3PimCzXcfffd3HbbbWO+pq2tDYA9e/ZwzTXXVNzmsssuo/xnQuXuvvtu\n+vv7h5ff97730dXVVW3RRURkEhSo5WocqNdffz0PPvjgqHUPPvgg119//YSvXbx4Md/61reO+b3L\nA/Xhhx9m1qxZx7w/EREZmwK1XKS2gXrNNdfwgx/8YPiG4rt27WLPnj2sW7eOyy+/nPXr13Puuefy\n3e9+902v3bVrF+eccw4AAwMDXHfddaxatYqrr76agYGB4e1uu+224Vu/ffaznwXgnnvuYc+ePWzc\nuJGNGzcCsGzZMt544w0APve5z3HOOedwzjnncPfddw+/36pVq/iTP/kT1qxZw7vf/e5R7yMiImNr\nnksP/vB22PfbKjZ0yPRCNAnRxPibLjwX3nvXuJvMmTOHCy+8kB/+8Ids2rSJBx98kGuvvZZUKsVD\nDz3EjBkzeOONN3jLW97CVVddhY1xucMvfvGLpNNpduzYwbPPPsv69euHn7vzzjuZM2cO+Xyeyy+/\nnGeffZaPf/zjfO5zn+Oxxx5j3rx5o/b15JNPcv/99/P444/j7lx00UW84x3vYPbs2bz44os88MAD\nfPnLX+baa6/l29/+NjfddFMVn5uISHNTDfVNLHzU7pKMpc2+xeZed+fTn/405513HldccQW7d+9m\n//79Y+7jZz/72XCwnXfeeZx33sjdcL75zW+yfv161q1bx7Zt2yre+q3UL37xC66++mpaW1tpa2vj\ngx/8ID//+c8BWL58OWvXrgV0izgRkclonhrqBDXJUfY+C+k5MHNJTd5606ZN/Omf/ilPPfUU/f39\nXHDBBXz1q1/l4MGDPPnkk8TjcZYtW1bxlm0TeeWVV/jbv/1btmzZwuzZs7nllluOaT9FyWRyeD4a\njarJV0SkSqqhVmK1vYVbW1sbGzdu5I/+6I+GByMdPXqUBQsWEI/Heeyxx3j11VfH3cell17KN77x\nDQCee+45nn32WSC49VtrayszZ85k//79/PCHPxx+TXt7Oz09PW/a1yWXXMJ3vvMd+vv76evr46GH\nHuKSSy6p1eGKiDSlugaqmV1pZi+Y2UtmdnuF5z9pZtvN7Fkz+5GZnVby3M1m9mL4uLme5XxzwSNQ\nqO3vUK+//nqeeeaZ4UC98cYb2bp1K+eeey5f//rXWbly5bivv+222+jt7WXVqlV85jOf4YILLgDg\n/PPPZ926daxcuZIbbrhh1K3fbr31Vq688srhQUlF69ev55ZbbuHCCy/koosu4o//+I9Zt25dTY9X\nRKTZ1O32bWYWBX4HvAvoBLYA17v79pJtNgKPu3u/md0GXObuHzKzOcBWYANBZ+aTwAXufmSs96vZ\n7dsADjwP0TjMPWPyr20Sun2biDSjRt2+7ULgJXff6e4Z4EFgU+kG7v6Yuxd/KPlroNhp+R7gUXc/\nHIboo8CVdSzraDVu8hURkemvnoHaAbxestwZrhvLR4BiB+BkX1tbEQWqiIhMzpQY5WtmNxE0775j\nkq+7FbgVYOnSpTUsUAQ8W7v9iYjItFfPGupu4NSS5SXhulHM7Arg/wGucvehybzW3e919w3uvmH+\n/PkVC3FMfcRq8h1XvfrdRUROZvUM1C3AWWa23MwSwHXA5tINzGwd8CWCMD1Q8tQjwLvNbLaZzQbe\nHa6blJaWFg4dOjT5AFCgjsndOXToEC0tLY0uiojIlFK3Jl93z5nZxwiCMArc5+7bzOwOYKu7bwb+\nG9AG/Et4yb3X3P0qdz9sZn9FEMoAd7j74cmWYcmSJXR2dnLw4MHJvXCgK7j84JEp0SI+5bS0tLBk\nSW0ueiEiMl3U7WczJ1qln80csx/fCT/7b/DZIzDGtXVFRKT5NOpnMyevRBpwyOqyeyIiUh0FaiXx\n1mCa7R9/OxERkZACtZJEOphm+hpbDhEROWkoUCuJh4GqGqqIiFRJgVpJImzyzShQRUSkOgrUSoZr\nqGryFRGR6ihQKxnuQ1UNVUREqqNArWR4lK9qqCIiUh0FaiWqoYqIyCQpUCvR71BFRGSSFKiV6Heo\nIiIySQrUSmItgKmGKiIiVVOgVmIW/BZVfagiIlIlBepY4mmN8hURkaopUMeSSKuGKiIiVdMdtMvs\nPNhLz2CO8+Ot6kMVEZGqKVDL/Pd/e5Hfdnbxk9lpjfIVEZGqqcm3TGsiSn8mH/ahqoYqIiLVUaCW\nSSdiQaBqlK+IiEyCArVMOhGlL5PDNcpXREQmQYFaJp2M4g75WEo1VBERqZoCtUxrIhinlY2k1Icq\nIiJVU6CWSSWiAGQjLcEoX/cGl0hERE4GCtQyxRrqUCQFnod8psElEhGRk4ECtUw6GdRQBy0ZrNBv\nUUVEpAoK1DLpeBCoQ7QEK9SPKiIiVVCglmlNBk2+/RRrqApUERGZmAK1TDoclNTvYaDqt6giIlIF\nBWqZdDgoqc9VQxURkeopUMsUByX1eiJYoT5UERGpggK1THFQUk9eo3xFRKR6CtQysWiERCxCTyEe\nrFANVUREqqBAraA1EeVoLmzyVQ1VRESqoECtIJ2I0ZUP772uGqqIiFRBgVpBOhGlOxs2+WqUr4iI\nVEGBWkE6GaM36xBL6XeoIiJSFQVqBa2JKP1DOUikVUMVEZGqKFArSCei9GfyEG9VH6qIiFRFgVpB\nOhGjP1OsoarJV0REJqZAraA1GaUvk4d4WjVUERGpigK1glQ8xkAmD4lW9aGKiEhVFKgVBDXUHB5P\na5SviIhURYFaQSoRxR3ysRRkBxpdHBEROQkoUCtoDW/hloum1OQrIiJVUaBWULzJeDaiCzuIiEh1\nFKgVFG8ynom0qIYqIiJVUaBWULzJ+JAlIT8EhXyDSyQiIlOdArWCYh/qkLUEK3RxBxERmYACtYJi\nH+oAyWCFLu4gIiITUKBWMBKoqqGKiEh1FKgVtCaDJt8+TwQrVEMVEZEJKFArSIU11D4Pm3w10ldE\nRCZQ10A1syvN7AUze8nMbq/w/KVm9pSZ5czsmrLn8mb2dPjYXM9ylkvHg0DtzRf7UNXkKyIi44vV\na8dmFgW+ALwL6AS2mNlmd99estlrwC3ApyrsYsDd19arfOOJRSMkYxF6CvFghWqoIiIygboFKnAh\n8JK77wQwsweBTcBwoLr7rvC5Qh3LcUzSiSjdefWhiohIderZ5NsBvF6y3Bmuq1aLmW01s1+b2Qcq\nbWBmt4bbbD148ODxlPVN0okYR/PFGqqafEVEZHxTeVDSae6+AbgBuNvMzijfwN3vdfcN7r5h/vz5\nNX3z1mSUrqxqqCIiUp16Bupu4NSS5SXhuqq4++5wuhP4CbCuloWbSCoRoyuvPlQREalOPQN1C3CW\nmS03swRwHVDVaF0zm21myXB+HvA2SvpeT4TWRJSeDBCJa5SviIhMqG6B6u454GPAI8AO4Jvuvs3M\n7jCzqwDM7PfMrBP4Q+BLZrYtfPkqYKuZPQM8BtxVNjq47tKJGH2ZPCTSqqGKiMiE6jnKF3d/GHi4\nbN1nSua3EDQFl7/ul8C59SzbRNKJKAOZHMRbVUMVEZEJTeVBSQ3VmoyqhioiIlVToI4hnYjRP5SD\neFqjfEVEZEIK1DGkE1H6s3k80arfoYqIyIQUqGNIJ2K4QyGWUg1VREQmpEAdQ/GeqLloSn2oIiIy\nIQXqGEYFqkb5iojIBBSoYyjeZDwTaVENVUREJqRAHUPxJuOZiPpQRURkYgrUMbQmghrqkLUEgVqY\ncneYExGRKUSBOoZiH+oAyWBFbqCBpRERkalOgTqGYqAO0hKsUD+qiIiMQ4E6huKgpP5iDVUjfUVE\nZBwK1DEUa6h9HgaqaqgiIjIOBeoY0uGgpL5CIlihkb4iIjIOBeoYohEjGYvQUwxUXc9XRETGoUAd\nR2syRrdqqCIiUgUF6jhS8Sjd+XiwoBqqiIiMQ4E6jtZklKNZ1VBFRGRiCtRxpBMxunLFGqoCVURE\nxqZAHUc6ER0JVP0OVURExqFAHUc6EaMrEwGLqIYqIiLjUqCOozUZpT+bh3ir+lBFRGRcCtRxpBNR\n+jN5SKQ1yldERMalQB1HOhGjfygH8bRqqCIiMi4F6jhaE0GTryfS6kMVEZFxKVDHkUrEcIdCLK1R\nviIiMi4F6jhak8EdZ/KxlGqoIiIyLgXqOIp3nMlFU+pDFRGRcSlQx1G8J2o2ktIoXxERGZcCdRzF\nQM1EVEMVEZHxKVDHUWzyzURa1IcqIiLjUqCOo1hDHbRkMMrXvcElEhGRqUqBOo7WZFBDHaQFvAC5\noQaXSEREpioF6jiKNdQBksEK9aOKiMgYqgpUMzvDzJLh/GVm9nEzm1XfojVeMVD7PQxUjfQVEZEx\nVFtD/TaQN7MzgXuBU4Fv1K1UU0RxUFKvq4YqIiLjqzZQC+6eA64G/oe7/xmwqH7FmhqiESMZi9BX\nSAQrVEMVEZExVBuoWTO7HrgZ+H64Ll6fIk0trckYPcVAVQ1VRETGUG2gfhi4GLjT3V8xs+XAP9av\nWFNHOhGlO1+soSpQRUSkslg1G7n7duDjAGY2G2h397+uZ8GminQiSneuWENVk6+IiFRW7Sjfn5jZ\nDDObAzwFfNnMPlffok0N6USMrnx43qEaqoiIjKHaJt+Z7t4NfBD4urtfBFxRv2JNHa3JKEdy6kMV\nEZHxVRuoMTNbBFzLyKCkppCKxziSDcdfaZSviIiModpAvQN4BHjZ3beY2enAi/Ur1tTRmozSlQk/\nJtVQRURkDNUOSvoX4F9KlncCf1CvQk0l6USMvqxDPK0aqoiIjKnaQUlLzOwhMzsQPr5tZkvqXbip\nIJ2I0j+UCwJVNVQRERlDtU2+9wObgcXh43vhummvNRGlP5vHE2mN8hURkTFVG6jz3f1+d8+Fj68C\n8+tYrikjnYzhDh5L63eoIiIypmoD9ZCZ3WRm0fBxE3CongWbKop3nMnHVEMVEZGxVRuof0Twk5l9\nwF7gGuCWOpVpSinecSYfS6kPVURExlRVoLr7q+5+lbvPd/cF7v4BmmSUb2tYQ81FUxrlKyIiY6q2\nhlrJJyfawMyuNLMXzOwlM7u9wvOXmtlTZpYzs2vKnrvZzF4MHzcfRzmPSyoM1IwlVUMVEZExHU+g\n2rhPmkWBLwDvBVYD15vZ6rLNXiNoOv5G2WvnAJ8FLgIuBD4bXpT/hGtNBk2+mUhKfagiIjKm4wlU\nn+D5C4GX3H2nu2eAB4FNo3bgvsvdnwUKZa99D/Coux929yPAo8CVx1HWY5aKBzXUoUiLRvmKiMiY\nxr1Skpn1UDk4DUhNsO8O4PWS5U6CGmc1Kr22o8rX1lSxhjpEUjVUEREZ07iB6u7tJ6ogx8LMbgVu\nBVi6dGld3qM4KGmAFihkIZ+FaLwu7yUiIiev42nynchu4NSS5SXhupq91t3vdfcN7r5h/vz6XGci\nNRyoyWCFRvqKiEgF9QzULcBZZrbczBLAdQSXL6zGI8C7zWx2OBjp3eG6E674O9Q+DwNVI31FRKSC\nugWqu+eAjxEE4Q7gm+6+zczuMLOrAMzs98ysE/hD4Etmti187WHgrwhCeQtwR7juhItGjJZ4hF4P\nbzKuflQREamgqtu3HSt3fxh4uGzdZ0rmtxA051Z67X3AffUsX7XSiRjdng4WBrsaWxgREZmS6tnk\nO22kE1EOMCdY6N7T2MKIiMiUpECtQmsixh4PA7Vnb2MLIyIiU5ICtQqpRJQDuTaIJqC72oHKIiLS\nTBSoVWhNRunPFmDGYjX5iohIRQrUKqQTMfozeZjRoUAVEZGKFKhVSCei9Gdy0L5ITb4iIlKRArUK\n6USMvqF82OS7F3yi+wKIiEizUaBWoTURZSCTC5p880PQ35BrTIiIyBSmQK1COhGlP5un0L4oWKFm\nXxERKaNArUI6GcMdMq0LgxUamCQiImUUqFUo3sKtv6UYqKqhiojIaArUKqTCO870RueARVVDFRGR\nN1GgVqFYQ+3LObQvVKCKiMibKFCrkE4GNdTg4g6L1eQrIiJvokCtQrrYh5rJBYGqC+SLiEgZBWoV\nioEaXNyhA47u1sUdRERkFAVqFVrDQUkD2bCGmu2Doe4Gl0pERKYSBWoVRtdQFwcrNTBJRERKKFCr\nMDIoKQftxUDVwCQRERmhQK1CKl4clKQaqoiIVKZArUI0YrTEI0GgDl/PVyN9RURkhAK1Sq2JGH1D\nOYgloHWBmnxFRGQUBWqVUokoA5l8sDBjsZp8RURkFAVqlVoTMfoyuWBhRocCVURERlGgVimdjAZ9\nqKDLD4qIyJsoUKuUTpQG6iIY7IJMf2MLJSIiU4YCtUrp4qAkCJp8Qdf0FRGRYQrUKrUmogxkS5p8\nQc2+IiIyTIFapVQiFlx6EEZqqBqYJCIiIQVqlVoT0eDSg1BycQfVUEVEJKBArVI6GWMgm6dQcEik\nITVbNVQRERmmQK1SOhHFHQZzYbNvuy7uICIiIxSoVWotvYUb6GpJIiIyigK1SuniTcZ1+UEREalA\ngVql9pYgUI/0Z4IVMzqg7wDkMg0slYiITBUK1CqdPr8NgBcP9AYrir9F1cUdREQEBWrVls1Nk4hF\neGFfd7BCNxoXEZESCtQqxaIRzlrQxvP7eoIVwxd30G9RRUREgTopKxa288JwoBYv7qAaqoiIKFAn\nZeXCdg70DHGkLwPJGZBoUx+qiIgACtRJWbFwBkDQ7Gum+6KKiMgwBeokrFzYDjB6YJKafEVEBAXq\npCxoTzIrHeeF/SUDkxSoIiKCAnVSzIyVC9tLRvouhp59kM81tmAiItJwCtRJWrlwBr/b1xPcdaZ9\nEXg+uGKSiIg0NQXqJK1Y2E5fJs/uroGS36JqpK+ISLNToE7SinBg0vP7ekqulqSRviIizU6BOkln\nn1Iy0ne4hqqBSSIizU6BOkltyRinzkkFNdT0HIgmVUMVEREF6rFYccqM4BKEwxd3UA1VRKTZKVCP\nwcqF7ex8o4+hXF6BKiIiQJ0D1cyuNLMXzOwlM7u9wvNJM/vn8PnHzWxZuH6ZmQ2Y2dPh4+/rWc7J\nWrGwnXzBeflAX/hbVAWqiEizi9Vrx2YWBb4AvAvoBLaY2WZ3316y2UeAI+5+ppldB/w18KHwuZfd\nfW29ync8hi9BuL+b1cUaqnvQBCwiIk2pnjXUC4GX3H2nu2eAB4FNZdtsAr4Wzn8LuNxs6qfSsnmt\nJKKR8KczHZDPQP+hRhdLREQaqJ6B2gG8XrLcGa6ruI2754CjwNzwueVm9hsz+6mZXVLHck5aPBrh\njAVtwcAk/RZVRESYuoOS9gJL3X0d8EngG2Y2o3wjM7vVzLaa2daDBw+e0AKuXNjO83tLA1X9qCIi\nzayegbobOLVkeUm4ruI2ZhYDZgKH3H3I3Q8BuPuTwMvA2eVv4O73uvsGd98wf/78OhzC2FYsbGdf\n9yDd8QXBCtVQRUSaWj0DdQtwlpktN7MEcB2wuWybzcDN4fw1wI/d3c1sfjioCTM7HTgL2FnHsk5a\n8RKEO7qTwcUdDr3c4BKJiEgj1W2Ur7vnzOxjwCNAFLjP3beZ2R3AVnffDHwF+Eczewk4TBC6AJcC\nd5hZFigA/6e7H65XWY/F8Ejfg/1cdOqF8Oq/N7hEIiLSSHULVAB3fxh4uGzdZ0rmB4E/rPC6bwPf\nrmfZjtfCGS3MaIkFI32XvR1+chcMdEFqVqOLJiIiDTBVByVNecHNxsNLEC57O+Dw2q8aXSwREWkQ\nBepxWLGwnd/t68E7Lgj6UXf9otFFEhGRBlGgHocVC9vpGcqxu9fh1Ath188bXSQREWkQBepxGB6Y\nVGz23fts0I8qIiJNR4F6HM4OA/V59aOKiDQ9BepxmNESp2NWKqihdmxQP6qISBNToB6nFQvbg0CN\nt6gfVUSkiSlQj9OKhe28fLCXTK6gflQRkSamQD1OKxe2kys4O9/oVT+qiEgTU6AepxWlI33Vjyoi\n0rQUqMfp9HlttMQj/Hrn4aAfdcnvqR9VRKQJKVCPUyIW4X3nLuJ7z+yhbyinflQRkSalQK2BGy9a\nSu9Qjs3P7CnpR/11o4slIiInkAK1BtYvnc2KU9p54InXgibfaFLNviIiTUaBWgNmxg0XLeXZzqM8\nd2Ao7EfVwCQRkWaiQK2RD6zroCUe4Z8efy1o9t2nflQRkWaiQK2Rmak47z9vMZuf3s1Ax8XgBfWj\niog0EQVqDd1w0VL6Mnm++0aH+lFFRJqMArWG1p06i5UL2/mfT+5TP6qISJNRoNZQcXDSc7u72T9n\ng/pRRUSaiAK1xj6wroNUPMp3u05XP6qISBNRoNbYjJY4/+H8Rfx/L8/G1Y8qItI0FKh1cP2FS+nK\nRDkw41z43SNQyDe6SCIiUmcK1DpYe+osVi2awVcyV8ChF+GprzW6SCIiUmcK1DooDk6699C59C68\nCH70VzBwpNHFEhGROlKg1smmtYtJxWPcm741CNOf/k2jiyQiInWkQK2TGS1xPvR7p3LP9hSdp18L\nT9wLB19odLFERKROFKh1dPt7V3Jux0xuePld5GNp+Nfbwb3RxRIRkTpQoNZRSzzK3/8fF9AXm8Xf\n2x/Cyz8ORv2KiMi0o0Cts45ZKf7uhvXc03MZe+NL8Uf+HHKZRhdLRERqTIF6Alx8xlxu//1zub3v\neuzwTnj87xtdJBERqTEF6glyy1uXMW/t7/Oj/Dpyj90FPfsbXSQREakhBeoJYmbcefU5/Mu82/Ds\nIN0/+EyjiyQiIjWkQD2BWuJRPnPzVTwQ+X3anv9njvz7VxpdJBERqREF6gm2eFaKNTfexS/9PGY/\n+klefOjORhdJRERqQIHaABec2cGS/+u7/DR+CWc98zf86ksfJZvTBfRFRE5mCtQGWXbKbC761P/i\n8bkf4OK9/5Of/L83sOdwb6OLJSIix0iB2kAtyQQXfeyr/G7Fbbxr4F/Zfs8H+cm21xtdLBEROQYK\n1EYz4+zr7+LQJXdwBY8Te/BD/Nk//pRnO7saXTIREZmEWKMLIIG5l3+CzOz5vHXzx1j30rU88MJG\nvrToOq7eeDHvXLmASMQaXUQRERmH+TS5WPuGDRt869atjS7G8dv3W7I//zzR7Q9R8AIP5y/i4fY/\n4NJ3vIcPru+gJR5tdAlFRJqWmT3p7hsqPqdAnaKOdpL/9RcpbLmfeK6PXxdW8c/2XjjrCi47ZxmX\nrVjAzFS80aUUEWkqCtST2WA3/tTXyPziCyT79zJIgp/nz+XffAPdS6/greeezTtXnULHrFSjSyoi\nMu0pUKeDfA5e+yW+4/tktn2fZN9u8kTYUljBj/NrOZRcSmrBcuYvOZMzly5hzeIZLJ2TVt+riEgN\nKVCnG3fY+ww8/32GnvseycPPj3q621Ps9nnsswUcaT2DwXlraFmyloXLV3P2opnMa0s2qOAiIic3\nBep01/cGdL0KXa+TPbyLo3tfYeiNXcS6X2Pu4KvECK7C1OdJnvelvBw9nWzrImamEsxIxZmZTjAj\nlWBmKk57exvxuWfA3DNg1lKINnk/rTvsfjL4HBaeB6Yav0gzGy9Q9bOZ6aB1XvDouIA4MK/0udwQ\nfmAHPbt+Q++rT9Gx/znWdP+clt5+mODCTDmiHIovoqvlVPralhJLzyKVSpFOpUmn07S1poknUpDp\ng5594WNPON0L2UFYeA4sXg8d64Pp3DMhchw/f85nYbAbBruCx1AvtJ0ShH8iPfbr+g7BgW2wfztk\neuHsK+GUNWMHZCEPOzbDv7q0ZDwAABBDSURBVN8De54K1s1eBqs/AKs3weJ1ClcRGUU11GbkDrkh\nwMnm8+w/OsjuIwPsOdrPG4ePYIdfIdn9Cm19rzJ38DVOye2hw/fRZoNj7jJPhK7IHLrjc+mNz6e/\nZQHRWJzFA79jfu/zxPMDAOTibQzNW0M0liRWGCJaGMSyA0H45gbAC2CRskcUPA+DR4MwHEvbwiD0\nZp8WTDN9sH8bHNgOvRXuPzv3zCAg11w9Eq7ZAXj6n+CXfwdHXoE5p8PFH4VoArZ9B175KRRyMOu0\nIFjPfg/MOSMI9eM5UZiOCvngs3/t1/Dar4JpIQ+r3h985ksvhoh+BiYnFzX5ynHL5Qsc6h3iYFcv\nh7q7OXS0l67uHrp6ejmUibI320ZPxukZzNGXydE7mKNnMEeu4EQocKbt5vzIy5xnO1kVeQ2AQY8z\nSIJ8JEkh2kIh1kIkGiMecWIGMXNiESdmTiQSJRtvJ5+YQS45E0/OxFtmEkm00p47xIzBPbT1d5Lu\ne51k7+vEe/dANEl+3gp8wWoiC9cQXbgGFoTBueN7sP07sOsXQYjPPRNOeys8/wPoPwQdF8DbPgEr\n3z/6j37/YXjh4SBcdz4WhCtANBnUkmefFoTtzA7IZWCoO6hRDx0Np90QS0H7wuDRdgq0L4L2UyDR\nDpkeGCp9dAcnG63zg33O6ICZS4Ll8hqyO2T7gxOJTG847Q/mi+vzmeD9Zp0Gs06FeIXR4UM98Mbv\n4OALwWOoOyhn24LgpKXtlKC8qdnBSU7/oaDbof9QOH8Q9vwGXn8ieC0E77n0LUGgvvhocPLUdgqs\nugrWfKB24eoevGchP3od4d+5RGvlYy7KZ6HrNTi8Ew6/An0HID0vON72ReGxLxx/H9NBLhN8D2IJ\niLce+8liPgcDh2GgK/j3jbUEn10sGczX84TKPfj/2rsv+J6e9taa7FaBKg3h7gzlCvQM5ugdytEz\nmKV3MEf3YDDfPZijeyBL92CW7oEcRweyDGbzDGbzDOUKDOXCabbAYC4fPleo6r3j5MgToVBydc2I\nQTIWJRGLEI8a0Ygxz7rZWHiCjYV/5/z8Nn4TX8/3269lZ/o8WhIxWuJRWmIRkvEIiWjw2kTUSMQi\ntHkvS3q3MSuzh5lDe2gb2E1r/25SfZ3EM0cByMfb8OQMSLZDy0wiLe1Bjbx3P9azD7J9Ex+MRYLQ\nLxVNwIzFEIkFzd7FEGWS/5+LzeUzT4WBI0GQdu8eeT4SD8o+cHgSOzWYvzII0KUXB9NZS0dOAIZ6\n4cVHgpOSYrimZgeB1TILUrNGT6Px8LU2eprpD/5Y9uwvme6HQnb84sVaRvafmh3M5waDED3aGbSG\nTCQ5E9rmB2HbOg/Sc8PpvCAwCrk3P/LF+WwQ+PnsyHL55zf8+UeDf+NIHKLFaTxY74TfCx85afBC\nsG/PB9NCbmTqeSgUgm08P7JtPhME3mBXMB048ubvZbwVkm2QaBs5KYnESsoXPgq5IMQGDgcnV4NH\nx/8ci8eDlbRIhfOxZPDvk5oD6eJ0TvDv5fkg9PNDweeYGwrm+w8H34GefcE0nwneJ9EOn+6c+N+1\nCgpUmTaKIV0M2YFMPgzbAoPZPAPZPEPD08JwMGdyxfkCmVyBXKFALu/kCk4uXyBXcLK5PEN5Hw7u\nYrAPZPJk8sHrMrkCmfzEod7CEBniowK9klYGWGBdnGJdzIgMko21kou1U0i04ck2SLQTS7Qw048y\nJ3eQOfmDzMkdCKcHiRrkY2ny8TYK8TQkWvFEG5ZohXBqyVYiyTaiLa3EYknSg/to6dtNS18nyd7g\nEe95HU/OJDfnLPLzzsbnnk1k/koic5cTSySIeZ5o/8Hgj1TxMXAEWmYGITIcKHPDEKxyeEYxXHf+\nJPxDXPKHfbBr/CZ+CN6vbWFQgyxO0/PCmo+V1OLDaaan5D2OhAHSFfxRn7M8aOKfczrMDudb5wfh\nUBwj0LtvZL7/jZGaeXE6URhbZHQoRsKphd+TUX+Pw4AsBm8+G4Rv+cnV6DcYHXIWDZfDdcUuFLOR\n940m3nyCkZoNLTOCoMr0hidtvSPz+aGSwC45YTAL/k1GPeYE+yvkg5On3FDQtZIbCpYLueC4vVAy\nLQQnOQNHSgI6nBZbhSD4/GLJ4BiiifDErKw1oX1h8N1Y+paajHtQoIrUkLuTzTuZfIGhbBC2g9mw\nRh2GeGlNezCbZzAXbDuYzZMr+PDfTQ92iAPZvDOQydGfydOfDU4W+jM5BrKFsj+0I6/N5ArB9pl8\n8NpsvtKmNWEGsYgRi0SIRYxoNJiPR41Y1IhHIsSK68KafDwaGX4kYxGiESNiEIkYEQvnzYhEjEQ0\nErYARMJWhAjJSJ6WqJOIQsyMeMyC/UaMSLyFaDxJNGLDj1i437H+bhrBc2Yl8+GxmRkGw68vTmOR\noNzFVo3SZSt9o0IhCOrcYEmNMlYWbjXoZy8UglAp1uaKJw7NMEiu2K1h0SBAGzBuoWGjfM3sSuDz\nQBT4B3e/q+z5JPB14ALgEPAhd98VPvfnwEeAPPBxd3+knmUVqZaZkYiFzb7JqTVQvliDL9aqh7Il\nTedhbb1QgFyhQMGdXN6DaSGYz4a19Vy+QHbUspMvFMgWnHwhXF9ewx9eN/LabL5A31COTHFf+QIF\nh4IHJxUFD/ZXcB+u/WfzwbqTQSIWIVk8EYiNnAhEw5OEaISRebPRQV4yX3rSEQ+7FOLRILhHTr7K\nTsTGELWRk4vgpGfkJKD8xCMaCcpWeiIxfIIR1uorvW/EIFo8sSq+VyQ4sSrud+QzGP8kJ2LFbRlV\ntsg4JwhmeSLhIMlIZOTErHgiVNynRUb2n0rUfwBc3f4amFkU+ALwLqAT2GJmm919e8lmHwGOuPuZ\nZnYd8NfAh8xsNXAdsAZYDPybmZ3tXk3nhkjzMrOg3/ckv4lCvuDDTezZQhDM2ZyHgTvyyIcnB/kw\n6POFIOQrCUIhCAcPlz2MiIIHJyPFdYVCsE2h4OR95KQhOJkonnAUGCrtChg+ISiWZ/QJQ74wsn/3\nsDuT4ASjLxN0S2TD/RWnhTDJijXhYtgxvPSmo6TgwSDC4mdRLHcza0vGeO4v31P396nn6fWFwEvu\nvhPAzB4ENgGlgboJ+Itw/lvA31nwzdkEPOjuQ8ArZvZSuL9f1bG8IjJFRCNBjeJE1CqagYeBnncf\ndfJRXEd4klHw0hMOrxjkhg2fIARhPdKKUQzv4ROJkvesWK7hsjHqdcX5sSqpQetGsbxBmfPFsg+f\nxIwcT/QEXYK1noHaAbxestwJXDTWNu6eM7OjwNxw/a/LXttR/gZmditwK8DSpUtrVnARkenELGiO\nnVodFNPPSf1LdHe/1903uPuG+fPnN7o4IiLSxOoZqLuBU0uWl4TrKm5jZjFgJsHgpGpeKyIiMmXU\nM1C3AGeZ2XIzSxAMMtpcts1m4OZw/hrgxx78jmczcJ2ZJc1sOXAW8EQdyyoiInJc6takHvaJfgx4\nhOBnM/e5+zYzuwPY6u6bga8A/xgOOjpMELqE232TYABTDvioRviKiMhUpgs7iIiIVGm8Czuc1IOS\nREREpgoFqoiISA0oUEVERGpAgSoiIlIDClQREZEaUKCKiIjUwLT52YyZHQRerdHu5gFv1GhfJ5tm\nPnZo7uPXsTenZj52mPzxn+buFa91O20CtZbMbOtYvzOa7pr52KG5j1/HrmNvRrU8fjX5ioiI1IAC\nVUREpAYUqJXd2+gCNFAzHzs09/Hr2JtTMx871PD41YcqIiJSA6qhioiI1IACtYyZXWlmL5jZS2Z2\ne6PLU09mdp+ZHTCz50rWzTGzR83sxXA6u5FlrBczO9XMHjOz7Wa2zcw+Ea6f9sdvZi1m9oSZPRMe\n+1+G65eb2ePhd/+fw/sYT0tmFjWz35jZ98PlZjr2XWb2WzN72sy2huum/fcewMxmmdm3zOx5M9th\nZhfX8tgVqCXMLAp8AXgvsBq43sxWN7ZUdfVV4MqydbcDP3L3s4AfhcvTUQ74T+6+GngL8NHw37oZ\njn8IeKe7nw+sBa40s7cAfw38d3c/EzgCfKSBZay3TwA7Spab6dgBNrr72pKfizTD9x7g88C/uvtK\n4HyC70DNjl2BOtqFwEvuvtPdM8CDwKYGl6lu3P1nBDd2L7UJ+Fo4/zXgAye0UCeIu+9196fC+R6C\n/1gdNMHxe6A3XIyHDwfeCXwrXD8tjx3AzJYAvw/8Q7hsNMmxj2Paf+/NbCZwKfAVAHfPuHsXNTx2\nBepoHcDrJcud4bpmcoq77w3n9wGnNLIwJ4KZLQPWAY/TJMcfNnk+DRwAHgVeBrrcPRduMp2/+3cD\n/xkohMtzaZ5jh+Dk6X+b2ZNmdmu4rhm+98uBg8D9YXP/P5hZKzU8dgWqjMmDIeDTehi4mbUB3wb+\no7t3lz43nY/f3fPuvhZYQtAys7LBRTohzOz9wAF3f7LRZWmgt7v7eoKurY+a2aWlT07j730MWA98\n0d3XAX2UNe8e77ErUEfbDZxasrwkXNdM9pvZIoBweqDB5akbM4sThOk/ufv/Clc3zfEDhE1ejwEX\nA7PMLBY+NV2/+28DrjKzXQRdOu8k6FdrhmMHwN13h9MDwEMEJ1TN8L3vBDrd/fFw+VsEAVuzY1eg\njrYFOCsc8ZcArgM2N7hMJ9pm4OZw/mbguw0sS92E/WZfAXa4++dKnpr2x29m881sVjifAt5F0If8\nGHBNuNm0PHZ3/3N3X+Luywj+f//Y3W+kCY4dwMxazay9OA+8G3iOJvjeu/s+4HUzWxGuuhzYTg2P\nXRd2KGNm7yPoY4kC97n7nQ0uUt2Y2QPAZQR3W9gPfBb4DvBNYCnB3XuudffygUsnPTN7O/Bz4LeM\n9KV9mqAfdVofv5mdRzD4IkpwUv1Nd7/DzE4nqLXNAX4D3OTuQ40raX2Z2WXAp9z9/c1y7OFxPhQu\nxoBvuPudZjaXaf69BzCztQSD0RLATuDDhP8HqMGxK1BFRERqQE2+IiIiNaBAFRERqQEFqoiISA0o\nUEVERGpAgSoiIlIDClSRk5yZ5cM7hxQfNbuwuZktK70bkYiMLTbxJiIyxQ2ElxEUkQZSDVVkmgrv\ne/k34b0vnzCzM8P1y8zsx2b2rJn9yMyWhutPMbOHwvukPmNmbw13FTWzL4f3Tv3f4dWVRKSMAlXk\n5Jcqa/L9UMlzR939XODvCK4ABvA/gK+5+3nAPwH3hOvvAX4a3id1PbAtXH8W8AV3XwN0AX9Q5+MR\nOSnpSkkiJzkz63X3tgrrdxHcSHxneCOAfe4+18zeABa5ezZcv9fd55nZQWBJ6SX3wlvbPRrefBkz\n+y9A3N3/a/2PTOTkohqqyPTmY8xPRuk1bfNo7IVIRQpUkentQyXTX4XzvyS40wrAjQQ3CQD4EXAb\nDN+AfOaJKqTIdKAzTZGTX8rMni5Z/ld3L/50ZraZPUtQy7w+XPd/A/eb2Z8BBwnuuAHwCeBeM/sI\nQU30NmBv3UsvMk2oD1Vkmgr7UDe4+xuNLotIM1CTr4iISA2ohioiIlIDqqGKiIjUgAJVRESkBhSo\nIiIiNaBAFRERqQEFqoiISA0oUEVERGrg/wdoW0qB+8pDTwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"0oRGW4-tkLha","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 18:56:04 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","import tensorflow as tf\n","import keras\n","from keras.models import Model, load_model\n","from keras.layers import Input ,BatchNormalization , Activation \n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.merge import concatenate\n","\n","\n","def Convolution(input_tensor,filters):\n","    \n","    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x) \n","    return x\n","\n","def model(input_shape):\n","    \n","    inputs = Input((input_shape))\n","    \n","    conv_1 = Convolution(inputs,32)\n","    conv_1 = Convolution(conv_1,32)\n","    \n","    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n","    \n","    conv_2 = Convolution(maxp_1,64)\n","    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n","    \n","    conv_3 = Convolution(maxp_2,128)\n","    conv_3 = Convolution(conv_3,128)\n","    \n","    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n","    \n","    conv_4 = Convolution(maxp_3,256)\n","    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n","    \n","    conv_5 = Convolution(maxp_4,512)\n","    conv_5 = Convolution(conv_5,512)\n","    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n","\n","    upsample_6 = concatenate([upsample_6, conv_4])\n","    \n","    conv_6 = Convolution(upsample_6,256)\n","    \n","    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n","    \n","    upsample_7 = concatenate([upsample_7, conv_3])\n","    \n","    conv_7 = Convolution(upsample_7,128)\n","    conv_7 = Convolution(conv_7,128)\n","    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n","    \n","    upsample_8 = concatenate([upsample_8, conv_2])\n","\n","    conv_8 = Convolution(upsample_8,64)\n","    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n","    \n","    upsample_9 = concatenate([upsample_9, conv_1])\n","    \n","    conv_9 = Convolution(upsample_9,32)\n","    conv_9 = Convolution(conv_9,32)\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n","    \n","    model = Model(inputs=[inputs], outputs=[outputs]) \n","    \n","    return model\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-IKjprlflHx4","colab_type":"code","outputId":"3832ef28-8598-4724-bc44-aa1e772c0a36","executionInfo":{"status":"ok","timestamp":1584160278336,"user_tz":-330,"elapsed":1624256,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 20:18:06 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","X_Dp      =   modality(Path,0)\n","X_Flair   =   modality(Path,1)\n","X_Gado    =   modality(Path,2)\n","X_T1      =   modality(Path,10)\n","X_T2      =   modality(Path,11)\n","Y_Manual  =   modality(Path,3)\n","\n","# Removing the null samples and concatenating the 5 modalities along the 3rd dimension\n","X, Y = remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual)\n","\n","\n","# Splitting the Whole data into Training and Testing data\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","\n","# Loding the modified U-net \n","model = model(input_shape = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('Modified_UNet.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('Modified_UNet.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)\n","#Loss_Graph(history)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 5) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 32) 1472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 256, 256, 32) 128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 256, 256, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 64, 64, 128)  147584      activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 16, 16, 512)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 16, 16, 512)  2359808     activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 32, 32, 512)  0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 768)  0           up_sampling2d[0][0]              \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 256)  1769728     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_8[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_1[0][0]            \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 64, 64, 128)  442496      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 64, 64, 128)  512         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 64, 64, 128)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 64, 64, 128)  147584      activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_2[0][0]            \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 128, 128, 64) 256         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 128, 128, 64) 0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           activation_11[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_3[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 256, 256, 32) 128         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 256, 256, 32) 0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 256, 256, 32) 9248        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 256, 256, 32) 128         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 256, 256, 32) 0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 256, 256, 1)  33          activation_13[0][0]              \n","==================================================================================================\n","Total params: 6,602,433\n","Trainable params: 6,597,825\n","Non-trainable params: 4,608\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 1999 samples, validate on 500 samples\n","Epoch 1/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9939 - dice_coef: 0.0649 - precision: 0.6667 - sensitivity: 0.7759 - specificity: 0.9948\n","Epoch 00001: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 38s 19ms/sample - loss: 0.1320 - acc: 0.9939 - dice_coef: 0.0649 - precision: 0.6680 - sensitivity: 0.7720 - specificity: 0.9949 - val_loss: 0.1881 - val_acc: 0.9970 - val_dice_coef: 0.0298 - val_precision: 0.7494 - val_sensitivity: 0.5391 - val_specificity: 0.9992\n","Epoch 2/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9980 - dice_coef: 0.1225 - precision: 0.8056 - sensitivity: 0.7007 - specificity: 0.9993\n","Epoch 00002: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0454 - acc: 0.9980 - dice_coef: 0.1216 - precision: 0.8057 - sensitivity: 0.6991 - specificity: 0.9993 - val_loss: 0.0730 - val_acc: 0.9977 - val_dice_coef: 0.0874 - val_precision: 0.7597 - val_sensitivity: 0.7163 - val_specificity: 0.9990\n","Epoch 3/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9982 - dice_coef: 0.1832 - precision: 0.8261 - sensitivity: 0.7032 - specificity: 0.9994\n","Epoch 00003: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0277 - acc: 0.9982 - dice_coef: 0.1862 - precision: 0.8275 - sensitivity: 0.7028 - specificity: 0.9994 - val_loss: 0.0403 - val_acc: 0.9978 - val_dice_coef: 0.1645 - val_precision: 0.7459 - val_sensitivity: 0.7830 - val_specificity: 0.9988\n","Epoch 4/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9982 - dice_coef: 0.2572 - precision: 0.8289 - sensitivity: 0.7208 - specificity: 0.9994\n","Epoch 00004: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0193 - acc: 0.9982 - dice_coef: 0.2563 - precision: 0.8292 - sensitivity: 0.7205 - specificity: 0.9994 - val_loss: 0.0224 - val_acc: 0.9980 - val_dice_coef: 0.2204 - val_precision: 0.8631 - val_sensitivity: 0.6576 - val_specificity: 0.9995\n","Epoch 5/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9982 - dice_coef: 0.3120 - precision: 0.8287 - sensitivity: 0.7264 - specificity: 0.9994\n","Epoch 00005: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0148 - acc: 0.9982 - dice_coef: 0.3116 - precision: 0.8282 - sensitivity: 0.7258 - specificity: 0.9994 - val_loss: 0.0162 - val_acc: 0.9981 - val_dice_coef: 0.3022 - val_precision: 0.8422 - val_sensitivity: 0.7106 - val_specificity: 0.9994\n","Epoch 6/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9983 - dice_coef: 0.3660 - precision: 0.8232 - sensitivity: 0.7462 - specificity: 0.9994\n","Epoch 00006: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0120 - acc: 0.9983 - dice_coef: 0.3693 - precision: 0.8247 - sensitivity: 0.7470 - specificity: 0.9994 - val_loss: 0.0121 - val_acc: 0.9982 - val_dice_coef: 0.3968 - val_precision: 0.8292 - val_sensitivity: 0.7438 - val_specificity: 0.9993\n","Epoch 7/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9983 - dice_coef: 0.4215 - precision: 0.8226 - sensitivity: 0.7602 - specificity: 0.9993\n","Epoch 00007: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0102 - acc: 0.9983 - dice_coef: 0.4188 - precision: 0.8231 - sensitivity: 0.7584 - specificity: 0.9993 - val_loss: 0.0106 - val_acc: 0.9979 - val_dice_coef: 0.3861 - val_precision: 0.8824 - val_sensitivity: 0.6115 - val_specificity: 0.9996\n","Epoch 8/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9983 - dice_coef: 0.4561 - precision: 0.8247 - sensitivity: 0.7558 - specificity: 0.9993\n","Epoch 00008: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0091 - acc: 0.9983 - dice_coef: 0.4574 - precision: 0.8258 - sensitivity: 0.7575 - specificity: 0.9993 - val_loss: 0.0094 - val_acc: 0.9983 - val_dice_coef: 0.4756 - val_precision: 0.8155 - val_sensitivity: 0.7814 - val_specificity: 0.9992\n","Epoch 9/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9984 - dice_coef: 0.4977 - precision: 0.8314 - sensitivity: 0.7668 - specificity: 0.9993\n","Epoch 00009: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0081 - acc: 0.9984 - dice_coef: 0.4997 - precision: 0.8310 - sensitivity: 0.7694 - specificity: 0.9993 - val_loss: 0.0078 - val_acc: 0.9983 - val_dice_coef: 0.5503 - val_precision: 0.8225 - val_sensitivity: 0.7873 - val_specificity: 0.9992\n","Epoch 10/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9984 - dice_coef: 0.5310 - precision: 0.8337 - sensitivity: 0.7837 - specificity: 0.9993\n","Epoch 00010: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0073 - acc: 0.9985 - dice_coef: 0.5328 - precision: 0.8340 - sensitivity: 0.7855 - specificity: 0.9993 - val_loss: 0.0075 - val_acc: 0.9983 - val_dice_coef: 0.5488 - val_precision: 0.8418 - val_sensitivity: 0.7686 - val_specificity: 0.9994\n","Epoch 11/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9985 - dice_coef: 0.5597 - precision: 0.8327 - sensitivity: 0.7883 - specificity: 0.9993\n","Epoch 00011: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0068 - acc: 0.9985 - dice_coef: 0.5577 - precision: 0.8324 - sensitivity: 0.7873 - specificity: 0.9993 - val_loss: 0.0076 - val_acc: 0.9983 - val_dice_coef: 0.5734 - val_precision: 0.8478 - val_sensitivity: 0.7397 - val_specificity: 0.9994\n","Epoch 12/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9984 - dice_coef: 0.5620 - precision: 0.8260 - sensitivity: 0.7771 - specificity: 0.9993\n","Epoch 00012: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0067 - acc: 0.9984 - dice_coef: 0.5628 - precision: 0.8255 - sensitivity: 0.7772 - specificity: 0.9993 - val_loss: 0.0068 - val_acc: 0.9984 - val_dice_coef: 0.5976 - val_precision: 0.8167 - val_sensitivity: 0.8099 - val_specificity: 0.9992\n","Epoch 13/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9985 - dice_coef: 0.5904 - precision: 0.8232 - sensitivity: 0.7898 - specificity: 0.9993\n","Epoch 00013: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0062 - acc: 0.9985 - dice_coef: 0.5900 - precision: 0.8250 - sensitivity: 0.7888 - specificity: 0.9993 - val_loss: 0.0064 - val_acc: 0.9984 - val_dice_coef: 0.5943 - val_precision: 0.8582 - val_sensitivity: 0.7529 - val_specificity: 0.9994\n","Epoch 14/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9985 - dice_coef: 0.6153 - precision: 0.8352 - sensitivity: 0.8036 - specificity: 0.9994\n","Epoch 00014: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0059 - acc: 0.9985 - dice_coef: 0.6137 - precision: 0.8347 - sensitivity: 0.8026 - specificity: 0.9994 - val_loss: 0.0067 - val_acc: 0.9981 - val_dice_coef: 0.5895 - val_precision: 0.8607 - val_sensitivity: 0.7051 - val_specificity: 0.9995\n","Epoch 15/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986 - dice_coef: 0.6285 - precision: 0.8448 - sensitivity: 0.8053 - specificity: 0.9994\n","Epoch 00015: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0056 - acc: 0.9986 - dice_coef: 0.6299 - precision: 0.8462 - sensitivity: 0.8045 - specificity: 0.9994 - val_loss: 0.0060 - val_acc: 0.9983 - val_dice_coef: 0.6466 - val_precision: 0.8758 - val_sensitivity: 0.7300 - val_specificity: 0.9995\n","Epoch 16/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9986 - dice_coef: 0.6413 - precision: 0.8395 - sensitivity: 0.8057 - specificity: 0.9994\n","Epoch 00016: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0055 - acc: 0.9985 - dice_coef: 0.6374 - precision: 0.8325 - sensitivity: 0.8034 - specificity: 0.9993 - val_loss: 0.0071 - val_acc: 0.9977 - val_dice_coef: 0.5690 - val_precision: 0.8285 - val_sensitivity: 0.6144 - val_specificity: 0.9994\n","Epoch 17/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9985 - dice_coef: 0.6391 - precision: 0.8313 - sensitivity: 0.7953 - specificity: 0.9993\n","Epoch 00017: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0055 - acc: 0.9985 - dice_coef: 0.6393 - precision: 0.8324 - sensitivity: 0.7941 - specificity: 0.9993 - val_loss: 0.0058 - val_acc: 0.9983 - val_dice_coef: 0.6569 - val_precision: 0.8099 - val_sensitivity: 0.8070 - val_specificity: 0.9991\n","Epoch 18/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9986 - dice_coef: 0.6576 - precision: 0.8388 - sensitivity: 0.8095 - specificity: 0.9994\n","Epoch 00018: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0052 - acc: 0.9986 - dice_coef: 0.6575 - precision: 0.8379 - sensitivity: 0.8092 - specificity: 0.9993 - val_loss: 0.0055 - val_acc: 0.9985 - val_dice_coef: 0.6662 - val_precision: 0.8443 - val_sensitivity: 0.8144 - val_specificity: 0.9993\n","Epoch 19/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9986 - dice_coef: 0.6658 - precision: 0.8475 - sensitivity: 0.8026 - specificity: 0.9994\n","Epoch 00019: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0051 - acc: 0.9986 - dice_coef: 0.6653 - precision: 0.8463 - sensitivity: 0.8032 - specificity: 0.9994 - val_loss: 0.0055 - val_acc: 0.9985 - val_dice_coef: 0.6614 - val_precision: 0.8574 - val_sensitivity: 0.7925 - val_specificity: 0.9994\n","Epoch 20/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9986 - dice_coef: 0.6817 - precision: 0.8531 - sensitivity: 0.8108 - specificity: 0.9994\n","Epoch 00020: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0049 - acc: 0.9986 - dice_coef: 0.6827 - precision: 0.8546 - sensitivity: 0.8116 - specificity: 0.9994 - val_loss: 0.0055 - val_acc: 0.9985 - val_dice_coef: 0.6786 - val_precision: 0.8630 - val_sensitivity: 0.7832 - val_specificity: 0.9994\n","Epoch 21/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9986 - dice_coef: 0.6800 - precision: 0.8490 - sensitivity: 0.8055 - specificity: 0.9994\n","Epoch 00021: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0049 - acc: 0.9986 - dice_coef: 0.6774 - precision: 0.8479 - sensitivity: 0.8039 - specificity: 0.9994 - val_loss: 0.0057 - val_acc: 0.9982 - val_dice_coef: 0.6291 - val_precision: 0.8909 - val_sensitivity: 0.6813 - val_specificity: 0.9996\n","Epoch 22/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6874 - precision: 0.8547 - sensitivity: 0.8047 - specificity: 0.9994\n","Epoch 00022: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6866 - precision: 0.8552 - sensitivity: 0.8024 - specificity: 0.9994 - val_loss: 0.0051 - val_acc: 0.9985 - val_dice_coef: 0.6971 - val_precision: 0.8637 - val_sensitivity: 0.7970 - val_specificity: 0.9994\n","Epoch 23/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987 - dice_coef: 0.6973 - precision: 0.8536 - sensitivity: 0.8098 - specificity: 0.9994\n","Epoch 00023: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0046 - acc: 0.9987 - dice_coef: 0.6968 - precision: 0.8542 - sensitivity: 0.8089 - specificity: 0.9994 - val_loss: 0.0063 - val_acc: 0.9977 - val_dice_coef: 0.5786 - val_precision: 0.9268 - val_sensitivity: 0.5290 - val_specificity: 0.9998\n","Epoch 24/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9987 - dice_coef: 0.6998 - precision: 0.8565 - sensitivity: 0.8107 - specificity: 0.9995\n","Epoch 00024: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0045 - acc: 0.9987 - dice_coef: 0.7015 - precision: 0.8574 - sensitivity: 0.8123 - specificity: 0.9994 - val_loss: 0.0050 - val_acc: 0.9986 - val_dice_coef: 0.7151 - val_precision: 0.8638 - val_sensitivity: 0.7978 - val_specificity: 0.9994\n","Epoch 25/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9987 - dice_coef: 0.7139 - precision: 0.8647 - sensitivity: 0.8137 - specificity: 0.9995\n","Epoch 00025: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0043 - acc: 0.9987 - dice_coef: 0.7105 - precision: 0.8634 - sensitivity: 0.8113 - specificity: 0.9995 - val_loss: 0.0050 - val_acc: 0.9985 - val_dice_coef: 0.6828 - val_precision: 0.8933 - val_sensitivity: 0.7495 - val_specificity: 0.9996\n","Epoch 26/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9987 - dice_coef: 0.7187 - precision: 0.8642 - sensitivity: 0.8180 - specificity: 0.9995\n","Epoch 00026: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0043 - acc: 0.9987 - dice_coef: 0.7196 - precision: 0.8649 - sensitivity: 0.8188 - specificity: 0.9995 - val_loss: 0.0047 - val_acc: 0.9986 - val_dice_coef: 0.7372 - val_precision: 0.8608 - val_sensitivity: 0.8308 - val_specificity: 0.9994\n","Epoch 27/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9987 - dice_coef: 0.7205 - precision: 0.8649 - sensitivity: 0.8159 - specificity: 0.9995\n","Epoch 00027: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0042 - acc: 0.9987 - dice_coef: 0.7225 - precision: 0.8657 - sensitivity: 0.8176 - specificity: 0.9995 - val_loss: 0.0063 - val_acc: 0.9983 - val_dice_coef: 0.7355 - val_precision: 0.7871 - val_sensitivity: 0.8667 - val_specificity: 0.9989\n","Epoch 28/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7308 - precision: 0.8735 - sensitivity: 0.8199 - specificity: 0.9995\n","Epoch 00028: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7316 - precision: 0.8735 - sensitivity: 0.8205 - specificity: 0.9995 - val_loss: 0.0049 - val_acc: 0.9985 - val_dice_coef: 0.7090 - val_precision: 0.8811 - val_sensitivity: 0.7750 - val_specificity: 0.9995\n","Epoch 29/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7311 - precision: 0.8731 - sensitivity: 0.8223 - specificity: 0.9995\n","Epoch 00029: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7316 - precision: 0.8746 - sensitivity: 0.8232 - specificity: 0.9995 - val_loss: 0.0049 - val_acc: 0.9986 - val_dice_coef: 0.7501 - val_precision: 0.8731 - val_sensitivity: 0.8049 - val_specificity: 0.9995\n","Epoch 30/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988 - dice_coef: 0.7343 - precision: 0.8729 - sensitivity: 0.8187 - specificity: 0.9995\n","Epoch 00030: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0040 - acc: 0.9988 - dice_coef: 0.7335 - precision: 0.8720 - sensitivity: 0.8183 - specificity: 0.9995 - val_loss: 0.0059 - val_acc: 0.9980 - val_dice_coef: 0.6703 - val_precision: 0.7619 - val_sensitivity: 0.8154 - val_specificity: 0.9988\n","Epoch 31/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9988 - dice_coef: 0.7403 - precision: 0.8776 - sensitivity: 0.8169 - specificity: 0.9995\n","Epoch 00031: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0039 - acc: 0.9988 - dice_coef: 0.7399 - precision: 0.8769 - sensitivity: 0.8164 - specificity: 0.9995 - val_loss: 0.0050 - val_acc: 0.9985 - val_dice_coef: 0.6808 - val_precision: 0.8854 - val_sensitivity: 0.7726 - val_specificity: 0.9995\n","Epoch 32/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9988 - dice_coef: 0.7435 - precision: 0.8798 - sensitivity: 0.8159 - specificity: 0.9995\n","Epoch 00032: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0038 - acc: 0.9988 - dice_coef: 0.7441 - precision: 0.8802 - sensitivity: 0.8160 - specificity: 0.9995 - val_loss: 0.0048 - val_acc: 0.9986 - val_dice_coef: 0.7122 - val_precision: 0.8974 - val_sensitivity: 0.7459 - val_specificity: 0.9996\n","Epoch 33/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9988 - dice_coef: 0.7508 - precision: 0.8778 - sensitivity: 0.8235 - specificity: 0.9995\n","Epoch 00033: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0037 - acc: 0.9988 - dice_coef: 0.7510 - precision: 0.8788 - sensitivity: 0.8230 - specificity: 0.9995 - val_loss: 0.0046 - val_acc: 0.9986 - val_dice_coef: 0.7333 - val_precision: 0.8456 - val_sensitivity: 0.8368 - val_specificity: 0.9993\n","Epoch 34/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9989 - dice_coef: 0.7609 - precision: 0.8836 - sensitivity: 0.8298 - specificity: 0.9995\n","Epoch 00034: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0036 - acc: 0.9989 - dice_coef: 0.7602 - precision: 0.8842 - sensitivity: 0.8292 - specificity: 0.9995 - val_loss: 0.0052 - val_acc: 0.9983 - val_dice_coef: 0.6197 - val_precision: 0.9378 - val_sensitivity: 0.6427 - val_specificity: 0.9998\n","Epoch 35/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9989 - dice_coef: 0.7654 - precision: 0.8889 - sensitivity: 0.8318 - specificity: 0.9996\n","Epoch 00035: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0035 - acc: 0.9989 - dice_coef: 0.7636 - precision: 0.8876 - sensitivity: 0.8311 - specificity: 0.9996 - val_loss: 0.0048 - val_acc: 0.9985 - val_dice_coef: 0.7094 - val_precision: 0.8866 - val_sensitivity: 0.7616 - val_specificity: 0.9996\n","Epoch 36/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9989 - dice_coef: 0.7607 - precision: 0.8845 - sensitivity: 0.8271 - specificity: 0.9996\n","Epoch 00036: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0035 - acc: 0.9989 - dice_coef: 0.7615 - precision: 0.8835 - sensitivity: 0.8287 - specificity: 0.9995 - val_loss: 0.0046 - val_acc: 0.9986 - val_dice_coef: 0.7930 - val_precision: 0.8427 - val_sensitivity: 0.8467 - val_specificity: 0.9993\n","Epoch 37/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9989 - dice_coef: 0.7653 - precision: 0.8839 - sensitivity: 0.8289 - specificity: 0.9996\n","Epoch 00037: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0034 - acc: 0.9989 - dice_coef: 0.7661 - precision: 0.8841 - sensitivity: 0.8300 - specificity: 0.9996 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.7521 - val_precision: 0.8705 - val_sensitivity: 0.8122 - val_specificity: 0.9995\n","Epoch 38/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9989 - dice_coef: 0.7751 - precision: 0.8883 - sensitivity: 0.8373 - specificity: 0.9996\n","Epoch 00038: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0034 - acc: 0.9989 - dice_coef: 0.7758 - precision: 0.8887 - sensitivity: 0.8384 - specificity: 0.9996 - val_loss: 0.0044 - val_acc: 0.9986 - val_dice_coef: 0.7570 - val_precision: 0.8452 - val_sensitivity: 0.8247 - val_specificity: 0.9994\n","Epoch 39/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9989 - dice_coef: 0.7655 - precision: 0.8806 - sensitivity: 0.8317 - specificity: 0.9995\n","Epoch 00039: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0034 - acc: 0.9989 - dice_coef: 0.7638 - precision: 0.8792 - sensitivity: 0.8308 - specificity: 0.9995 - val_loss: 0.0054 - val_acc: 0.9981 - val_dice_coef: 0.6091 - val_precision: 0.9175 - val_sensitivity: 0.6207 - val_specificity: 0.9998\n","Epoch 40/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9989 - dice_coef: 0.7761 - precision: 0.8891 - sensitivity: 0.8375 - specificity: 0.9996\n","Epoch 00040: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0033 - acc: 0.9989 - dice_coef: 0.7755 - precision: 0.8895 - sensitivity: 0.8370 - specificity: 0.9996 - val_loss: 0.0056 - val_acc: 0.9981 - val_dice_coef: 0.6211 - val_precision: 0.9067 - val_sensitivity: 0.6295 - val_specificity: 0.9997\n","Epoch 41/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7833 - precision: 0.8904 - sensitivity: 0.8453 - specificity: 0.9996\n","Epoch 00041: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7837 - precision: 0.8908 - sensitivity: 0.8458 - specificity: 0.9996 - val_loss: 0.0042 - val_acc: 0.9987 - val_dice_coef: 0.7920 - val_precision: 0.9005 - val_sensitivity: 0.8183 - val_specificity: 0.9996\n","Epoch 42/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7868 - precision: 0.8901 - sensitivity: 0.8452 - specificity: 0.9996\n","Epoch 00042: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7872 - precision: 0.8903 - sensitivity: 0.8457 - specificity: 0.9996 - val_loss: 0.0042 - val_acc: 0.9986 - val_dice_coef: 0.7489 - val_precision: 0.8513 - val_sensitivity: 0.8240 - val_specificity: 0.9994\n","Epoch 43/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9990 - dice_coef: 0.7984 - precision: 0.8971 - sensitivity: 0.8560 - specificity: 0.9996\n","Epoch 00043: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0030 - acc: 0.9990 - dice_coef: 0.7992 - precision: 0.8968 - sensitivity: 0.8572 - specificity: 0.9996 - val_loss: 0.0042 - val_acc: 0.9987 - val_dice_coef: 0.7698 - val_precision: 0.8778 - val_sensitivity: 0.8042 - val_specificity: 0.9995\n","Epoch 44/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.7996 - precision: 0.8966 - sensitivity: 0.8531 - specificity: 0.9996\n","Epoch 00044: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.7985 - precision: 0.8963 - sensitivity: 0.8518 - specificity: 0.9996 - val_loss: 0.0046 - val_acc: 0.9985 - val_dice_coef: 0.7420 - val_precision: 0.8879 - val_sensitivity: 0.7663 - val_specificity: 0.9995\n","Epoch 45/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.7977 - precision: 0.8946 - sensitivity: 0.8507 - specificity: 0.9996\n","Epoch 00045: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.7973 - precision: 0.8932 - sensitivity: 0.8514 - specificity: 0.9996 - val_loss: 0.0042 - val_acc: 0.9986 - val_dice_coef: 0.7382 - val_precision: 0.8784 - val_sensitivity: 0.8071 - val_specificity: 0.9995\n","Epoch 46/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9990 - dice_coef: 0.8003 - precision: 0.8986 - sensitivity: 0.8502 - specificity: 0.9996\n","Epoch 00046: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0028 - acc: 0.9990 - dice_coef: 0.8017 - precision: 0.8991 - sensitivity: 0.8513 - specificity: 0.9996 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.7799 - val_precision: 0.8834 - val_sensitivity: 0.8090 - val_specificity: 0.9995\n","Epoch 47/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9990 - dice_coef: 0.8091 - precision: 0.9008 - sensitivity: 0.8601 - specificity: 0.9996\n","Epoch 00047: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0027 - acc: 0.9991 - dice_coef: 0.8083 - precision: 0.9013 - sensitivity: 0.8590 - specificity: 0.9996 - val_loss: 0.0044 - val_acc: 0.9987 - val_dice_coef: 0.7865 - val_precision: 0.8698 - val_sensitivity: 0.8221 - val_specificity: 0.9994\n","Epoch 48/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8138 - precision: 0.9004 - sensitivity: 0.8647 - specificity: 0.9996\n","Epoch 00048: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8134 - precision: 0.8993 - sensitivity: 0.8654 - specificity: 0.9996 - val_loss: 0.0045 - val_acc: 0.9987 - val_dice_coef: 0.8142 - val_precision: 0.8486 - val_sensitivity: 0.8618 - val_specificity: 0.9993\n","Epoch 49/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8180 - precision: 0.9016 - sensitivity: 0.8643 - specificity: 0.9996\n","Epoch 00049: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8183 - precision: 0.9025 - sensitivity: 0.8644 - specificity: 0.9996 - val_loss: 0.0040 - val_acc: 0.9987 - val_dice_coef: 0.7793 - val_precision: 0.8933 - val_sensitivity: 0.8027 - val_specificity: 0.9996\n","Epoch 50/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9991 - dice_coef: 0.8225 - precision: 0.9040 - sensitivity: 0.8699 - specificity: 0.9996\n","Epoch 00050: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0025 - acc: 0.9991 - dice_coef: 0.8231 - precision: 0.9043 - sensitivity: 0.8703 - specificity: 0.9996 - val_loss: 0.0045 - val_acc: 0.9986 - val_dice_coef: 0.7848 - val_precision: 0.8243 - val_sensitivity: 0.8655 - val_specificity: 0.9992\n","Epoch 51/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9991 - dice_coef: 0.8278 - precision: 0.9049 - sensitivity: 0.8745 - specificity: 0.9996\n","Epoch 00051: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0024 - acc: 0.9991 - dice_coef: 0.8261 - precision: 0.9041 - sensitivity: 0.8737 - specificity: 0.9996 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.8199 - val_precision: 0.8737 - val_sensitivity: 0.8433 - val_specificity: 0.9994\n","Epoch 52/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9991 - dice_coef: 0.8325 - precision: 0.9103 - sensitivity: 0.8752 - specificity: 0.9996\n","Epoch 00052: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0024 - acc: 0.9991 - dice_coef: 0.8332 - precision: 0.9103 - sensitivity: 0.8763 - specificity: 0.9996 - val_loss: 0.0044 - val_acc: 0.9987 - val_dice_coef: 0.8072 - val_precision: 0.8833 - val_sensitivity: 0.8158 - val_specificity: 0.9995\n","Epoch 53/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9991 - dice_coef: 0.8367 - precision: 0.9073 - sensitivity: 0.8825 - specificity: 0.9996\n","Epoch 00053: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0023 - acc: 0.9991 - dice_coef: 0.8369 - precision: 0.9078 - sensitivity: 0.8818 - specificity: 0.9996 - val_loss: 0.0039 - val_acc: 0.9987 - val_dice_coef: 0.7879 - val_precision: 0.8609 - val_sensitivity: 0.8411 - val_specificity: 0.9994\n","Epoch 54/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9991 - dice_coef: 0.8338 - precision: 0.9065 - sensitivity: 0.8786 - specificity: 0.9996\n","Epoch 00054: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0023 - acc: 0.9991 - dice_coef: 0.8307 - precision: 0.9045 - sensitivity: 0.8764 - specificity: 0.9996 - val_loss: 0.0044 - val_acc: 0.9987 - val_dice_coef: 0.8227 - val_precision: 0.8600 - val_sensitivity: 0.8614 - val_specificity: 0.9993\n","Epoch 55/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8429 - precision: 0.9099 - sensitivity: 0.8875 - specificity: 0.9996\n","Epoch 00055: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8443 - precision: 0.9112 - sensitivity: 0.8885 - specificity: 0.9996 - val_loss: 0.0043 - val_acc: 0.9988 - val_dice_coef: 0.8105 - val_precision: 0.9026 - val_sensitivity: 0.7992 - val_specificity: 0.9996\n","Epoch 56/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8438 - precision: 0.9112 - sensitivity: 0.8865 - specificity: 0.9996\n","Epoch 00056: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8443 - precision: 0.9115 - sensitivity: 0.8873 - specificity: 0.9996 - val_loss: 0.0037 - val_acc: 0.9988 - val_dice_coef: 0.8106 - val_precision: 0.8787 - val_sensitivity: 0.8477 - val_specificity: 0.9995\n","Epoch 57/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8509 - precision: 0.9150 - sensitivity: 0.8908 - specificity: 0.9997\n","Epoch 00057: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8514 - precision: 0.9152 - sensitivity: 0.8913 - specificity: 0.9997 - val_loss: 0.0045 - val_acc: 0.9988 - val_dice_coef: 0.8211 - val_precision: 0.8861 - val_sensitivity: 0.8255 - val_specificity: 0.9995\n","Epoch 58/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8533 - precision: 0.9125 - sensitivity: 0.8945 - specificity: 0.9997\n","Epoch 00058: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8526 - precision: 0.9123 - sensitivity: 0.8936 - specificity: 0.9997 - val_loss: 0.0040 - val_acc: 0.9988 - val_dice_coef: 0.8014 - val_precision: 0.8839 - val_sensitivity: 0.8176 - val_specificity: 0.9995\n","Epoch 59/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8571 - precision: 0.9176 - sensitivity: 0.8959 - specificity: 0.9997\n","Epoch 00059: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8578 - precision: 0.9184 - sensitivity: 0.8964 - specificity: 0.9997 - val_loss: 0.0038 - val_acc: 0.9988 - val_dice_coef: 0.8257 - val_precision: 0.8843 - val_sensitivity: 0.8461 - val_specificity: 0.9995\n","Epoch 60/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8536 - precision: 0.9159 - sensitivity: 0.8932 - specificity: 0.9997\n","Epoch 00060: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 25s 12ms/sample - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8501 - precision: 0.9123 - sensitivity: 0.8916 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9986 - val_dice_coef: 0.7764 - val_precision: 0.8839 - val_sensitivity: 0.7801 - val_specificity: 0.9995\n","2499/2499 [==============================] - 10s 4ms/sample - loss: 0.0029 - acc: 0.9989 - dice_coef: 0.7982 - precision: 0.9030 - sensitivity: 0.8101 - specificity: 0.9997\n","441/441 [==============================] - 2s 5ms/sample - loss: 0.0038 - acc: 0.9987 - dice_coef: 0.7863 - precision: 0.8946 - sensitivity: 0.7934 - specificity: 0.9996\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.0038127185932050147,\n"," 0.9986763,\n"," 0.786333,\n"," 0.89457685,\n"," 0.79337204,\n"," 0.99959224]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"0JaqrEJLsTY_","colab_type":"code","outputId":"d5bc3a34-73dd-48e7-dc0b-2d1796725e83","executionInfo":{"status":"ok","timestamp":1584160298297,"user_tz":-330,"elapsed":2574,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Accuracy vs Epoch\n","def Accuracy_Graph(history):\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    #plt.title('Model accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","    \n","# Dice Similarity Coefficient vs Epoch\n","def Dice_coefficient_Graph(history):\n","\n","    plt.plot(history.history['dice_coef'])\n","    plt.plot(history.history['val_dice_coef'])\n","    #plt.title('Dice_Coefficient')\n","    plt.ylabel('Dice_Coefficient')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","# Loss vs Epoch\n","def Loss_Graph(history):\n","\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    #plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","Accuracy_Graph(history)\n","Dice_coefficient_Graph(history)\n","Loss_Graph(history)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdoAAAFNCAYAAACnh65UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no42IiKgojTYiIqKi/wEhz05nr/UciAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAc4AAAFNCAYAAACJwo/GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdoAAAFNCAYAAACnh65UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBa2IiEiEFLQiIiIRUtCKiIhE6P8CTl9El1AMiwAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Dg-ilmL1smoU","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 18:56:04 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","import tensorflow as tf\n","import keras\n","from keras.models import Model, load_model\n","from keras.layers import Input ,BatchNormalization , Activation \n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.merge import concatenate\n","\n","\n","def Convolution(input_tensor,filters):\n","    \n","    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x) \n","    return x\n","\n","def model(input_shape):\n","    \n","    inputs = Input((input_shape))\n","    \n","    conv_1 = Convolution(inputs,32)\n","    conv_1 = Convolution(inputs,32)\n","    \n","    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n","    \n","    conv_2 = Convolution(maxp_1,64)\n","    conv_2 = Convolution(maxp_1,64)\n","\n","    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n","    \n","    conv_3 = Convolution(maxp_2,128)\n","    conv_3 = Convolution(maxp_2,128)\n","    \n","    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n","    \n","    conv_4 = Convolution(maxp_3,256)\n","    conv_4 = Convolution(maxp_3,256)\n","\n","    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n","    \n","    conv_5 = Convolution(maxp_4,512)\n","    conv_5 = Convolution(maxp_4,512)\n","    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n","\n","    upsample_6 = concatenate([upsample_6, conv_4])\n","    \n","    conv_6 = Convolution(upsample_6,256)\n","    conv_6 = Convolution(upsample_6,256)\n","    \n","    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n","    \n","    upsample_7 = concatenate([upsample_7, conv_3])\n","    \n","    conv_7 = Convolution(upsample_7,128)\n","    conv_7 = Convolution(upsample_7,128)\n","    \n","    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n","    \n","    upsample_8 = concatenate([upsample_8, conv_2])\n","\n","    conv_8 = Convolution(upsample_8,64)\n","    conv_8 = Convolution(upsample_8,64)\n","\n","    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n","    \n","    upsample_9 = concatenate([upsample_9, conv_1])\n","    \n","    conv_9 = Convolution(upsample_9,32)\n","    conv_9 = Convolution(upsample_9,32)\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n","    \n","    model = Model(inputs=[inputs], outputs=[outputs]) \n","    \n","    return model\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Em5VSRcbtG9h","colab_type":"code","outputId":"c32458f1-4623-4cb3-86bc-a640708b3bbd","executionInfo":{"status":"ok","timestamp":1584084572128,"user_tz":-330,"elapsed":1212615,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 20:18:06 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","X_Dp      =   modality(Path,0)\n","X_Flair   =   modality(Path,1)\n","X_Gado    =   modality(Path,2)\n","X_T1      =   modality(Path,10)\n","X_T2      =   modality(Path,11)\n","Y_Manual  =   modality(Path,3)\n","\n","# Removing the null samples and concatenating the 5 modalities along the 3rd dimension\n","X, Y = remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual)\n","\n","\n","# Splitting the Whole data into Training and Testing data\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","\n","# Loding the modified U-net \n","model = model(input_shape = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('Modified_UNet.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('Modified_UNet.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)\n","#Loss_Graph(history)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 5) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 256, 256, 32) 1472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 256, 256, 32) 128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 256, 256, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 128, 128, 64) 256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 128, 128, 64) 0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 64, 64, 128)  512         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 16, 16, 512)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 32, 32, 512)  0           activation_9[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 768)  0           up_sampling2d[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 32, 256)  1769728     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 32, 256)  1024        conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 32, 32, 256)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_11[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_1[0][0]            \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           activation_13[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_2[0][0]            \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 128, 128, 64) 256         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 128, 128, 64) 0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           activation_15[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_3[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 256, 256, 32) 128         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 256, 256, 32) 0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 256, 256, 1)  33          activation_17[0][0]              \n","==================================================================================================\n","Total params: 3,925,633\n","Trainable params: 3,922,689\n","Non-trainable params: 2,944\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 1999 samples, validate on 500 samples\n","Epoch 1/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.4835 - acc: 0.9235 - dice_coef: 0.0214 - precision: 0.4334 - sensitivity: 0.8880 - specificity: 0.9236\n","Epoch 00001: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 30s 15ms/sample - loss: 0.4822 - acc: 0.9240 - dice_coef: 0.0216 - precision: 0.4374 - sensitivity: 0.8852 - specificity: 0.9247 - val_loss: 0.1989 - val_acc: 0.9923 - val_dice_coef: 0.0502 - val_precision: 0.3572 - val_sensitivity: 0.8773 - val_specificity: 0.9928\n","Epoch 2/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9980 - dice_coef: 0.0314 - precision: 0.7705 - sensitivity: 0.7437 - specificity: 0.9991\n","Epoch 00002: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.2293 - acc: 0.9980 - dice_coef: 0.0316 - precision: 0.7722 - sensitivity: 0.7387 - specificity: 0.9991 - val_loss: 0.1924 - val_acc: 0.9969 - val_dice_coef: 0.0441 - val_precision: 0.6325 - val_sensitivity: 0.8274 - val_specificity: 0.9977\n","Epoch 3/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9981 - dice_coef: 0.0455 - precision: 0.8314 - sensitivity: 0.6645 - specificity: 0.9995\n","Epoch 00003: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.1360 - acc: 0.9981 - dice_coef: 0.0458 - precision: 0.8324 - sensitivity: 0.6664 - specificity: 0.9995 - val_loss: 0.1103 - val_acc: 0.9979 - val_dice_coef: 0.0570 - val_precision: 0.8404 - val_sensitivity: 0.6748 - val_specificity: 0.9994\n","Epoch 4/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9981 - dice_coef: 0.0682 - precision: 0.8337 - sensitivity: 0.6870 - specificity: 0.9995\n","Epoch 00004: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0836 - acc: 0.9982 - dice_coef: 0.0680 - precision: 0.8329 - sensitivity: 0.6878 - specificity: 0.9995 - val_loss: 0.0725 - val_acc: 0.9980 - val_dice_coef: 0.0856 - val_precision: 0.8036 - val_sensitivity: 0.7470 - val_specificity: 0.9992\n","Epoch 5/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9982 - dice_coef: 0.1011 - precision: 0.8311 - sensitivity: 0.7158 - specificity: 0.9994\n","Epoch 00005: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0538 - acc: 0.9982 - dice_coef: 0.1002 - precision: 0.8289 - sensitivity: 0.7147 - specificity: 0.9994 - val_loss: 0.0474 - val_acc: 0.9980 - val_dice_coef: 0.1284 - val_precision: 0.7818 - val_sensitivity: 0.7645 - val_specificity: 0.9991\n","Epoch 6/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9982 - dice_coef: 0.1400 - precision: 0.8318 - sensitivity: 0.7256 - specificity: 0.9994\n","Epoch 00006: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0372 - acc: 0.9982 - dice_coef: 0.1406 - precision: 0.8307 - sensitivity: 0.7257 - specificity: 0.9994 - val_loss: 0.0346 - val_acc: 0.9981 - val_dice_coef: 0.1631 - val_precision: 0.8231 - val_sensitivity: 0.7330 - val_specificity: 0.9993\n","Epoch 7/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9983 - dice_coef: 0.1848 - precision: 0.8307 - sensitivity: 0.7232 - specificity: 0.9994\n","Epoch 00007: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0273 - acc: 0.9983 - dice_coef: 0.1834 - precision: 0.8305 - sensitivity: 0.7246 - specificity: 0.9994 - val_loss: 0.0245 - val_acc: 0.9981 - val_dice_coef: 0.2339 - val_precision: 0.7782 - val_sensitivity: 0.7790 - val_specificity: 0.9990\n","Epoch 8/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9983 - dice_coef: 0.2291 - precision: 0.8328 - sensitivity: 0.7386 - specificity: 0.9994\n","Epoch 00008: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0212 - acc: 0.9983 - dice_coef: 0.2314 - precision: 0.8332 - sensitivity: 0.7389 - specificity: 0.9994 - val_loss: 0.0196 - val_acc: 0.9981 - val_dice_coef: 0.2592 - val_precision: 0.8111 - val_sensitivity: 0.7480 - val_specificity: 0.9992\n","Epoch 9/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9983 - dice_coef: 0.2723 - precision: 0.8240 - sensitivity: 0.7399 - specificity: 0.9994\n","Epoch 00009: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0172 - acc: 0.9983 - dice_coef: 0.2702 - precision: 0.8222 - sensitivity: 0.7387 - specificity: 0.9994 - val_loss: 0.0157 - val_acc: 0.9981 - val_dice_coef: 0.3144 - val_precision: 0.8439 - val_sensitivity: 0.7190 - val_specificity: 0.9994\n","Epoch 10/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9983 - dice_coef: 0.3141 - precision: 0.8347 - sensitivity: 0.7447 - specificity: 0.9994\n","Epoch 00010: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0144 - acc: 0.9983 - dice_coef: 0.3155 - precision: 0.8350 - sensitivity: 0.7466 - specificity: 0.9994 - val_loss: 0.0138 - val_acc: 0.9982 - val_dice_coef: 0.3539 - val_precision: 0.7967 - val_sensitivity: 0.7718 - val_specificity: 0.9992\n","Epoch 11/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9983 - dice_coef: 0.3481 - precision: 0.8154 - sensitivity: 0.7530 - specificity: 0.9993\n","Epoch 00011: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0126 - acc: 0.9983 - dice_coef: 0.3488 - precision: 0.8152 - sensitivity: 0.7512 - specificity: 0.9993 - val_loss: 0.0124 - val_acc: 0.9982 - val_dice_coef: 0.4026 - val_precision: 0.7790 - val_sensitivity: 0.8283 - val_specificity: 0.9989\n","Epoch 12/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9984 - dice_coef: 0.3908 - precision: 0.8299 - sensitivity: 0.7644 - specificity: 0.9994\n","Epoch 00012: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0110 - acc: 0.9984 - dice_coef: 0.3910 - precision: 0.8313 - sensitivity: 0.7633 - specificity: 0.9994 - val_loss: 0.0115 - val_acc: 0.9982 - val_dice_coef: 0.3960 - val_precision: 0.8047 - val_sensitivity: 0.7836 - val_specificity: 0.9991\n","Epoch 13/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9984 - dice_coef: 0.4241 - precision: 0.8275 - sensitivity: 0.7731 - specificity: 0.9993\n","Epoch 00013: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0098 - acc: 0.9984 - dice_coef: 0.4246 - precision: 0.8292 - sensitivity: 0.7733 - specificity: 0.9993 - val_loss: 0.0096 - val_acc: 0.9982 - val_dice_coef: 0.4563 - val_precision: 0.8446 - val_sensitivity: 0.7212 - val_specificity: 0.9994\n","Epoch 14/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9984 - dice_coef: 0.4560 - precision: 0.8272 - sensitivity: 0.7812 - specificity: 0.9993\n","Epoch 00014: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0090 - acc: 0.9984 - dice_coef: 0.4582 - precision: 0.8287 - sensitivity: 0.7813 - specificity: 0.9993 - val_loss: 0.0087 - val_acc: 0.9983 - val_dice_coef: 0.4970 - val_precision: 0.8314 - val_sensitivity: 0.7941 - val_specificity: 0.9992\n","Epoch 15/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9984 - dice_coef: 0.4792 - precision: 0.8251 - sensitivity: 0.7835 - specificity: 0.9993\n","Epoch 00015: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0083 - acc: 0.9984 - dice_coef: 0.4738 - precision: 0.8246 - sensitivity: 0.7778 - specificity: 0.9993 - val_loss: 0.0083 - val_acc: 0.9983 - val_dice_coef: 0.5106 - val_precision: 0.8142 - val_sensitivity: 0.8147 - val_specificity: 0.9991\n","Epoch 16/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9985 - dice_coef: 0.5075 - precision: 0.8306 - sensitivity: 0.7921 - specificity: 0.9993\n","Epoch 00016: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0077 - acc: 0.9985 - dice_coef: 0.5082 - precision: 0.8310 - sensitivity: 0.7931 - specificity: 0.9993 - val_loss: 0.0080 - val_acc: 0.9983 - val_dice_coef: 0.5250 - val_precision: 0.8535 - val_sensitivity: 0.7645 - val_specificity: 0.9994\n","Epoch 17/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9985 - dice_coef: 0.5287 - precision: 0.8318 - sensitivity: 0.7914 - specificity: 0.9993\n","Epoch 00017: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0072 - acc: 0.9985 - dice_coef: 0.5256 - precision: 0.8316 - sensitivity: 0.7887 - specificity: 0.9994 - val_loss: 0.0082 - val_acc: 0.9980 - val_dice_coef: 0.4457 - val_precision: 0.8912 - val_sensitivity: 0.6107 - val_specificity: 0.9997\n","Epoch 18/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9985 - dice_coef: 0.5536 - precision: 0.8382 - sensitivity: 0.7989 - specificity: 0.9993\n","Epoch 00018: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0069 - acc: 0.9985 - dice_coef: 0.5517 - precision: 0.8379 - sensitivity: 0.7983 - specificity: 0.9993 - val_loss: 0.0071 - val_acc: 0.9984 - val_dice_coef: 0.5742 - val_precision: 0.8309 - val_sensitivity: 0.7979 - val_specificity: 0.9992\n","Epoch 19/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9985 - dice_coef: 0.5678 - precision: 0.8340 - sensitivity: 0.8015 - specificity: 0.9994\n","Epoch 00019: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0065 - acc: 0.9985 - dice_coef: 0.5693 - precision: 0.8358 - sensitivity: 0.8015 - specificity: 0.9994 - val_loss: 0.0068 - val_acc: 0.9984 - val_dice_coef: 0.6015 - val_precision: 0.7999 - val_sensitivity: 0.8454 - val_specificity: 0.9991\n","Epoch 20/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9986 - dice_coef: 0.5907 - precision: 0.8429 - sensitivity: 0.8060 - specificity: 0.9994\n","Epoch 00020: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0062 - acc: 0.9986 - dice_coef: 0.5914 - precision: 0.8430 - sensitivity: 0.8076 - specificity: 0.9994 - val_loss: 0.0069 - val_acc: 0.9983 - val_dice_coef: 0.6277 - val_precision: 0.7831 - val_sensitivity: 0.8522 - val_specificity: 0.9989\n","Epoch 21/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9986 - dice_coef: 0.5967 - precision: 0.8362 - sensitivity: 0.8052 - specificity: 0.9994\n","Epoch 00021: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0060 - acc: 0.9986 - dice_coef: 0.5976 - precision: 0.8361 - sensitivity: 0.8053 - specificity: 0.9994 - val_loss: 0.0063 - val_acc: 0.9984 - val_dice_coef: 0.6206 - val_precision: 0.8644 - val_sensitivity: 0.7684 - val_specificity: 0.9994\n","Epoch 22/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9986 - dice_coef: 0.6125 - precision: 0.8448 - sensitivity: 0.8081 - specificity: 0.9994\n","Epoch 00022: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0058 - acc: 0.9986 - dice_coef: 0.6141 - precision: 0.8462 - sensitivity: 0.8091 - specificity: 0.9994 - val_loss: 0.0060 - val_acc: 0.9985 - val_dice_coef: 0.6278 - val_precision: 0.8290 - val_sensitivity: 0.8269 - val_specificity: 0.9992\n","Epoch 23/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986 - dice_coef: 0.6257 - precision: 0.8416 - sensitivity: 0.8116 - specificity: 0.9994\n","Epoch 00023: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0056 - acc: 0.9986 - dice_coef: 0.6264 - precision: 0.8422 - sensitivity: 0.8113 - specificity: 0.9994 - val_loss: 0.0066 - val_acc: 0.9983 - val_dice_coef: 0.6123 - val_precision: 0.8587 - val_sensitivity: 0.7056 - val_specificity: 0.9995\n","Epoch 24/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9986 - dice_coef: 0.6362 - precision: 0.8452 - sensitivity: 0.8135 - specificity: 0.9994\n","Epoch 00024: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0054 - acc: 0.9986 - dice_coef: 0.6316 - precision: 0.8416 - sensitivity: 0.8108 - specificity: 0.9994 - val_loss: 0.0067 - val_acc: 0.9982 - val_dice_coef: 0.6043 - val_precision: 0.8945 - val_sensitivity: 0.6838 - val_specificity: 0.9996\n","Epoch 25/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9986 - dice_coef: 0.6465 - precision: 0.8546 - sensitivity: 0.8057 - specificity: 0.9994\n","Epoch 00025: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0052 - acc: 0.9986 - dice_coef: 0.6459 - precision: 0.8540 - sensitivity: 0.8062 - specificity: 0.9994 - val_loss: 0.0060 - val_acc: 0.9983 - val_dice_coef: 0.5993 - val_precision: 0.8556 - val_sensitivity: 0.7007 - val_specificity: 0.9995\n","Epoch 26/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9986 - dice_coef: 0.6527 - precision: 0.8456 - sensitivity: 0.8199 - specificity: 0.9994\n","Epoch 00026: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0051 - acc: 0.9986 - dice_coef: 0.6517 - precision: 0.8448 - sensitivity: 0.8188 - specificity: 0.9994 - val_loss: 0.0065 - val_acc: 0.9982 - val_dice_coef: 0.6534 - val_precision: 0.7694 - val_sensitivity: 0.8601 - val_specificity: 0.9988\n","Epoch 27/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9986 - dice_coef: 0.6596 - precision: 0.8524 - sensitivity: 0.8092 - specificity: 0.9994\n","Epoch 00027: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0051 - acc: 0.9987 - dice_coef: 0.6606 - precision: 0.8530 - sensitivity: 0.8106 - specificity: 0.9994 - val_loss: 0.0056 - val_acc: 0.9985 - val_dice_coef: 0.6794 - val_precision: 0.8208 - val_sensitivity: 0.8242 - val_specificity: 0.9992\n","Epoch 28/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9987 - dice_coef: 0.6695 - precision: 0.8575 - sensitivity: 0.8108 - specificity: 0.9995\n","Epoch 00028: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0048 - acc: 0.9987 - dice_coef: 0.6697 - precision: 0.8569 - sensitivity: 0.8133 - specificity: 0.9995 - val_loss: 0.0055 - val_acc: 0.9984 - val_dice_coef: 0.6553 - val_precision: 0.8589 - val_sensitivity: 0.7725 - val_specificity: 0.9994\n","Epoch 29/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6823 - precision: 0.8575 - sensitivity: 0.8196 - specificity: 0.9994\n","Epoch 00029: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6820 - precision: 0.8571 - sensitivity: 0.8187 - specificity: 0.9994 - val_loss: 0.0062 - val_acc: 0.9983 - val_dice_coef: 0.6710 - val_precision: 0.8889 - val_sensitivity: 0.7040 - val_specificity: 0.9996\n","Epoch 30/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6807 - precision: 0.8578 - sensitivity: 0.8165 - specificity: 0.9994\n","Epoch 00030: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0047 - acc: 0.9987 - dice_coef: 0.6807 - precision: 0.8581 - sensitivity: 0.8155 - specificity: 0.9994 - val_loss: 0.0059 - val_acc: 0.9982 - val_dice_coef: 0.6591 - val_precision: 0.7601 - val_sensitivity: 0.8697 - val_specificity: 0.9988\n","Epoch 31/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987 - dice_coef: 0.6946 - precision: 0.8540 - sensitivity: 0.8261 - specificity: 0.9994\n","Epoch 00031: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0046 - acc: 0.9987 - dice_coef: 0.6950 - precision: 0.8547 - sensitivity: 0.8259 - specificity: 0.9994 - val_loss: 0.0054 - val_acc: 0.9985 - val_dice_coef: 0.6983 - val_precision: 0.8757 - val_sensitivity: 0.7751 - val_specificity: 0.9995\n","Epoch 32/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9988 - dice_coef: 0.7055 - precision: 0.8685 - sensitivity: 0.8240 - specificity: 0.9995\n","Epoch 00032: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0044 - acc: 0.9988 - dice_coef: 0.7041 - precision: 0.8670 - sensitivity: 0.8240 - specificity: 0.9995 - val_loss: 0.0067 - val_acc: 0.9981 - val_dice_coef: 0.6427 - val_precision: 0.8934 - val_sensitivity: 0.6531 - val_specificity: 0.9996\n","Epoch 33/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9987 - dice_coef: 0.7049 - precision: 0.8605 - sensitivity: 0.8265 - specificity: 0.9995\n","Epoch 00033: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0043 - acc: 0.9987 - dice_coef: 0.7033 - precision: 0.8600 - sensitivity: 0.8251 - specificity: 0.9995 - val_loss: 0.0052 - val_acc: 0.9985 - val_dice_coef: 0.6709 - val_precision: 0.8875 - val_sensitivity: 0.7619 - val_specificity: 0.9995\n","Epoch 34/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7174 - precision: 0.8693 - sensitivity: 0.8298 - specificity: 0.9995\n","Epoch 00034: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7181 - precision: 0.8697 - sensitivity: 0.8295 - specificity: 0.9995 - val_loss: 0.0056 - val_acc: 0.9983 - val_dice_coef: 0.6873 - val_precision: 0.7836 - val_sensitivity: 0.8677 - val_specificity: 0.9989\n","Epoch 35/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9988 - dice_coef: 0.7207 - precision: 0.8685 - sensitivity: 0.8315 - specificity: 0.9995\n","Epoch 00035: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0041 - acc: 0.9988 - dice_coef: 0.7206 - precision: 0.8691 - sensitivity: 0.8315 - specificity: 0.9995 - val_loss: 0.0055 - val_acc: 0.9983 - val_dice_coef: 0.6437 - val_precision: 0.9005 - val_sensitivity: 0.6920 - val_specificity: 0.9996\n","Epoch 36/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9988 - dice_coef: 0.7253 - precision: 0.8702 - sensitivity: 0.8313 - specificity: 0.9995\n","Epoch 00036: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0039 - acc: 0.9988 - dice_coef: 0.7248 - precision: 0.8707 - sensitivity: 0.8301 - specificity: 0.9995 - val_loss: 0.0065 - val_acc: 0.9983 - val_dice_coef: 0.7001 - val_precision: 0.8708 - val_sensitivity: 0.7078 - val_specificity: 0.9995\n","Epoch 37/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9988 - dice_coef: 0.7300 - precision: 0.8748 - sensitivity: 0.8301 - specificity: 0.9995\n","Epoch 00037: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0039 - acc: 0.9988 - dice_coef: 0.7312 - precision: 0.8757 - sensitivity: 0.8311 - specificity: 0.9995 - val_loss: 0.0057 - val_acc: 0.9982 - val_dice_coef: 0.7053 - val_precision: 0.7476 - val_sensitivity: 0.8878 - val_specificity: 0.9987\n","Epoch 38/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9989 - dice_coef: 0.7492 - precision: 0.8818 - sensitivity: 0.8446 - specificity: 0.9995\n","Epoch 00038: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0037 - acc: 0.9989 - dice_coef: 0.7476 - precision: 0.8804 - sensitivity: 0.8429 - specificity: 0.9995 - val_loss: 0.0051 - val_acc: 0.9985 - val_dice_coef: 0.7431 - val_precision: 0.8141 - val_sensitivity: 0.8603 - val_specificity: 0.9991\n","Epoch 39/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9989 - dice_coef: 0.7456 - precision: 0.8775 - sensitivity: 0.8401 - specificity: 0.9995\n","Epoch 00039: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0037 - acc: 0.9989 - dice_coef: 0.7468 - precision: 0.8786 - sensitivity: 0.8409 - specificity: 0.9995 - val_loss: 0.0051 - val_acc: 0.9985 - val_dice_coef: 0.7065 - val_precision: 0.8152 - val_sensitivity: 0.8366 - val_specificity: 0.9992\n","Epoch 40/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9989 - dice_coef: 0.7510 - precision: 0.8758 - sensitivity: 0.8454 - specificity: 0.9995\n","Epoch 00040: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0036 - acc: 0.9989 - dice_coef: 0.7522 - precision: 0.8767 - sensitivity: 0.8462 - specificity: 0.9995 - val_loss: 0.0070 - val_acc: 0.9980 - val_dice_coef: 0.6350 - val_precision: 0.9389 - val_sensitivity: 0.5597 - val_specificity: 0.9998\n","Epoch 41/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9989 - dice_coef: 0.7613 - precision: 0.8858 - sensitivity: 0.8489 - specificity: 0.9995\n","Epoch 00041: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0034 - acc: 0.9989 - dice_coef: 0.7600 - precision: 0.8855 - sensitivity: 0.8477 - specificity: 0.9995 - val_loss: 0.0051 - val_acc: 0.9984 - val_dice_coef: 0.7048 - val_precision: 0.8639 - val_sensitivity: 0.7729 - val_specificity: 0.9994\n","Epoch 42/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9990 - dice_coef: 0.7679 - precision: 0.8855 - sensitivity: 0.8535 - specificity: 0.9996\n","Epoch 00042: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0033 - acc: 0.9990 - dice_coef: 0.7669 - precision: 0.8854 - sensitivity: 0.8541 - specificity: 0.9996 - val_loss: 0.0048 - val_acc: 0.9985 - val_dice_coef: 0.7521 - val_precision: 0.8276 - val_sensitivity: 0.8396 - val_specificity: 0.9992\n","Epoch 43/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990 - dice_coef: 0.7742 - precision: 0.8915 - sensitivity: 0.8525 - specificity: 0.9996\n","Epoch 00043: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0032 - acc: 0.9990 - dice_coef: 0.7750 - precision: 0.8926 - sensitivity: 0.8526 - specificity: 0.9996 - val_loss: 0.0054 - val_acc: 0.9985 - val_dice_coef: 0.7551 - val_precision: 0.9083 - val_sensitivity: 0.7583 - val_specificity: 0.9996\n","Epoch 44/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7776 - precision: 0.8912 - sensitivity: 0.8555 - specificity: 0.9996\n","Epoch 00044: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7777 - precision: 0.8913 - sensitivity: 0.8558 - specificity: 0.9996 - val_loss: 0.0065 - val_acc: 0.9981 - val_dice_coef: 0.6999 - val_precision: 0.7383 - val_sensitivity: 0.8869 - val_specificity: 0.9986\n","Epoch 45/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7884 - precision: 0.8979 - sensitivity: 0.8619 - specificity: 0.9996\n","Epoch 00045: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0031 - acc: 0.9990 - dice_coef: 0.7899 - precision: 0.8988 - sensitivity: 0.8630 - specificity: 0.9996 - val_loss: 0.0049 - val_acc: 0.9985 - val_dice_coef: 0.7626 - val_precision: 0.8246 - val_sensitivity: 0.8505 - val_specificity: 0.9992\n","Epoch 46/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9990 - dice_coef: 0.7869 - precision: 0.8969 - sensitivity: 0.8609 - specificity: 0.9996\n","Epoch 00046: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0030 - acc: 0.9990 - dice_coef: 0.7851 - precision: 0.8959 - sensitivity: 0.8592 - specificity: 0.9996 - val_loss: 0.0046 - val_acc: 0.9986 - val_dice_coef: 0.7326 - val_precision: 0.8928 - val_sensitivity: 0.7739 - val_specificity: 0.9996\n","Epoch 47/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.7962 - precision: 0.8995 - sensitivity: 0.8648 - specificity: 0.9996\n","Epoch 00047: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0029 - acc: 0.9991 - dice_coef: 0.7914 - precision: 0.8971 - sensitivity: 0.8606 - specificity: 0.9996 - val_loss: 0.0047 - val_acc: 0.9987 - val_dice_coef: 0.7675 - val_precision: 0.8955 - val_sensitivity: 0.7905 - val_specificity: 0.9996\n","Epoch 48/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9991 - dice_coef: 0.8008 - precision: 0.9018 - sensitivity: 0.8692 - specificity: 0.9996\n","Epoch 00048: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0028 - acc: 0.9991 - dice_coef: 0.7977 - precision: 0.9002 - sensitivity: 0.8665 - specificity: 0.9996 - val_loss: 0.0050 - val_acc: 0.9984 - val_dice_coef: 0.7564 - val_precision: 0.7850 - val_sensitivity: 0.8792 - val_specificity: 0.9989\n","Epoch 49/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9991 - dice_coef: 0.7983 - precision: 0.8971 - sensitivity: 0.8666 - specificity: 0.9996\n","Epoch 00049: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0028 - acc: 0.9991 - dice_coef: 0.7970 - precision: 0.8961 - sensitivity: 0.8673 - specificity: 0.9996 - val_loss: 0.0047 - val_acc: 0.9986 - val_dice_coef: 0.7435 - val_precision: 0.9039 - val_sensitivity: 0.7638 - val_specificity: 0.9996\n","Epoch 50/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8123 - precision: 0.9074 - sensitivity: 0.8748 - specificity: 0.9996\n","Epoch 00050: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8118 - precision: 0.9076 - sensitivity: 0.8734 - specificity: 0.9996 - val_loss: 0.0046 - val_acc: 0.9986 - val_dice_coef: 0.7759 - val_precision: 0.8203 - val_sensitivity: 0.8690 - val_specificity: 0.9991\n","Epoch 51/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8168 - precision: 0.9094 - sensitivity: 0.8771 - specificity: 0.9996\n","Epoch 00051: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0025 - acc: 0.9991 - dice_coef: 0.8154 - precision: 0.9081 - sensitivity: 0.8764 - specificity: 0.9996 - val_loss: 0.0047 - val_acc: 0.9985 - val_dice_coef: 0.7785 - val_precision: 0.8259 - val_sensitivity: 0.8521 - val_specificity: 0.9992\n","Epoch 52/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9991 - dice_coef: 0.8197 - precision: 0.9052 - sensitivity: 0.8831 - specificity: 0.9996\n","Epoch 00052: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0025 - acc: 0.9991 - dice_coef: 0.8187 - precision: 0.9043 - sensitivity: 0.8830 - specificity: 0.9996 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.7950 - val_precision: 0.8541 - val_sensitivity: 0.8562 - val_specificity: 0.9993\n","Epoch 53/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992 - dice_coef: 0.8271 - precision: 0.9130 - sensitivity: 0.8822 - specificity: 0.9996\n","Epoch 00053: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0024 - acc: 0.9992 - dice_coef: 0.8244 - precision: 0.9117 - sensitivity: 0.8803 - specificity: 0.9997 - val_loss: 0.0046 - val_acc: 0.9986 - val_dice_coef: 0.7640 - val_precision: 0.9015 - val_sensitivity: 0.7685 - val_specificity: 0.9996\n","Epoch 54/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8309 - precision: 0.9125 - sensitivity: 0.8880 - specificity: 0.9996\n","Epoch 00054: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8296 - precision: 0.9109 - sensitivity: 0.8875 - specificity: 0.9996 - val_loss: 0.0046 - val_acc: 0.9985 - val_dice_coef: 0.7500 - val_precision: 0.8596 - val_sensitivity: 0.8008 - val_specificity: 0.9994\n","Epoch 55/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8316 - precision: 0.9150 - sensitivity: 0.8833 - specificity: 0.9997\n","Epoch 00055: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.8313 - precision: 0.9149 - sensitivity: 0.8829 - specificity: 0.9997 - val_loss: 0.0049 - val_acc: 0.9985 - val_dice_coef: 0.7432 - val_precision: 0.9136 - val_sensitivity: 0.7283 - val_specificity: 0.9997\n","Epoch 56/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8363 - precision: 0.9134 - sensitivity: 0.8913 - specificity: 0.9996\n","Epoch 00056: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8344 - precision: 0.9132 - sensitivity: 0.8886 - specificity: 0.9997 - val_loss: 0.0045 - val_acc: 0.9986 - val_dice_coef: 0.7915 - val_precision: 0.8571 - val_sensitivity: 0.8346 - val_specificity: 0.9994\n","Epoch 57/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8334 - precision: 0.9107 - sensitivity: 0.8889 - specificity: 0.9997\n","Epoch 00057: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.8326 - precision: 0.9104 - sensitivity: 0.8878 - specificity: 0.9997 - val_loss: 0.0046 - val_acc: 0.9986 - val_dice_coef: 0.7962 - val_precision: 0.8433 - val_sensitivity: 0.8515 - val_specificity: 0.9993\n","Epoch 58/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8373 - precision: 0.9138 - sensitivity: 0.8896 - specificity: 0.9997\n","Epoch 00058: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8377 - precision: 0.9136 - sensitivity: 0.8902 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9986 - val_dice_coef: 0.7684 - val_precision: 0.8497 - val_sensitivity: 0.8264 - val_specificity: 0.9993\n","Epoch 59/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8455 - precision: 0.9166 - sensitivity: 0.8948 - specificity: 0.9997\n","Epoch 00059: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8458 - precision: 0.9170 - sensitivity: 0.8950 - specificity: 0.9997 - val_loss: 0.0043 - val_acc: 0.9987 - val_dice_coef: 0.8024 - val_precision: 0.8624 - val_sensitivity: 0.8449 - val_specificity: 0.9994\n","Epoch 60/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.8492 - precision: 0.9188 - sensitivity: 0.8992 - specificity: 0.9997\n","Epoch 00060: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.8505 - precision: 0.9196 - sensitivity: 0.9003 - specificity: 0.9997 - val_loss: 0.0050 - val_acc: 0.9985 - val_dice_coef: 0.7963 - val_precision: 0.8071 - val_sensitivity: 0.8702 - val_specificity: 0.9991\n","2499/2499 [==============================] - 8s 3ms/sample - loss: 0.0029 - acc: 0.9990 - dice_coef: 0.8292 - precision: 0.8361 - sensitivity: 0.9162 - specificity: 0.9993\n","441/441 [==============================] - 2s 4ms/sample - loss: 0.0043 - acc: 0.9987 - dice_coef: 0.8185 - precision: 0.8294 - sensitivity: 0.8902 - specificity: 0.9992\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.0043177661726720076, 0.99872905, 0.8185155, 0.82937396, 0.890223, 0.9992019]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"14Plv9T1zfdz","colab_type":"code","outputId":"58207ee4-628c-4b08-e75d-e9d1f60443a8","executionInfo":{"status":"ok","timestamp":1584084685789,"user_tz":-330,"elapsed":1940,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Accuracy vs Epoch\n","def Accuracy_Graph(history):\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    #plt.title('Model accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","    \n","# Dice Similarity Coefficient vs Epoch\n","def Dice_coefficient_Graph(history):\n","\n","    plt.plot(history.history['dice_coef'])\n","    plt.plot(history.history['val_dice_coef'])\n","    #plt.title('Dice_Coefficient')\n","    plt.ylabel('Dice_Coefficient')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","# Loss vs Epoch\n","def Loss_Graph(history):\n","\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    #plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n","                        wspace=0.35)\n","    plt.show()\n","Accuracy_Graph(history)\n","Dice_coefficient_Graph(history)\n","Loss_Graph(history)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdQAAAFNCAYAAAC5Tp7nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUKCKiIg0wf8PfmdQ0DO2dxAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAc4AAAFNCAYAAACJwo/GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRESSoMIpIiKSBBVOERGRJPwfi49Xi0uxwTcAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAc0AAAFOCAYAAADkYUZrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUiSFpoiISJEUmiIiIkX6/1dnuf5OVM61AAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ddJNTtraL65N","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 18:52:08 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","\n","from keras import backend as K\n","import numpy as np\n","import tensorflow as tf\n","\n","# Computing Dice_Coefficient\n","def dice_coef(y_true, y_pred, smooth=1.0):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","# Computing Precision \n","def precision(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","# Computing Sensitivity      \n","def sensitivity(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    return true_positives / (possible_positives + K.epsilon())\n","\n","# Computing Specificity\n","def specificity(y_true, y_pred):\n","    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n","    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n","    return true_negatives / (possible_negatives + K.epsilon())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja6JC8YDMDci","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import nibabel as nib\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","    \n","def modality(Path,index):\n","    X = []\n","    p=os.listdir(Path) \n","\n","    for i in p[:14]:                                                                      # Loading all the folders in the given path\n","        q = os.listdir(os.path.join(Path,i))     \n","\n","        x = nib.load(os.path.join(Path,i,q[index]))         \n","        f = x.get_fdata()\n","        f = np.asarray(f,'float32')\n","        \n","        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n","            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n","            if(index != 3 and np.sum(_slice) != 0 ):                                           # To check whether the slice is null or not\n","              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n","                _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n","            elif(index == 3):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n","                _slice = np.array(_slice)\n","                _slice[_slice > 0] = 1.0\n","            _slice = _slice.T\n","            _slice = _slice[:,:,np.newaxis]\n","            X.append(_slice)\n","    return X\n","\n","# Removing the null samples as it contains no information\n","def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual): \n","     \n","    X=[]\n","    Y=[]\n","    \n","    for i in range(len(X_Dp)):        \n","        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n","        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n","            X.append(final_slice)\n","            Y.append(Y_Manual[i])\n"," \n","#   Converting the list into array  \n","    X=np.array(X,dtype='float32')\n","    Y=np.array(Y,dtype='float32')\n","    \n","    return X,Y\n","\n","#   To store the data in numpy format    \n","def store_data(X,Y):\n","    np.save(\"X.npy\",X)\n","    np.save(\"Y.npy\",Y)\n","\n","\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"97cxigbAUrNA","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 18:56:04 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","import tensorflow as tf\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","\n","\n","def Convolution(input_tensor,filters):\n","    \n","    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x) \n","    return x\n","\n","def model(input_shape):\n","    \n","    inputs = Input((input_shape))\n","    \n","    conv_1 = Convolution(inputs,32)\n","    conv_1 = Convolution(conv_1,32)\n","\n","    \n","    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n","    maxp_1= Dropout(0.4)(maxp_1)\n","    \n","    conv_2 = Convolution(maxp_1,64)\n","    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n","    maxp_2= Dropout(0.2)(maxp_2)\n","\n","    conv_3 = Convolution(maxp_2,128)\n","    conv_3 = Convolution(conv_3,128)\n","    \n","    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n","    maxp_3= Dropout(0.4)(maxp_3)\n","    \n","    conv_4 = Convolution(maxp_3,256)\n","    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n","    maxp_4= Dropout(0.2)(maxp_4)\n","    \n","    conv_5 = Convolution(maxp_4,512)\n","    conv_5 = Convolution(conv_5,512)\n","    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n","\n","    upsample_6 = concatenate([upsample_6, conv_4])\n","    \n","    conv_6 = Convolution(upsample_6,256)\n","    \n","    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n","    \n","    upsample_7 = concatenate([upsample_7, conv_3])\n","    \n","    conv_7 = Convolution(upsample_7,128)\n","    conv_7 = Convolution(conv_7,128)\n","    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n","    \n","    upsample_8 = concatenate([upsample_8, conv_2])\n","\n","    conv_8 = Convolution(upsample_8,64)\n","    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n","    \n","    upsample_9 = concatenate([upsample_9, conv_1])\n","    \n","    conv_9 = Convolution(upsample_9,32)\n","    conv_9 = Convolution(conv_9,32)\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n","    \n","    model = Model(inputs=[inputs], outputs=[outputs]) \n","    \n","    return model\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dP9xbbYUV_VA","colab_type":"code","outputId":"ff9c1d22-0390-4b30-aa64-870f1c1efd3c","executionInfo":{"status":"error","timestamp":1584195840198,"user_tz":-330,"elapsed":97548,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 20:18:06 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","X_Dp      =   modality(Path,0)\n","X_Flair   =   modality(Path,1)\n","X_Gado    =   modality(Path,2)\n","X_T1      =   modality(Path,10)\n","X_T2      =   modality(Path,11)\n","Y_Manual  =   modality(Path,3)\n","\n","# Removing the null samples and concatenating the 5 modalities along the 3rd dimension\n","X, Y = remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual)\n","\n","\n","# Splitting the Whole data into Training and Testing data\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","\n","# Loding the modified U-net \n","model = model(input_shape = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('Modified_UNet.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('Modified_UNet.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)\n","#Loss_Graph(history)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 5) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 32) 1472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 256, 256, 32) 128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 256, 256, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 128, 128, 32) 0           max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 128, 128, 64) 18496       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 64, 64, 64)   0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 64, 64, 128)  73856       dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 64, 64, 128)  147584      activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 32, 32, 128)  0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 256)  295168      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 16, 16, 256)  0           max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 16, 16, 512)  1180160     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 16, 16, 512)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 16, 16, 512)  2359808     activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 32, 32, 512)  0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 768)  0           up_sampling2d[0][0]              \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 256)  1769728     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_8[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_1[0][0]            \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 64, 64, 128)  442496      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 64, 64, 128)  512         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 64, 64, 128)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 64, 64, 128)  147584      activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           activation_10[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_2[0][0]            \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 128, 128, 64) 256         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 128, 128, 64) 0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           activation_11[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_3[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 256, 256, 32) 27680       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 256, 256, 32) 128         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 256, 256, 32) 0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 256, 256, 32) 9248        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 256, 256, 32) 128         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 256, 256, 32) 0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 256, 256, 1)  33          activation_13[0][0]              \n","==================================================================================================\n","Total params: 6,602,433\n","Trainable params: 6,597,825\n","Non-trainable params: 4,608\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 1999 samples, validate on 500 samples\n","Epoch 1/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9633 - dice_coef: 0.0356 - precision: 0.5770 - sensitivity: 0.7850 - specificity: 0.9640\n","Epoch 00001: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 109s 54ms/sample - loss: 0.2460 - acc: 0.9635 - dice_coef: 0.0358 - precision: 0.5810 - sensitivity: 0.7848 - specificity: 0.9645 - val_loss: 0.3225 - val_acc: 0.9959 - val_dice_coef: 0.0090 - val_precision: 0.7892 - val_sensitivity: 0.1665 - val_specificity: 0.9998\n","Epoch 2/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9980 - dice_coef: 0.0642 - precision: 0.8225 - sensitivity: 0.6701 - specificity: 0.9994\n","Epoch 00002: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 43ms/sample - loss: 0.0932 - acc: 0.9980 - dice_coef: 0.0642 - precision: 0.8213 - sensitivity: 0.6703 - specificity: 0.9994 - val_loss: 0.1211 - val_acc: 0.9979 - val_dice_coef: 0.0524 - val_precision: 0.8362 - val_sensitivity: 0.6744 - val_specificity: 0.9994\n","Epoch 3/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9981 - dice_coef: 0.0989 - precision: 0.8369 - sensitivity: 0.6812 - specificity: 0.9995\n","Epoch 00003: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 43ms/sample - loss: 0.0555 - acc: 0.9981 - dice_coef: 0.0990 - precision: 0.8366 - sensitivity: 0.6802 - specificity: 0.9995 - val_loss: 0.0642 - val_acc: 0.9979 - val_dice_coef: 0.0993 - val_precision: 0.7842 - val_sensitivity: 0.7473 - val_specificity: 0.9991\n","Epoch 4/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9982 - dice_coef: 0.1409 - precision: 0.8314 - sensitivity: 0.6933 - specificity: 0.9994\n","Epoch 00004: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 43ms/sample - loss: 0.0370 - acc: 0.9981 - dice_coef: 0.1434 - precision: 0.8329 - sensitivity: 0.6935 - specificity: 0.9994 - val_loss: 0.0372 - val_acc: 0.9980 - val_dice_coef: 0.1550 - val_precision: 0.8184 - val_sensitivity: 0.7153 - val_specificity: 0.9993\n","Epoch 5/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9982 - dice_coef: 0.1924 - precision: 0.8278 - sensitivity: 0.7084 - specificity: 0.9994\n","Epoch 00005: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 44ms/sample - loss: 0.0267 - acc: 0.9982 - dice_coef: 0.1922 - precision: 0.8281 - sensitivity: 0.7074 - specificity: 0.9994 - val_loss: 0.0249 - val_acc: 0.9980 - val_dice_coef: 0.2144 - val_precision: 0.8398 - val_sensitivity: 0.6992 - val_specificity: 0.9994\n","Epoch 6/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9982 - dice_coef: 0.2374 - precision: 0.8298 - sensitivity: 0.7115 - specificity: 0.9994\n","Epoch 00006: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 43ms/sample - loss: 0.0204 - acc: 0.9982 - dice_coef: 0.2373 - precision: 0.8316 - sensitivity: 0.7120 - specificity: 0.9994 - val_loss: 0.0192 - val_acc: 0.9980 - val_dice_coef: 0.2498 - val_precision: 0.8651 - val_sensitivity: 0.6456 - val_specificity: 0.9995\n","Epoch 7/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9983 - dice_coef: 0.2865 - precision: 0.8326 - sensitivity: 0.7296 - specificity: 0.9994\n","Epoch 00007: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 43ms/sample - loss: 0.0163 - acc: 0.9983 - dice_coef: 0.2850 - precision: 0.8325 - sensitivity: 0.7293 - specificity: 0.9994 - val_loss: 0.0155 - val_acc: 0.9981 - val_dice_coef: 0.3290 - val_precision: 0.8240 - val_sensitivity: 0.7431 - val_specificity: 0.9993\n","Epoch 8/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9983 - dice_coef: 0.3350 - precision: 0.8282 - sensitivity: 0.7426 - specificity: 0.9994\n","Epoch 00008: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 44ms/sample - loss: 0.0136 - acc: 0.9983 - dice_coef: 0.3354 - precision: 0.8292 - sensitivity: 0.7429 - specificity: 0.9994 - val_loss: 0.0132 - val_acc: 0.9981 - val_dice_coef: 0.3599 - val_precision: 0.8501 - val_sensitivity: 0.7214 - val_specificity: 0.9994\n","Epoch 9/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9983 - dice_coef: 0.3710 - precision: 0.8305 - sensitivity: 0.7525 - specificity: 0.9994\n","Epoch 00009: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 44ms/sample - loss: 0.0118 - acc: 0.9983 - dice_coef: 0.3685 - precision: 0.8291 - sensitivity: 0.7480 - specificity: 0.9994 - val_loss: 0.0117 - val_acc: 0.9981 - val_dice_coef: 0.3898 - val_precision: 0.8443 - val_sensitivity: 0.7099 - val_specificity: 0.9994\n","Epoch 10/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9983 - dice_coef: 0.4073 - precision: 0.8268 - sensitivity: 0.7561 - specificity: 0.9994\n","Epoch 00010: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 43ms/sample - loss: 0.0105 - acc: 0.9983 - dice_coef: 0.4083 - precision: 0.8263 - sensitivity: 0.7582 - specificity: 0.9993 - val_loss: 0.0102 - val_acc: 0.9982 - val_dice_coef: 0.4476 - val_precision: 0.8369 - val_sensitivity: 0.7309 - val_specificity: 0.9993\n","Epoch 11/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9984 - dice_coef: 0.4352 - precision: 0.8268 - sensitivity: 0.7606 - specificity: 0.9994\n","Epoch 00011: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 43ms/sample - loss: 0.0094 - acc: 0.9984 - dice_coef: 0.4370 - precision: 0.8275 - sensitivity: 0.7601 - specificity: 0.9994 - val_loss: 0.0096 - val_acc: 0.9982 - val_dice_coef: 0.4810 - val_precision: 0.8154 - val_sensitivity: 0.7558 - val_specificity: 0.9993\n","Epoch 12/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9984 - dice_coef: 0.4635 - precision: 0.8251 - sensitivity: 0.7626 - specificity: 0.9993\n","Epoch 00012: saving model to Modified_UNet.h5\n","1999/1999 [==============================] - 87s 43ms/sample - loss: 0.0087 - acc: 0.9984 - dice_coef: 0.4612 - precision: 0.8246 - sensitivity: 0.7614 - specificity: 0.9994 - val_loss: 0.0086 - val_acc: 0.9983 - val_dice_coef: 0.5145 - val_precision: 0.8187 - val_sensitivity: 0.7873 - val_specificity: 0.9992\n","Epoch 13/60\n","1088/1999 [===============>..............] - ETA: 36s - loss: 0.0080 - acc: 0.9984 - dice_coef: 0.4693 - precision: 0.8239 - sensitivity: 0.7523 - specificity: 0.9994"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"trf3JP4yePO0","colab_type":"code","colab":{}},"source":["\n","import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import numpy as np\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as keras\n","\n","\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = Model(input = inputs, output = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    \n","    #model.summary()\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VALSiWESHPOI","colab_type":"text"},"source":["# **UNION MODEL RESULTS**"]},{"cell_type":"code","metadata":{"id":"VGWFdd0Gee9D","colab_type":"code","outputId":"50164221-8145-45b5-b933-22293ba8ca72","executionInfo":{"status":"error","timestamp":1584196867651,"user_tz":-330,"elapsed":73301,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","X_Dp      =   modality(Path,0)\n","X_Flair   =   modality(Path,1)\n","X_Gado    =   modality(Path,2)\n","X_T1      =   modality(Path,10)\n","X_T2      =   modality(Path,11)\n","Y_Manual  =   modality(Path,3)\n","\n","# Removing the null samples and concatenating the 5 modalities along the 3rd dimension\n","X, Y = remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual)\n","\n","\n","# Splitting the Whole data into Training and Testing data\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","\n","# Loding the modified U-net \n","model = unet(input_size = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('Modified_UNet.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('Modified_UNet.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)\n","#Loss_Graph(history)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-19bee8787620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Loding the modified U-net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-626b05590d97>\u001b[0m in \u001b[0;36munet\u001b[0;34m(pretrained_weights, input_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mconv4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mconv4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdrop4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mpool4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mprevious_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collect_previous_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0muser_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_all_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_collect_previous_mask\u001b[0;34m(input_tensors)\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0minbound_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'output_masks'"]}]},{"cell_type":"code","metadata":{"id":"2w1IJip9HuTv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJpNNClzHwHz","colab_type":"text"},"source":["# **UNION MODEL RESULTS**"]},{"cell_type":"code","metadata":{"id":"s-VbmjONNK_s","colab_type":"code","outputId":"ce93fc0e-74fc-4080-9e0e-1e265cfe503b","executionInfo":{"status":"ok","timestamp":1585160190799,"user_tz":-330,"elapsed":1225,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Dec 13 18:52:08 2019\n","\n","@author: Krishna Chandra\n","\"\"\"\n","\n","from keras import backend as K\n","import numpy as np\n","import tensorflow as tf\n","\n","# Computing Dice_Coefficient\n","def dice_coef(y_true, y_pred, smooth=1.0):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","# Computing Precision \n","def precision(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","# Computing Sensitivity      \n","def sensitivity(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    return true_positives / (possible_positives + K.epsilon())\n","\n","# Computing Specificity\n","def specificity(y_true, y_pred):\n","    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n","    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n","    return true_negatives / (possible_negatives + K.epsilon())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"isR_MW1XNrV0","colab_type":"code","colab":{}},"source":["def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_1, Y_2, Y_3, Y_4, Y_5, Y_6, Y_7): \n","     \n","    X=[]\n","    Y_a1=[]\n","    Y_a2=[]\n","    Y_a3=[]\n","    Y_a4=[]\n","    Y_a5=[]\n","    Y_a6=[]\n","    Y_a7=[]\n","\n","    for i in range(len(X_Dp)):        \n","        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n","        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n","            X.append(final_slice)\n","            Y_a1.append(Y_1[i])\n","            Y_a2.append(Y_2[i])\n","            Y_a3.append(Y_3[i])\n","            Y_a4.append(Y_4[i])\n","            Y_a5.append(Y_5[i])\n","            Y_a6.append(Y_6[i])\n","            Y_a7.append(Y_7[i])\n"," \n","#   Converting the list into array  \n","    X=np.array(X,dtype='float32')\n","    Y_1=np.array(Y_a1,dtype='float32')\n","    Y_2=np.array(Y_a2,dtype='float32')\n","    Y_3=np.array(Y_a3,dtype='float32')\n","    Y_4=np.array(Y_a4,dtype='float32')\n","    Y_5=np.array(Y_a5,dtype='float32')\n","    Y_6=np.array(Y_a6,dtype='float32')\n","    Y_7=np.array(Y_a7,dtype='float32')\n","    \n","    \n","\n","    \n","    return X,Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7\n","\n","\n","#   To store the data in numpy format   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"73JoBEggNxf7","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import nibabel as nib\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","    \n","def modality(Path,index):\n","    X = []\n","    p=os.listdir(Path) \n","\n","    for i in p[:14]:                                                                      # Loading all the folders in the given path\n","        q = os.listdir(os.path.join(Path,i))     \n","\n","        x = nib.load(os.path.join(Path,i,q[index]))         \n","        f = x.get_fdata()\n","        f = np.asarray(f,'float32')\n","        \n","        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n","            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n","            if(index not in [3,4,5,6,7,8,9] and np.sum(_slice) != 0 ):  \n","                print(\"DONE\")                                         # To check whether the slice is null or not\n","              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n","                _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n","            elif(index in [3,4,5,6,7,8,9]):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n","                _slice = np.array(_slice)\n","                _slice[_slice > 0] = 1.0\n","                _slice[_slice < 0] = 0.0\n","            _slice = _slice.T\n","            _slice = _slice[:,:,np.newaxis]\n","            X.append(_slice)\n","   # X=np.array(X,dtype='float32')\n","    return X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4GxnKPlOd0M","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","import keras\n","from keras.models import Model, load_model\n","from keras.layers import Input ,BatchNormalization , Activation \n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.merge import concatenate\n","\n","\n","def Convolution(input_tensor,filters):\n","    \n","    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x) \n","    return x\n","\n","def model(input_shape):\n","    \n","    inputs = Input((input_shape))\n","    \n","    conv_1 = Convolution(inputs,32)\n","    \n","    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n","    \n","    conv_2 = Convolution(maxp_1,64)\n","    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n","    \n","    conv_3 = Convolution(maxp_2,128)\n","    \n","    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n","    \n","    conv_4 = Convolution(maxp_3,256)\n","    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n","    \n","    conv_5 = Convolution(maxp_4,512)\n","   \n","    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n","\n","    upsample_6 = concatenate([upsample_6, conv_4])\n","    \n","    conv_6 = Convolution(upsample_6,256)\n","    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n","    \n","    upsample_7 = concatenate([upsample_7, conv_3])\n","    \n","    conv_7 = Convolution(upsample_7,128)\n","    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n","    \n","    upsample_8 = concatenate([upsample_8, conv_2])\n","\n","    conv_8 = Convolution(upsample_8,64)\n","    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n","    \n","    upsample_9 = concatenate([upsample_9, conv_1])\n","    \n","    conv_9 = Convolution(upsample_9,32)\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n","    \n","    model = Model(inputs=[inputs], outputs=[outputs]) \n","    \n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYrB9vNeOkXG","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","X_Dp_t      =   modality(Path,0)\n","X_Flair_t   =   modality(Path,1)\n","X_Gado_t    =   modality(Path,2)\n","X_T1_t      =   modality(Path,10)\n","X_T2_t      =   modality(Path,11)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xplBrTSKOsRJ","colab_type":"code","colab":{}},"source":["\n","Y_1  =   modality(Path,3)\n","Y_2  =   modality(Path,4)\n","Y_3  =   modality(Path,5)\n","Y_4  =   modality(Path,6)\n","Y_5  =   modality(Path,7)\n","Y_6  =   modality(Path,8)\n","Y_7  =   modality(Path,9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NwQX-PWOtQc","colab_type":"code","colab":{}},"source":["def store_data(X,Y):\n","    np.save(\"drive/My Drive/MS_data/X_union_new.npy\",X)\n","    np.save(\"drive/My Drive/MS_data/Y_union_new.npy\",Y)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pckiKg5cQiei","colab_type":"code","colab":{}},"source":["X, Y_a1,Y_a2,Y_a3,Y_a4,Y_a5,Y_a6,Y_a7 = remove_null_samples(X_Dp_t, X_Flair_t, X_Gado_t, X_T1_t, X_T2_t, Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KndBtj1JbJbw","colab_type":"code","colab":{}},"source":["import math\n","def union(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7):\n","  Y=[]\n","  sum2=[]\n","  flag=0\n","  #y=np.array()\n","  print(\"A\")\n","  for i in range (len(Y_1)):\n","    #print(Y_1[i])\n","    \n","        f=np.concatenate((Y_1[i],Y_2[i],Y_3[i],Y_4[i],Y_5[i],Y_6[i],Y_7[i]),axis=-1)\n","        sum=np.sum(f,axis=2)\n","       # print(sum)\n","        \n","          #print(j)\n","        sum_1=np.divide(sum,7)\n","        sum_1=np.ceil(sum_1)\n","        sum2.append(sum_1)\n","\n","    #sum2=np.array(sum2,dtype='float32')\n","    \n","        \n","  return sum2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jw8ZHiQObSES","colab_type":"code","outputId":"1235284d-91c2-4e95-a8e1-cee799d056f0","executionInfo":{"status":"ok","timestamp":1585157035418,"user_tz":-330,"elapsed":14474,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["Y_Manual=union(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O0qawHmtuU7Y","colab_type":"code","colab":{}},"source":["def remove_null_samples_2(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual): \n","     \n","    X=[]\n","    Y=[]\n","    \n","    for i in range(len(X_Dp)):        \n","        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n","        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n","            X.append(final_slice)\n","            Y.append(Y_Manual[i])\n"," \n","#   Converting the list into array  \n","    X=np.array(X,dtype='float32')\n","    Y=np.array(Y,dtype='float32')\n","    \n","    return X,Y\n","\n","\n","#   To store the data in numpy for"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wsSCpcccu8St","colab_type":"code","colab":{}},"source":["Y_manual=np.load(\"drive/My Drive/MS_data/Y_manual_new.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nhzHFta62wcH","colab_type":"code","outputId":"6d424d36-6ca9-41d7-f5c0-45f63f6c8017","executionInfo":{"status":"ok","timestamp":1585159312344,"user_tz":-330,"elapsed":2360,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(np.max(Y_manual))\n","print(np.min(Y_manual))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.0\n","0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TFtgpk5punxj","colab_type":"code","colab":{}},"source":["X, Y = remove_null_samples_2(X_Dp_t, X_Flair_t, X_Gado_t, X_T1_t, X_T2_t, Y_manual)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSwm3V-Uv9VO","colab_type":"code","colab":{}},"source":["store_data(X,Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3xXvGLquuQl7","colab_type":"code","colab":{}},"source":["Y=np.array(Y_Manual,dtype='float32')\n","np.save(\"drive/My Drive/MS_data/Y_manual_new.npy\",Y)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oj1HVIqvbS9-","colab_type":"code","outputId":"f20bc819-a7d9-48ed-e8f1-e89fa7b98e1f","executionInfo":{"status":"ok","timestamp":1585157663462,"user_tz":-330,"elapsed":3604,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["Y_Manual_1=np.array(Y,dtype='float32')\n","print(np.min(Y_Manual_1))\n","\n","print(np.max(Y_Manual_1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.0\n","1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZQ94cF5yxMq9","colab_type":"code","colab":{}},"source":["import numpy as np\n","#X=np.load(\"drive/My Drive/MS_data/X_union_new.npy\")\n","Y=np.load(\"drive/My Drive/MS_data/Y_union_new.npy\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cB_P_lCB5Osw","colab_type":"code","outputId":"d1941e42-ac4b-482a-d7f0-c56cf42e8f2f","executionInfo":{"status":"ok","timestamp":1585159944365,"user_tz":-330,"elapsed":1220,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(np.min(Y))\n","\n","print(np.max(Y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.0\n","1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rJCQpYtfbhCE","colab_type":"code","colab":{}},"source":["Y_Manual=list(Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SwoJegstdHrZ","colab_type":"code","colab":{}},"source":["Y_1=Y_Manual[:1401]\n","Y_2=Y_Manual[1401:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvvWBuCk5VMA","colab_type":"code","colab":{}},"source":["Y_A_1=np.array(Y_1,dtype='float32')\n","Y_A_2=np.array(Y_2,dtype='float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZFUaiCA5f1J","colab_type":"code","outputId":"f571d6af-26e1-4a7d-90bf-36a8012fc116","executionInfo":{"status":"ok","timestamp":1585160043094,"user_tz":-330,"elapsed":1418,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print(np.min(Y_A_1))\n","print(np.min(Y_A_2))\n","print(np.max(Y_A_1))\n","print(np.max(Y_A_2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.0\n","0.0\n","1.0\n","1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"geLCXT2MdPKX","colab_type":"code","outputId":"9d206c50-7805-4735-fd45-a2ce2831af7e","executionInfo":{"status":"ok","timestamp":1585158117678,"user_tz":-330,"elapsed":72147,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["p=[]\n","y=[]\n","z=[]\n","a=[]\n","n=1\n","for i in Y_1:\n","  print(n)\n","  for j in i:\n","    for k in j:\n","      #print(k)\n","      a.append(k)\n","     # print(a)\n","      z.append(a)\n","      a=[]\n","    #print(z)\n","    y.append(z)\n","    z=[]\n","  p.append(y)\n","  y=[]\n","  n+=1\n","\n","\n","#print(p)\n","\n","      "],"execution_count":0,"outputs":[{"output_type":"stream","text":["1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","511\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n","540\n","541\n","542\n","543\n","544\n","545\n","546\n","547\n","548\n","549\n","550\n","551\n","552\n","553\n","554\n","555\n","556\n","557\n","558\n","559\n","560\n","561\n","562\n","563\n","564\n","565\n","566\n","567\n","568\n","569\n","570\n","571\n","572\n","573\n","574\n","575\n","576\n","577\n","578\n","579\n","580\n","581\n","582\n","583\n","584\n","585\n","586\n","587\n","588\n","589\n","590\n","591\n","592\n","593\n","594\n","595\n","596\n","597\n","598\n","599\n","600\n","601\n","602\n","603\n","604\n","605\n","606\n","607\n","608\n","609\n","610\n","611\n","612\n","613\n","614\n","615\n","616\n","617\n","618\n","619\n","620\n","621\n","622\n","623\n","624\n","625\n","626\n","627\n","628\n","629\n","630\n","631\n","632\n","633\n","634\n","635\n","636\n","637\n","638\n","639\n","640\n","641\n","642\n","643\n","644\n","645\n","646\n","647\n","648\n","649\n","650\n","651\n","652\n","653\n","654\n","655\n","656\n","657\n","658\n","659\n","660\n","661\n","662\n","663\n","664\n","665\n","666\n","667\n","668\n","669\n","670\n","671\n","672\n","673\n","674\n","675\n","676\n","677\n","678\n","679\n","680\n","681\n","682\n","683\n","684\n","685\n","686\n","687\n","688\n","689\n","690\n","691\n","692\n","693\n","694\n","695\n","696\n","697\n","698\n","699\n","700\n","701\n","702\n","703\n","704\n","705\n","706\n","707\n","708\n","709\n","710\n","711\n","712\n","713\n","714\n","715\n","716\n","717\n","718\n","719\n","720\n","721\n","722\n","723\n","724\n","725\n","726\n","727\n","728\n","729\n","730\n","731\n","732\n","733\n","734\n","735\n","736\n","737\n","738\n","739\n","740\n","741\n","742\n","743\n","744\n","745\n","746\n","747\n","748\n","749\n","750\n","751\n","752\n","753\n","754\n","755\n","756\n","757\n","758\n","759\n","760\n","761\n","762\n","763\n","764\n","765\n","766\n","767\n","768\n","769\n","770\n","771\n","772\n","773\n","774\n","775\n","776\n","777\n","778\n","779\n","780\n","781\n","782\n","783\n","784\n","785\n","786\n","787\n","788\n","789\n","790\n","791\n","792\n","793\n","794\n","795\n","796\n","797\n","798\n","799\n","800\n","801\n","802\n","803\n","804\n","805\n","806\n","807\n","808\n","809\n","810\n","811\n","812\n","813\n","814\n","815\n","816\n","817\n","818\n","819\n","820\n","821\n","822\n","823\n","824\n","825\n","826\n","827\n","828\n","829\n","830\n","831\n","832\n","833\n","834\n","835\n","836\n","837\n","838\n","839\n","840\n","841\n","842\n","843\n","844\n","845\n","846\n","847\n","848\n","849\n","850\n","851\n","852\n","853\n","854\n","855\n","856\n","857\n","858\n","859\n","860\n","861\n","862\n","863\n","864\n","865\n","866\n","867\n","868\n","869\n","870\n","871\n","872\n","873\n","874\n","875\n","876\n","877\n","878\n","879\n","880\n","881\n","882\n","883\n","884\n","885\n","886\n","887\n","888\n","889\n","890\n","891\n","892\n","893\n","894\n","895\n","896\n","897\n","898\n","899\n","900\n","901\n","902\n","903\n","904\n","905\n","906\n","907\n","908\n","909\n","910\n","911\n","912\n","913\n","914\n","915\n","916\n","917\n","918\n","919\n","920\n","921\n","922\n","923\n","924\n","925\n","926\n","927\n","928\n","929\n","930\n","931\n","932\n","933\n","934\n","935\n","936\n","937\n","938\n","939\n","940\n","941\n","942\n","943\n","944\n","945\n","946\n","947\n","948\n","949\n","950\n","951\n","952\n","953\n","954\n","955\n","956\n","957\n","958\n","959\n","960\n","961\n","962\n","963\n","964\n","965\n","966\n","967\n","968\n","969\n","970\n","971\n","972\n","973\n","974\n","975\n","976\n","977\n","978\n","979\n","980\n","981\n","982\n","983\n","984\n","985\n","986\n","987\n","988\n","989\n","990\n","991\n","992\n","993\n","994\n","995\n","996\n","997\n","998\n","999\n","1000\n","1001\n","1002\n","1003\n","1004\n","1005\n","1006\n","1007\n","1008\n","1009\n","1010\n","1011\n","1012\n","1013\n","1014\n","1015\n","1016\n","1017\n","1018\n","1019\n","1020\n","1021\n","1022\n","1023\n","1024\n","1025\n","1026\n","1027\n","1028\n","1029\n","1030\n","1031\n","1032\n","1033\n","1034\n","1035\n","1036\n","1037\n","1038\n","1039\n","1040\n","1041\n","1042\n","1043\n","1044\n","1045\n","1046\n","1047\n","1048\n","1049\n","1050\n","1051\n","1052\n","1053\n","1054\n","1055\n","1056\n","1057\n","1058\n","1059\n","1060\n","1061\n","1062\n","1063\n","1064\n","1065\n","1066\n","1067\n","1068\n","1069\n","1070\n","1071\n","1072\n","1073\n","1074\n","1075\n","1076\n","1077\n","1078\n","1079\n","1080\n","1081\n","1082\n","1083\n","1084\n","1085\n","1086\n","1087\n","1088\n","1089\n","1090\n","1091\n","1092\n","1093\n","1094\n","1095\n","1096\n","1097\n","1098\n","1099\n","1100\n","1101\n","1102\n","1103\n","1104\n","1105\n","1106\n","1107\n","1108\n","1109\n","1110\n","1111\n","1112\n","1113\n","1114\n","1115\n","1116\n","1117\n","1118\n","1119\n","1120\n","1121\n","1122\n","1123\n","1124\n","1125\n","1126\n","1127\n","1128\n","1129\n","1130\n","1131\n","1132\n","1133\n","1134\n","1135\n","1136\n","1137\n","1138\n","1139\n","1140\n","1141\n","1142\n","1143\n","1144\n","1145\n","1146\n","1147\n","1148\n","1149\n","1150\n","1151\n","1152\n","1153\n","1154\n","1155\n","1156\n","1157\n","1158\n","1159\n","1160\n","1161\n","1162\n","1163\n","1164\n","1165\n","1166\n","1167\n","1168\n","1169\n","1170\n","1171\n","1172\n","1173\n","1174\n","1175\n","1176\n","1177\n","1178\n","1179\n","1180\n","1181\n","1182\n","1183\n","1184\n","1185\n","1186\n","1187\n","1188\n","1189\n","1190\n","1191\n","1192\n","1193\n","1194\n","1195\n","1196\n","1197\n","1198\n","1199\n","1200\n","1201\n","1202\n","1203\n","1204\n","1205\n","1206\n","1207\n","1208\n","1209\n","1210\n","1211\n","1212\n","1213\n","1214\n","1215\n","1216\n","1217\n","1218\n","1219\n","1220\n","1221\n","1222\n","1223\n","1224\n","1225\n","1226\n","1227\n","1228\n","1229\n","1230\n","1231\n","1232\n","1233\n","1234\n","1235\n","1236\n","1237\n","1238\n","1239\n","1240\n","1241\n","1242\n","1243\n","1244\n","1245\n","1246\n","1247\n","1248\n","1249\n","1250\n","1251\n","1252\n","1253\n","1254\n","1255\n","1256\n","1257\n","1258\n","1259\n","1260\n","1261\n","1262\n","1263\n","1264\n","1265\n","1266\n","1267\n","1268\n","1269\n","1270\n","1271\n","1272\n","1273\n","1274\n","1275\n","1276\n","1277\n","1278\n","1279\n","1280\n","1281\n","1282\n","1283\n","1284\n","1285\n","1286\n","1287\n","1288\n","1289\n","1290\n","1291\n","1292\n","1293\n","1294\n","1295\n","1296\n","1297\n","1298\n","1299\n","1300\n","1301\n","1302\n","1303\n","1304\n","1305\n","1306\n","1307\n","1308\n","1309\n","1310\n","1311\n","1312\n","1313\n","1314\n","1315\n","1316\n","1317\n","1318\n","1319\n","1320\n","1321\n","1322\n","1323\n","1324\n","1325\n","1326\n","1327\n","1328\n","1329\n","1330\n","1331\n","1332\n","1333\n","1334\n","1335\n","1336\n","1337\n","1338\n","1339\n","1340\n","1341\n","1342\n","1343\n","1344\n","1345\n","1346\n","1347\n","1348\n","1349\n","1350\n","1351\n","1352\n","1353\n","1354\n","1355\n","1356\n","1357\n","1358\n","1359\n","1360\n","1361\n","1362\n","1363\n","1364\n","1365\n","1366\n","1367\n","1368\n","1369\n","1370\n","1371\n","1372\n","1373\n","1374\n","1375\n","1376\n","1377\n","1378\n","1379\n","1380\n","1381\n","1382\n","1383\n","1384\n","1385\n","1386\n","1387\n","1388\n","1389\n","1390\n","1391\n","1392\n","1393\n","1394\n","1395\n","1396\n","1397\n","1398\n","1399\n","1400\n","1401\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q3PCxrZZw-Jm","colab_type":"code","colab":{}},"source":["temp=np.array(p)\n","np.save(\"drive/My Drive/MS_data/temp_1_new.npy\",temp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FeA9ss0M443_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPD9JxBbdTYK","colab_type":"code","outputId":"26836d5c-c193-488b-e088-3c7dcde02f14","executionInfo":{"status":"ok","timestamp":1585158373404,"user_tz":-330,"elapsed":74271,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["q=[]\n","y=[]\n","z=[]\n","a=[]\n","n=1401\n","for i in Y_2:\n","  print(n)\n","  for j in i:\n","    for k in j:\n","      #print(k)\n","      a.append(k)\n","     # print(a)\n","      z.append(a)\n","      a=[]\n","    #print(z)\n","    y.append(z)\n","    z=[]\n","  q.append(y)\n","  y=[]\n","  n+=1\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1401\n","1402\n","1403\n","1404\n","1405\n","1406\n","1407\n","1408\n","1409\n","1410\n","1411\n","1412\n","1413\n","1414\n","1415\n","1416\n","1417\n","1418\n","1419\n","1420\n","1421\n","1422\n","1423\n","1424\n","1425\n","1426\n","1427\n","1428\n","1429\n","1430\n","1431\n","1432\n","1433\n","1434\n","1435\n","1436\n","1437\n","1438\n","1439\n","1440\n","1441\n","1442\n","1443\n","1444\n","1445\n","1446\n","1447\n","1448\n","1449\n","1450\n","1451\n","1452\n","1453\n","1454\n","1455\n","1456\n","1457\n","1458\n","1459\n","1460\n","1461\n","1462\n","1463\n","1464\n","1465\n","1466\n","1467\n","1468\n","1469\n","1470\n","1471\n","1472\n","1473\n","1474\n","1475\n","1476\n","1477\n","1478\n","1479\n","1480\n","1481\n","1482\n","1483\n","1484\n","1485\n","1486\n","1487\n","1488\n","1489\n","1490\n","1491\n","1492\n","1493\n","1494\n","1495\n","1496\n","1497\n","1498\n","1499\n","1500\n","1501\n","1502\n","1503\n","1504\n","1505\n","1506\n","1507\n","1508\n","1509\n","1510\n","1511\n","1512\n","1513\n","1514\n","1515\n","1516\n","1517\n","1518\n","1519\n","1520\n","1521\n","1522\n","1523\n","1524\n","1525\n","1526\n","1527\n","1528\n","1529\n","1530\n","1531\n","1532\n","1533\n","1534\n","1535\n","1536\n","1537\n","1538\n","1539\n","1540\n","1541\n","1542\n","1543\n","1544\n","1545\n","1546\n","1547\n","1548\n","1549\n","1550\n","1551\n","1552\n","1553\n","1554\n","1555\n","1556\n","1557\n","1558\n","1559\n","1560\n","1561\n","1562\n","1563\n","1564\n","1565\n","1566\n","1567\n","1568\n","1569\n","1570\n","1571\n","1572\n","1573\n","1574\n","1575\n","1576\n","1577\n","1578\n","1579\n","1580\n","1581\n","1582\n","1583\n","1584\n","1585\n","1586\n","1587\n","1588\n","1589\n","1590\n","1591\n","1592\n","1593\n","1594\n","1595\n","1596\n","1597\n","1598\n","1599\n","1600\n","1601\n","1602\n","1603\n","1604\n","1605\n","1606\n","1607\n","1608\n","1609\n","1610\n","1611\n","1612\n","1613\n","1614\n","1615\n","1616\n","1617\n","1618\n","1619\n","1620\n","1621\n","1622\n","1623\n","1624\n","1625\n","1626\n","1627\n","1628\n","1629\n","1630\n","1631\n","1632\n","1633\n","1634\n","1635\n","1636\n","1637\n","1638\n","1639\n","1640\n","1641\n","1642\n","1643\n","1644\n","1645\n","1646\n","1647\n","1648\n","1649\n","1650\n","1651\n","1652\n","1653\n","1654\n","1655\n","1656\n","1657\n","1658\n","1659\n","1660\n","1661\n","1662\n","1663\n","1664\n","1665\n","1666\n","1667\n","1668\n","1669\n","1670\n","1671\n","1672\n","1673\n","1674\n","1675\n","1676\n","1677\n","1678\n","1679\n","1680\n","1681\n","1682\n","1683\n","1684\n","1685\n","1686\n","1687\n","1688\n","1689\n","1690\n","1691\n","1692\n","1693\n","1694\n","1695\n","1696\n","1697\n","1698\n","1699\n","1700\n","1701\n","1702\n","1703\n","1704\n","1705\n","1706\n","1707\n","1708\n","1709\n","1710\n","1711\n","1712\n","1713\n","1714\n","1715\n","1716\n","1717\n","1718\n","1719\n","1720\n","1721\n","1722\n","1723\n","1724\n","1725\n","1726\n","1727\n","1728\n","1729\n","1730\n","1731\n","1732\n","1733\n","1734\n","1735\n","1736\n","1737\n","1738\n","1739\n","1740\n","1741\n","1742\n","1743\n","1744\n","1745\n","1746\n","1747\n","1748\n","1749\n","1750\n","1751\n","1752\n","1753\n","1754\n","1755\n","1756\n","1757\n","1758\n","1759\n","1760\n","1761\n","1762\n","1763\n","1764\n","1765\n","1766\n","1767\n","1768\n","1769\n","1770\n","1771\n","1772\n","1773\n","1774\n","1775\n","1776\n","1777\n","1778\n","1779\n","1780\n","1781\n","1782\n","1783\n","1784\n","1785\n","1786\n","1787\n","1788\n","1789\n","1790\n","1791\n","1792\n","1793\n","1794\n","1795\n","1796\n","1797\n","1798\n","1799\n","1800\n","1801\n","1802\n","1803\n","1804\n","1805\n","1806\n","1807\n","1808\n","1809\n","1810\n","1811\n","1812\n","1813\n","1814\n","1815\n","1816\n","1817\n","1818\n","1819\n","1820\n","1821\n","1822\n","1823\n","1824\n","1825\n","1826\n","1827\n","1828\n","1829\n","1830\n","1831\n","1832\n","1833\n","1834\n","1835\n","1836\n","1837\n","1838\n","1839\n","1840\n","1841\n","1842\n","1843\n","1844\n","1845\n","1846\n","1847\n","1848\n","1849\n","1850\n","1851\n","1852\n","1853\n","1854\n","1855\n","1856\n","1857\n","1858\n","1859\n","1860\n","1861\n","1862\n","1863\n","1864\n","1865\n","1866\n","1867\n","1868\n","1869\n","1870\n","1871\n","1872\n","1873\n","1874\n","1875\n","1876\n","1877\n","1878\n","1879\n","1880\n","1881\n","1882\n","1883\n","1884\n","1885\n","1886\n","1887\n","1888\n","1889\n","1890\n","1891\n","1892\n","1893\n","1894\n","1895\n","1896\n","1897\n","1898\n","1899\n","1900\n","1901\n","1902\n","1903\n","1904\n","1905\n","1906\n","1907\n","1908\n","1909\n","1910\n","1911\n","1912\n","1913\n","1914\n","1915\n","1916\n","1917\n","1918\n","1919\n","1920\n","1921\n","1922\n","1923\n","1924\n","1925\n","1926\n","1927\n","1928\n","1929\n","1930\n","1931\n","1932\n","1933\n","1934\n","1935\n","1936\n","1937\n","1938\n","1939\n","1940\n","1941\n","1942\n","1943\n","1944\n","1945\n","1946\n","1947\n","1948\n","1949\n","1950\n","1951\n","1952\n","1953\n","1954\n","1955\n","1956\n","1957\n","1958\n","1959\n","1960\n","1961\n","1962\n","1963\n","1964\n","1965\n","1966\n","1967\n","1968\n","1969\n","1970\n","1971\n","1972\n","1973\n","1974\n","1975\n","1976\n","1977\n","1978\n","1979\n","1980\n","1981\n","1982\n","1983\n","1984\n","1985\n","1986\n","1987\n","1988\n","1989\n","1990\n","1991\n","1992\n","1993\n","1994\n","1995\n","1996\n","1997\n","1998\n","1999\n","2000\n","2001\n","2002\n","2003\n","2004\n","2005\n","2006\n","2007\n","2008\n","2009\n","2010\n","2011\n","2012\n","2013\n","2014\n","2015\n","2016\n","2017\n","2018\n","2019\n","2020\n","2021\n","2022\n","2023\n","2024\n","2025\n","2026\n","2027\n","2028\n","2029\n","2030\n","2031\n","2032\n","2033\n","2034\n","2035\n","2036\n","2037\n","2038\n","2039\n","2040\n","2041\n","2042\n","2043\n","2044\n","2045\n","2046\n","2047\n","2048\n","2049\n","2050\n","2051\n","2052\n","2053\n","2054\n","2055\n","2056\n","2057\n","2058\n","2059\n","2060\n","2061\n","2062\n","2063\n","2064\n","2065\n","2066\n","2067\n","2068\n","2069\n","2070\n","2071\n","2072\n","2073\n","2074\n","2075\n","2076\n","2077\n","2078\n","2079\n","2080\n","2081\n","2082\n","2083\n","2084\n","2085\n","2086\n","2087\n","2088\n","2089\n","2090\n","2091\n","2092\n","2093\n","2094\n","2095\n","2096\n","2097\n","2098\n","2099\n","2100\n","2101\n","2102\n","2103\n","2104\n","2105\n","2106\n","2107\n","2108\n","2109\n","2110\n","2111\n","2112\n","2113\n","2114\n","2115\n","2116\n","2117\n","2118\n","2119\n","2120\n","2121\n","2122\n","2123\n","2124\n","2125\n","2126\n","2127\n","2128\n","2129\n","2130\n","2131\n","2132\n","2133\n","2134\n","2135\n","2136\n","2137\n","2138\n","2139\n","2140\n","2141\n","2142\n","2143\n","2144\n","2145\n","2146\n","2147\n","2148\n","2149\n","2150\n","2151\n","2152\n","2153\n","2154\n","2155\n","2156\n","2157\n","2158\n","2159\n","2160\n","2161\n","2162\n","2163\n","2164\n","2165\n","2166\n","2167\n","2168\n","2169\n","2170\n","2171\n","2172\n","2173\n","2174\n","2175\n","2176\n","2177\n","2178\n","2179\n","2180\n","2181\n","2182\n","2183\n","2184\n","2185\n","2186\n","2187\n","2188\n","2189\n","2190\n","2191\n","2192\n","2193\n","2194\n","2195\n","2196\n","2197\n","2198\n","2199\n","2200\n","2201\n","2202\n","2203\n","2204\n","2205\n","2206\n","2207\n","2208\n","2209\n","2210\n","2211\n","2212\n","2213\n","2214\n","2215\n","2216\n","2217\n","2218\n","2219\n","2220\n","2221\n","2222\n","2223\n","2224\n","2225\n","2226\n","2227\n","2228\n","2229\n","2230\n","2231\n","2232\n","2233\n","2234\n","2235\n","2236\n","2237\n","2238\n","2239\n","2240\n","2241\n","2242\n","2243\n","2244\n","2245\n","2246\n","2247\n","2248\n","2249\n","2250\n","2251\n","2252\n","2253\n","2254\n","2255\n","2256\n","2257\n","2258\n","2259\n","2260\n","2261\n","2262\n","2263\n","2264\n","2265\n","2266\n","2267\n","2268\n","2269\n","2270\n","2271\n","2272\n","2273\n","2274\n","2275\n","2276\n","2277\n","2278\n","2279\n","2280\n","2281\n","2282\n","2283\n","2284\n","2285\n","2286\n","2287\n","2288\n","2289\n","2290\n","2291\n","2292\n","2293\n","2294\n","2295\n","2296\n","2297\n","2298\n","2299\n","2300\n","2301\n","2302\n","2303\n","2304\n","2305\n","2306\n","2307\n","2308\n","2309\n","2310\n","2311\n","2312\n","2313\n","2314\n","2315\n","2316\n","2317\n","2318\n","2319\n","2320\n","2321\n","2322\n","2323\n","2324\n","2325\n","2326\n","2327\n","2328\n","2329\n","2330\n","2331\n","2332\n","2333\n","2334\n","2335\n","2336\n","2337\n","2338\n","2339\n","2340\n","2341\n","2342\n","2343\n","2344\n","2345\n","2346\n","2347\n","2348\n","2349\n","2350\n","2351\n","2352\n","2353\n","2354\n","2355\n","2356\n","2357\n","2358\n","2359\n","2360\n","2361\n","2362\n","2363\n","2364\n","2365\n","2366\n","2367\n","2368\n","2369\n","2370\n","2371\n","2372\n","2373\n","2374\n","2375\n","2376\n","2377\n","2378\n","2379\n","2380\n","2381\n","2382\n","2383\n","2384\n","2385\n","2386\n","2387\n","2388\n","2389\n","2390\n","2391\n","2392\n","2393\n","2394\n","2395\n","2396\n","2397\n","2398\n","2399\n","2400\n","2401\n","2402\n","2403\n","2404\n","2405\n","2406\n","2407\n","2408\n","2409\n","2410\n","2411\n","2412\n","2413\n","2414\n","2415\n","2416\n","2417\n","2418\n","2419\n","2420\n","2421\n","2422\n","2423\n","2424\n","2425\n","2426\n","2427\n","2428\n","2429\n","2430\n","2431\n","2432\n","2433\n","2434\n","2435\n","2436\n","2437\n","2438\n","2439\n","2440\n","2441\n","2442\n","2443\n","2444\n","2445\n","2446\n","2447\n","2448\n","2449\n","2450\n","2451\n","2452\n","2453\n","2454\n","2455\n","2456\n","2457\n","2458\n","2459\n","2460\n","2461\n","2462\n","2463\n","2464\n","2465\n","2466\n","2467\n","2468\n","2469\n","2470\n","2471\n","2472\n","2473\n","2474\n","2475\n","2476\n","2477\n","2478\n","2479\n","2480\n","2481\n","2482\n","2483\n","2484\n","2485\n","2486\n","2487\n","2488\n","2489\n","2490\n","2491\n","2492\n","2493\n","2494\n","2495\n","2496\n","2497\n","2498\n","2499\n","2500\n","2501\n","2502\n","2503\n","2504\n","2505\n","2506\n","2507\n","2508\n","2509\n","2510\n","2511\n","2512\n","2513\n","2514\n","2515\n","2516\n","2517\n","2518\n","2519\n","2520\n","2521\n","2522\n","2523\n","2524\n","2525\n","2526\n","2527\n","2528\n","2529\n","2530\n","2531\n","2532\n","2533\n","2534\n","2535\n","2536\n","2537\n","2538\n","2539\n","2540\n","2541\n","2542\n","2543\n","2544\n","2545\n","2546\n","2547\n","2548\n","2549\n","2550\n","2551\n","2552\n","2553\n","2554\n","2555\n","2556\n","2557\n","2558\n","2559\n","2560\n","2561\n","2562\n","2563\n","2564\n","2565\n","2566\n","2567\n","2568\n","2569\n","2570\n","2571\n","2572\n","2573\n","2574\n","2575\n","2576\n","2577\n","2578\n","2579\n","2580\n","2581\n","2582\n","2583\n","2584\n","2585\n","2586\n","2587\n","2588\n","2589\n","2590\n","2591\n","2592\n","2593\n","2594\n","2595\n","2596\n","2597\n","2598\n","2599\n","2600\n","2601\n","2602\n","2603\n","2604\n","2605\n","2606\n","2607\n","2608\n","2609\n","2610\n","2611\n","2612\n","2613\n","2614\n","2615\n","2616\n","2617\n","2618\n","2619\n","2620\n","2621\n","2622\n","2623\n","2624\n","2625\n","2626\n","2627\n","2628\n","2629\n","2630\n","2631\n","2632\n","2633\n","2634\n","2635\n","2636\n","2637\n","2638\n","2639\n","2640\n","2641\n","2642\n","2643\n","2644\n","2645\n","2646\n","2647\n","2648\n","2649\n","2650\n","2651\n","2652\n","2653\n","2654\n","2655\n","2656\n","2657\n","2658\n","2659\n","2660\n","2661\n","2662\n","2663\n","2664\n","2665\n","2666\n","2667\n","2668\n","2669\n","2670\n","2671\n","2672\n","2673\n","2674\n","2675\n","2676\n","2677\n","2678\n","2679\n","2680\n","2681\n","2682\n","2683\n","2684\n","2685\n","2686\n","2687\n","2688\n","2689\n","2690\n","2691\n","2692\n","2693\n","2694\n","2695\n","2696\n","2697\n","2698\n","2699\n","2700\n","2701\n","2702\n","2703\n","2704\n","2705\n","2706\n","2707\n","2708\n","2709\n","2710\n","2711\n","2712\n","2713\n","2714\n","2715\n","2716\n","2717\n","2718\n","2719\n","2720\n","2721\n","2722\n","2723\n","2724\n","2725\n","2726\n","2727\n","2728\n","2729\n","2730\n","2731\n","2732\n","2733\n","2734\n","2735\n","2736\n","2737\n","2738\n","2739\n","2740\n","2741\n","2742\n","2743\n","2744\n","2745\n","2746\n","2747\n","2748\n","2749\n","2750\n","2751\n","2752\n","2753\n","2754\n","2755\n","2756\n","2757\n","2758\n","2759\n","2760\n","2761\n","2762\n","2763\n","2764\n","2765\n","2766\n","2767\n","2768\n","2769\n","2770\n","2771\n","2772\n","2773\n","2774\n","2775\n","2776\n","2777\n","2778\n","2779\n","2780\n","2781\n","2782\n","2783\n","2784\n","2785\n","2786\n","2787\n","2788\n","2789\n","2790\n","2791\n","2792\n","2793\n","2794\n","2795\n","2796\n","2797\n","2798\n","2799\n","2800\n","2801\n","2802\n","2803\n","2804\n","2805\n","2806\n","2807\n","2808\n","2809\n","2810\n","2811\n","2812\n","2813\n","2814\n","2815\n","2816\n","2817\n","2818\n","2819\n","2820\n","2821\n","2822\n","2823\n","2824\n","2825\n","2826\n","2827\n","2828\n","2829\n","2830\n","2831\n","2832\n","2833\n","2834\n","2835\n","2836\n","2837\n","2838\n","2839\n","2840\n","2841\n","2842\n","2843\n","2844\n","2845\n","2846\n","2847\n","2848\n","2849\n","2850\n","2851\n","2852\n","2853\n","2854\n","2855\n","2856\n","2857\n","2858\n","2859\n","2860\n","2861\n","2862\n","2863\n","2864\n","2865\n","2866\n","2867\n","2868\n","2869\n","2870\n","2871\n","2872\n","2873\n","2874\n","2875\n","2876\n","2877\n","2878\n","2879\n","2880\n","2881\n","2882\n","2883\n","2884\n","2885\n","2886\n","2887\n","2888\n","2889\n","2890\n","2891\n","2892\n","2893\n","2894\n","2895\n","2896\n","2897\n","2898\n","2899\n","2900\n","2901\n","2902\n","2903\n","2904\n","2905\n","2906\n","2907\n","2908\n","2909\n","2910\n","2911\n","2912\n","2913\n","2914\n","2915\n","2916\n","2917\n","2918\n","2919\n","2920\n","2921\n","2922\n","2923\n","2924\n","2925\n","2926\n","2927\n","2928\n","2929\n","2930\n","2931\n","2932\n","2933\n","2934\n","2935\n","2936\n","2937\n","2938\n","2939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IK28gXYhzY1Y","colab_type":"code","colab":{}},"source":["temp2=np.array(q)\n","np.save(\"drive/My Drive/MS_data/temp_2_new.npy\",temp2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vb_itkkrzpUs","colab_type":"code","colab":{}},"source":["temp=np.load(\"drive/My Drive/MS_data/temp_1_new.npy\")\n","p=list(temp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c57afBl054tk","colab_type":"code","colab":{}},"source":["temp2=np.load(\"drive/My Drive/MS_data/temp_2_new.npy\")\n","q=list(temp2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3QRbAKp48jU","colab_type":"code","outputId":"efba208a-f365-4b6f-a4eb-84cab13b312f","executionInfo":{"status":"ok","timestamp":1585160130129,"user_tz":-330,"elapsed":1289,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(np.max(temp))\n","print(np.min(temp))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.0\n","0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M3faK4nodXJn","colab_type":"code","outputId":"6a4cc1f8-f987-421a-a984-7fd066edcacf","executionInfo":{"status":"ok","timestamp":1585160134370,"user_tz":-330,"elapsed":1351,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["j=1401\n","for i in q:\n","  print(j)\n","  p.append(i)\n","  j+=1\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1401\n","1402\n","1403\n","1404\n","1405\n","1406\n","1407\n","1408\n","1409\n","1410\n","1411\n","1412\n","1413\n","1414\n","1415\n","1416\n","1417\n","1418\n","1419\n","1420\n","1421\n","1422\n","1423\n","1424\n","1425\n","1426\n","1427\n","1428\n","1429\n","1430\n","1431\n","1432\n","1433\n","1434\n","1435\n","1436\n","1437\n","1438\n","1439\n","1440\n","1441\n","1442\n","1443\n","1444\n","1445\n","1446\n","1447\n","1448\n","1449\n","1450\n","1451\n","1452\n","1453\n","1454\n","1455\n","1456\n","1457\n","1458\n","1459\n","1460\n","1461\n","1462\n","1463\n","1464\n","1465\n","1466\n","1467\n","1468\n","1469\n","1470\n","1471\n","1472\n","1473\n","1474\n","1475\n","1476\n","1477\n","1478\n","1479\n","1480\n","1481\n","1482\n","1483\n","1484\n","1485\n","1486\n","1487\n","1488\n","1489\n","1490\n","1491\n","1492\n","1493\n","1494\n","1495\n","1496\n","1497\n","1498\n","1499\n","1500\n","1501\n","1502\n","1503\n","1504\n","1505\n","1506\n","1507\n","1508\n","1509\n","1510\n","1511\n","1512\n","1513\n","1514\n","1515\n","1516\n","1517\n","1518\n","1519\n","1520\n","1521\n","1522\n","1523\n","1524\n","1525\n","1526\n","1527\n","1528\n","1529\n","1530\n","1531\n","1532\n","1533\n","1534\n","1535\n","1536\n","1537\n","1538\n","1539\n","1540\n","1541\n","1542\n","1543\n","1544\n","1545\n","1546\n","1547\n","1548\n","1549\n","1550\n","1551\n","1552\n","1553\n","1554\n","1555\n","1556\n","1557\n","1558\n","1559\n","1560\n","1561\n","1562\n","1563\n","1564\n","1565\n","1566\n","1567\n","1568\n","1569\n","1570\n","1571\n","1572\n","1573\n","1574\n","1575\n","1576\n","1577\n","1578\n","1579\n","1580\n","1581\n","1582\n","1583\n","1584\n","1585\n","1586\n","1587\n","1588\n","1589\n","1590\n","1591\n","1592\n","1593\n","1594\n","1595\n","1596\n","1597\n","1598\n","1599\n","1600\n","1601\n","1602\n","1603\n","1604\n","1605\n","1606\n","1607\n","1608\n","1609\n","1610\n","1611\n","1612\n","1613\n","1614\n","1615\n","1616\n","1617\n","1618\n","1619\n","1620\n","1621\n","1622\n","1623\n","1624\n","1625\n","1626\n","1627\n","1628\n","1629\n","1630\n","1631\n","1632\n","1633\n","1634\n","1635\n","1636\n","1637\n","1638\n","1639\n","1640\n","1641\n","1642\n","1643\n","1644\n","1645\n","1646\n","1647\n","1648\n","1649\n","1650\n","1651\n","1652\n","1653\n","1654\n","1655\n","1656\n","1657\n","1658\n","1659\n","1660\n","1661\n","1662\n","1663\n","1664\n","1665\n","1666\n","1667\n","1668\n","1669\n","1670\n","1671\n","1672\n","1673\n","1674\n","1675\n","1676\n","1677\n","1678\n","1679\n","1680\n","1681\n","1682\n","1683\n","1684\n","1685\n","1686\n","1687\n","1688\n","1689\n","1690\n","1691\n","1692\n","1693\n","1694\n","1695\n","1696\n","1697\n","1698\n","1699\n","1700\n","1701\n","1702\n","1703\n","1704\n","1705\n","1706\n","1707\n","1708\n","1709\n","1710\n","1711\n","1712\n","1713\n","1714\n","1715\n","1716\n","1717\n","1718\n","1719\n","1720\n","1721\n","1722\n","1723\n","1724\n","1725\n","1726\n","1727\n","1728\n","1729\n","1730\n","1731\n","1732\n","1733\n","1734\n","1735\n","1736\n","1737\n","1738\n","1739\n","1740\n","1741\n","1742\n","1743\n","1744\n","1745\n","1746\n","1747\n","1748\n","1749\n","1750\n","1751\n","1752\n","1753\n","1754\n","1755\n","1756\n","1757\n","1758\n","1759\n","1760\n","1761\n","1762\n","1763\n","1764\n","1765\n","1766\n","1767\n","1768\n","1769\n","1770\n","1771\n","1772\n","1773\n","1774\n","1775\n","1776\n","1777\n","1778\n","1779\n","1780\n","1781\n","1782\n","1783\n","1784\n","1785\n","1786\n","1787\n","1788\n","1789\n","1790\n","1791\n","1792\n","1793\n","1794\n","1795\n","1796\n","1797\n","1798\n","1799\n","1800\n","1801\n","1802\n","1803\n","1804\n","1805\n","1806\n","1807\n","1808\n","1809\n","1810\n","1811\n","1812\n","1813\n","1814\n","1815\n","1816\n","1817\n","1818\n","1819\n","1820\n","1821\n","1822\n","1823\n","1824\n","1825\n","1826\n","1827\n","1828\n","1829\n","1830\n","1831\n","1832\n","1833\n","1834\n","1835\n","1836\n","1837\n","1838\n","1839\n","1840\n","1841\n","1842\n","1843\n","1844\n","1845\n","1846\n","1847\n","1848\n","1849\n","1850\n","1851\n","1852\n","1853\n","1854\n","1855\n","1856\n","1857\n","1858\n","1859\n","1860\n","1861\n","1862\n","1863\n","1864\n","1865\n","1866\n","1867\n","1868\n","1869\n","1870\n","1871\n","1872\n","1873\n","1874\n","1875\n","1876\n","1877\n","1878\n","1879\n","1880\n","1881\n","1882\n","1883\n","1884\n","1885\n","1886\n","1887\n","1888\n","1889\n","1890\n","1891\n","1892\n","1893\n","1894\n","1895\n","1896\n","1897\n","1898\n","1899\n","1900\n","1901\n","1902\n","1903\n","1904\n","1905\n","1906\n","1907\n","1908\n","1909\n","1910\n","1911\n","1912\n","1913\n","1914\n","1915\n","1916\n","1917\n","1918\n","1919\n","1920\n","1921\n","1922\n","1923\n","1924\n","1925\n","1926\n","1927\n","1928\n","1929\n","1930\n","1931\n","1932\n","1933\n","1934\n","1935\n","1936\n","1937\n","1938\n","1939\n","1940\n","1941\n","1942\n","1943\n","1944\n","1945\n","1946\n","1947\n","1948\n","1949\n","1950\n","1951\n","1952\n","1953\n","1954\n","1955\n","1956\n","1957\n","1958\n","1959\n","1960\n","1961\n","1962\n","1963\n","1964\n","1965\n","1966\n","1967\n","1968\n","1969\n","1970\n","1971\n","1972\n","1973\n","1974\n","1975\n","1976\n","1977\n","1978\n","1979\n","1980\n","1981\n","1982\n","1983\n","1984\n","1985\n","1986\n","1987\n","1988\n","1989\n","1990\n","1991\n","1992\n","1993\n","1994\n","1995\n","1996\n","1997\n","1998\n","1999\n","2000\n","2001\n","2002\n","2003\n","2004\n","2005\n","2006\n","2007\n","2008\n","2009\n","2010\n","2011\n","2012\n","2013\n","2014\n","2015\n","2016\n","2017\n","2018\n","2019\n","2020\n","2021\n","2022\n","2023\n","2024\n","2025\n","2026\n","2027\n","2028\n","2029\n","2030\n","2031\n","2032\n","2033\n","2034\n","2035\n","2036\n","2037\n","2038\n","2039\n","2040\n","2041\n","2042\n","2043\n","2044\n","2045\n","2046\n","2047\n","2048\n","2049\n","2050\n","2051\n","2052\n","2053\n","2054\n","2055\n","2056\n","2057\n","2058\n","2059\n","2060\n","2061\n","2062\n","2063\n","2064\n","2065\n","2066\n","2067\n","2068\n","2069\n","2070\n","2071\n","2072\n","2073\n","2074\n","2075\n","2076\n","2077\n","2078\n","2079\n","2080\n","2081\n","2082\n","2083\n","2084\n","2085\n","2086\n","2087\n","2088\n","2089\n","2090\n","2091\n","2092\n","2093\n","2094\n","2095\n","2096\n","2097\n","2098\n","2099\n","2100\n","2101\n","2102\n","2103\n","2104\n","2105\n","2106\n","2107\n","2108\n","2109\n","2110\n","2111\n","2112\n","2113\n","2114\n","2115\n","2116\n","2117\n","2118\n","2119\n","2120\n","2121\n","2122\n","2123\n","2124\n","2125\n","2126\n","2127\n","2128\n","2129\n","2130\n","2131\n","2132\n","2133\n","2134\n","2135\n","2136\n","2137\n","2138\n","2139\n","2140\n","2141\n","2142\n","2143\n","2144\n","2145\n","2146\n","2147\n","2148\n","2149\n","2150\n","2151\n","2152\n","2153\n","2154\n","2155\n","2156\n","2157\n","2158\n","2159\n","2160\n","2161\n","2162\n","2163\n","2164\n","2165\n","2166\n","2167\n","2168\n","2169\n","2170\n","2171\n","2172\n","2173\n","2174\n","2175\n","2176\n","2177\n","2178\n","2179\n","2180\n","2181\n","2182\n","2183\n","2184\n","2185\n","2186\n","2187\n","2188\n","2189\n","2190\n","2191\n","2192\n","2193\n","2194\n","2195\n","2196\n","2197\n","2198\n","2199\n","2200\n","2201\n","2202\n","2203\n","2204\n","2205\n","2206\n","2207\n","2208\n","2209\n","2210\n","2211\n","2212\n","2213\n","2214\n","2215\n","2216\n","2217\n","2218\n","2219\n","2220\n","2221\n","2222\n","2223\n","2224\n","2225\n","2226\n","2227\n","2228\n","2229\n","2230\n","2231\n","2232\n","2233\n","2234\n","2235\n","2236\n","2237\n","2238\n","2239\n","2240\n","2241\n","2242\n","2243\n","2244\n","2245\n","2246\n","2247\n","2248\n","2249\n","2250\n","2251\n","2252\n","2253\n","2254\n","2255\n","2256\n","2257\n","2258\n","2259\n","2260\n","2261\n","2262\n","2263\n","2264\n","2265\n","2266\n","2267\n","2268\n","2269\n","2270\n","2271\n","2272\n","2273\n","2274\n","2275\n","2276\n","2277\n","2278\n","2279\n","2280\n","2281\n","2282\n","2283\n","2284\n","2285\n","2286\n","2287\n","2288\n","2289\n","2290\n","2291\n","2292\n","2293\n","2294\n","2295\n","2296\n","2297\n","2298\n","2299\n","2300\n","2301\n","2302\n","2303\n","2304\n","2305\n","2306\n","2307\n","2308\n","2309\n","2310\n","2311\n","2312\n","2313\n","2314\n","2315\n","2316\n","2317\n","2318\n","2319\n","2320\n","2321\n","2322\n","2323\n","2324\n","2325\n","2326\n","2327\n","2328\n","2329\n","2330\n","2331\n","2332\n","2333\n","2334\n","2335\n","2336\n","2337\n","2338\n","2339\n","2340\n","2341\n","2342\n","2343\n","2344\n","2345\n","2346\n","2347\n","2348\n","2349\n","2350\n","2351\n","2352\n","2353\n","2354\n","2355\n","2356\n","2357\n","2358\n","2359\n","2360\n","2361\n","2362\n","2363\n","2364\n","2365\n","2366\n","2367\n","2368\n","2369\n","2370\n","2371\n","2372\n","2373\n","2374\n","2375\n","2376\n","2377\n","2378\n","2379\n","2380\n","2381\n","2382\n","2383\n","2384\n","2385\n","2386\n","2387\n","2388\n","2389\n","2390\n","2391\n","2392\n","2393\n","2394\n","2395\n","2396\n","2397\n","2398\n","2399\n","2400\n","2401\n","2402\n","2403\n","2404\n","2405\n","2406\n","2407\n","2408\n","2409\n","2410\n","2411\n","2412\n","2413\n","2414\n","2415\n","2416\n","2417\n","2418\n","2419\n","2420\n","2421\n","2422\n","2423\n","2424\n","2425\n","2426\n","2427\n","2428\n","2429\n","2430\n","2431\n","2432\n","2433\n","2434\n","2435\n","2436\n","2437\n","2438\n","2439\n","2440\n","2441\n","2442\n","2443\n","2444\n","2445\n","2446\n","2447\n","2448\n","2449\n","2450\n","2451\n","2452\n","2453\n","2454\n","2455\n","2456\n","2457\n","2458\n","2459\n","2460\n","2461\n","2462\n","2463\n","2464\n","2465\n","2466\n","2467\n","2468\n","2469\n","2470\n","2471\n","2472\n","2473\n","2474\n","2475\n","2476\n","2477\n","2478\n","2479\n","2480\n","2481\n","2482\n","2483\n","2484\n","2485\n","2486\n","2487\n","2488\n","2489\n","2490\n","2491\n","2492\n","2493\n","2494\n","2495\n","2496\n","2497\n","2498\n","2499\n","2500\n","2501\n","2502\n","2503\n","2504\n","2505\n","2506\n","2507\n","2508\n","2509\n","2510\n","2511\n","2512\n","2513\n","2514\n","2515\n","2516\n","2517\n","2518\n","2519\n","2520\n","2521\n","2522\n","2523\n","2524\n","2525\n","2526\n","2527\n","2528\n","2529\n","2530\n","2531\n","2532\n","2533\n","2534\n","2535\n","2536\n","2537\n","2538\n","2539\n","2540\n","2541\n","2542\n","2543\n","2544\n","2545\n","2546\n","2547\n","2548\n","2549\n","2550\n","2551\n","2552\n","2553\n","2554\n","2555\n","2556\n","2557\n","2558\n","2559\n","2560\n","2561\n","2562\n","2563\n","2564\n","2565\n","2566\n","2567\n","2568\n","2569\n","2570\n","2571\n","2572\n","2573\n","2574\n","2575\n","2576\n","2577\n","2578\n","2579\n","2580\n","2581\n","2582\n","2583\n","2584\n","2585\n","2586\n","2587\n","2588\n","2589\n","2590\n","2591\n","2592\n","2593\n","2594\n","2595\n","2596\n","2597\n","2598\n","2599\n","2600\n","2601\n","2602\n","2603\n","2604\n","2605\n","2606\n","2607\n","2608\n","2609\n","2610\n","2611\n","2612\n","2613\n","2614\n","2615\n","2616\n","2617\n","2618\n","2619\n","2620\n","2621\n","2622\n","2623\n","2624\n","2625\n","2626\n","2627\n","2628\n","2629\n","2630\n","2631\n","2632\n","2633\n","2634\n","2635\n","2636\n","2637\n","2638\n","2639\n","2640\n","2641\n","2642\n","2643\n","2644\n","2645\n","2646\n","2647\n","2648\n","2649\n","2650\n","2651\n","2652\n","2653\n","2654\n","2655\n","2656\n","2657\n","2658\n","2659\n","2660\n","2661\n","2662\n","2663\n","2664\n","2665\n","2666\n","2667\n","2668\n","2669\n","2670\n","2671\n","2672\n","2673\n","2674\n","2675\n","2676\n","2677\n","2678\n","2679\n","2680\n","2681\n","2682\n","2683\n","2684\n","2685\n","2686\n","2687\n","2688\n","2689\n","2690\n","2691\n","2692\n","2693\n","2694\n","2695\n","2696\n","2697\n","2698\n","2699\n","2700\n","2701\n","2702\n","2703\n","2704\n","2705\n","2706\n","2707\n","2708\n","2709\n","2710\n","2711\n","2712\n","2713\n","2714\n","2715\n","2716\n","2717\n","2718\n","2719\n","2720\n","2721\n","2722\n","2723\n","2724\n","2725\n","2726\n","2727\n","2728\n","2729\n","2730\n","2731\n","2732\n","2733\n","2734\n","2735\n","2736\n","2737\n","2738\n","2739\n","2740\n","2741\n","2742\n","2743\n","2744\n","2745\n","2746\n","2747\n","2748\n","2749\n","2750\n","2751\n","2752\n","2753\n","2754\n","2755\n","2756\n","2757\n","2758\n","2759\n","2760\n","2761\n","2762\n","2763\n","2764\n","2765\n","2766\n","2767\n","2768\n","2769\n","2770\n","2771\n","2772\n","2773\n","2774\n","2775\n","2776\n","2777\n","2778\n","2779\n","2780\n","2781\n","2782\n","2783\n","2784\n","2785\n","2786\n","2787\n","2788\n","2789\n","2790\n","2791\n","2792\n","2793\n","2794\n","2795\n","2796\n","2797\n","2798\n","2799\n","2800\n","2801\n","2802\n","2803\n","2804\n","2805\n","2806\n","2807\n","2808\n","2809\n","2810\n","2811\n","2812\n","2813\n","2814\n","2815\n","2816\n","2817\n","2818\n","2819\n","2820\n","2821\n","2822\n","2823\n","2824\n","2825\n","2826\n","2827\n","2828\n","2829\n","2830\n","2831\n","2832\n","2833\n","2834\n","2835\n","2836\n","2837\n","2838\n","2839\n","2840\n","2841\n","2842\n","2843\n","2844\n","2845\n","2846\n","2847\n","2848\n","2849\n","2850\n","2851\n","2852\n","2853\n","2854\n","2855\n","2856\n","2857\n","2858\n","2859\n","2860\n","2861\n","2862\n","2863\n","2864\n","2865\n","2866\n","2867\n","2868\n","2869\n","2870\n","2871\n","2872\n","2873\n","2874\n","2875\n","2876\n","2877\n","2878\n","2879\n","2880\n","2881\n","2882\n","2883\n","2884\n","2885\n","2886\n","2887\n","2888\n","2889\n","2890\n","2891\n","2892\n","2893\n","2894\n","2895\n","2896\n","2897\n","2898\n","2899\n","2900\n","2901\n","2902\n","2903\n","2904\n","2905\n","2906\n","2907\n","2908\n","2909\n","2910\n","2911\n","2912\n","2913\n","2914\n","2915\n","2916\n","2917\n","2918\n","2919\n","2920\n","2921\n","2922\n","2923\n","2924\n","2925\n","2926\n","2927\n","2928\n","2929\n","2930\n","2931\n","2932\n","2933\n","2934\n","2935\n","2936\n","2937\n","2938\n","2939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xM7uQo_Bzx_f","colab_type":"code","colab":{}},"source":["np.save(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\",p)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XQxNvAh0FDy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7U8m3cso0Gj0","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","Y=np.load(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\")\n","X=np.load(\"drive/My Drive/MS_data/X_union_new.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwk4Kuis2FWG","colab_type":"code","outputId":"ca614061-8b4c-48c2-a337-d6b7c93ee5d6","executionInfo":{"status":"ok","timestamp":1585160169290,"user_tz":-330,"elapsed":1219,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(np.max(Y))\n","print(np.min(Y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.0\n","0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LliKAu1xdiq0","colab_type":"code","outputId":"06994e13-3a5b-42a8-dbb1-1f18654e5d75","executionInfo":{"status":"ok","timestamp":1585160174088,"user_tz":-330,"elapsed":2940,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","#print(X_train)\n","print(X_test)\n","print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n","#print(Y_train)\n","print(Y_test)\n","# Loding the modified U-net "],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[[[-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   ...\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]]\n","\n","  [[-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   ...\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]]\n","\n","  [[-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   ...\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]]\n","\n","  ...\n","\n","  [[-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   ...\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]]\n","\n","  [[-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   ...\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]]\n","\n","  [[-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   ...\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]\n","   [-0.10365924 -0.10786358 -0.08113487 -0.7821694  -0.6822675 ]]]\n","\n","\n"," [[[-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   ...\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]]\n","\n","  [[-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   ...\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]]\n","\n","  [[-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   ...\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]]\n","\n","  ...\n","\n","  [[-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   ...\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]]\n","\n","  [[-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   ...\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]]\n","\n","  [[-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   ...\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]\n","   [-0.20037444 -0.24523255 -0.22386745 -0.6625842  -0.6647193 ]]]\n","\n","\n"," [[[ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   ...\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]]\n","\n","  [[ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   ...\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]]\n","\n","  [[ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   ...\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]]\n","\n","  ...\n","\n","  [[ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   ...\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]]\n","\n","  [[ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   ...\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]]\n","\n","  [[ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   ...\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]\n","   [ 0.          0.          0.         -0.2247246  -0.22439095]]]\n","\n","\n"," ...\n","\n","\n"," [[[-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   ...\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]]\n","\n","  [[-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   ...\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]]\n","\n","  [[-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   ...\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]]\n","\n","  ...\n","\n","  [[-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   ...\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]]\n","\n","  [[-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   ...\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]]\n","\n","  [[-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   ...\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]\n","   [-0.0875681  -0.08114678 -0.0844168  -0.6997102  -0.6754599 ]]]\n","\n","\n"," [[[ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   ...\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]]\n","\n","  [[ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   ...\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]]\n","\n","  [[ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   ...\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]]\n","\n","  ...\n","\n","  [[ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   ...\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]]\n","\n","  [[ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   ...\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]]\n","\n","  [[ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   ...\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]\n","   [ 0.          0.          0.         -0.39520493 -0.3815758 ]]]\n","\n","\n"," [[[-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   ...\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]]\n","\n","  [[-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   ...\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]]\n","\n","  [[-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   ...\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]]\n","\n","  ...\n","\n","  [[-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   ...\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]]\n","\n","  [[-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   ...\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]]\n","\n","  [[-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   ...\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]\n","   [-0.08641064 -0.03238345 -0.07873021 -0.7422806  -0.72793293]]]]\n","+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","[[[[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  ...\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]]\n","\n","\n"," [[[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  ...\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]]\n","\n","\n"," [[[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  ...\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]]\n","\n","\n"," ...\n","\n","\n"," [[[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  ...\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]]\n","\n","\n"," [[[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  ...\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]]\n","\n","\n"," [[[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  ...\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]\n","\n","  [[0.]\n","   [0.]\n","   [0.]\n","   ...\n","   [0.]\n","   [0.]\n","   [0.]]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dqUEVTXLdkj8","colab_type":"code","outputId":"437bffbc-e6fd-41af-d110-760d83ac5dd1","executionInfo":{"status":"ok","timestamp":1585161362791,"user_tz":-330,"elapsed":1155599,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","model = model(input_shape = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('drive/My Drive/MS_data/Modified_UNet_union.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('drive/My Drive/MS_data/Modified_UNet_union.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)\n","#Loss_Graph(history)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 5) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 32) 1472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 256)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 16, 16, 512)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 32, 32, 512)  0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 768)  0           up_sampling2d[0][0]              \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 256)  1769728     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_1[0][0]            \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 64, 64, 128)  442496      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_2[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 128, 128, 64) 110656      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_3[0][0]            \n","                                                                 activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 256, 256, 32) 27680       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 256, 256, 32) 128         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 256, 256, 32) 0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 256, 256, 1)  33          activation_8[0][0]               \n","==================================================================================================\n","Total params: 3,925,633\n","Trainable params: 3,922,689\n","Non-trainable params: 2,944\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 1999 samples, validate on 500 samples\n","Epoch 1/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.1647 - acc: 0.9826 - dice_coef: 0.7626 - precision: 0.9653 - sensitivity: 0.9945 - specificity: 0.9785\n","Epoch 00001: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 30s 15ms/sample - loss: 0.1641 - acc: 0.9828 - dice_coef: 0.7639 - precision: 0.9658 - sensitivity: 0.9946 - specificity: 0.9788 - val_loss: 0.1952 - val_acc: 0.9965 - val_dice_coef: 0.7152 - val_precision: 0.9909 - val_sensitivity: 0.9939 - val_specificity: 0.9973\n","Epoch 2/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9983 - dice_coef: 0.8790 - precision: 0.9959 - sensitivity: 0.9965 - specificity: 0.9988\n","Epoch 00002: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0651 - acc: 0.9983 - dice_coef: 0.8788 - precision: 0.9958 - sensitivity: 0.9965 - specificity: 0.9988 - val_loss: 0.0829 - val_acc: 0.9974 - val_dice_coef: 0.8542 - val_precision: 0.9899 - val_sensitivity: 0.9989 - val_specificity: 0.9969\n","Epoch 3/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9989 - dice_coef: 0.9305 - precision: 0.9979 - sensitivity: 0.9971 - specificity: 0.9994\n","Epoch 00003: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0346 - acc: 0.9989 - dice_coef: 0.9302 - precision: 0.9979 - sensitivity: 0.9971 - specificity: 0.9994 - val_loss: 0.0391 - val_acc: 0.9990 - val_dice_coef: 0.9236 - val_precision: 0.9989 - val_sensitivity: 0.9967 - val_specificity: 0.9997\n","Epoch 4/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9995 - dice_coef: 0.9578 - precision: 0.9994 - sensitivity: 0.9982 - specificity: 0.9998\n","Epoch 00004: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0202 - acc: 0.9995 - dice_coef: 0.9576 - precision: 0.9994 - sensitivity: 0.9982 - specificity: 0.9998 - val_loss: 0.0244 - val_acc: 0.9994 - val_dice_coef: 0.9512 - val_precision: 0.9988 - val_sensitivity: 0.9985 - val_specificity: 0.9996\n","Epoch 5/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9997 - dice_coef: 0.9715 - precision: 0.9998 - sensitivity: 0.9987 - specificity: 0.9999\n","Epoch 00005: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0132 - acc: 0.9997 - dice_coef: 0.9717 - precision: 0.9998 - sensitivity: 0.9987 - specificity: 0.9999 - val_loss: 0.0142 - val_acc: 0.9997 - val_dice_coef: 0.9709 - val_precision: 0.9995 - val_sensitivity: 0.9990 - val_specificity: 0.9998\n","Epoch 6/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9998 - dice_coef: 0.9796 - precision: 0.9998 - sensitivity: 0.9991 - specificity: 1.0000\n","Epoch 00006: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0094 - acc: 0.9998 - dice_coef: 0.9796 - precision: 0.9999 - sensitivity: 0.9991 - specificity: 1.0000 - val_loss: 0.0090 - val_acc: 0.9997 - val_dice_coef: 0.9814 - val_precision: 0.9999 - val_sensitivity: 0.9990 - val_specificity: 1.0000\n","Epoch 7/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9998 - dice_coef: 0.9850 - precision: 0.9999 - sensitivity: 0.9993 - specificity: 1.0000\n","Epoch 00007: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0069 - acc: 0.9998 - dice_coef: 0.9851 - precision: 0.9999 - sensitivity: 0.9993 - specificity: 1.0000 - val_loss: 0.0062 - val_acc: 0.9997 - val_dice_coef: 0.9871 - val_precision: 0.9999 - val_sensitivity: 0.9989 - val_specificity: 1.0000\n","Epoch 8/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9998 - dice_coef: 0.9885 - precision: 0.9999 - sensitivity: 0.9994 - specificity: 1.0000\n","Epoch 00008: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0054 - acc: 0.9998 - dice_coef: 0.9884 - precision: 0.9999 - sensitivity: 0.9994 - specificity: 1.0000 - val_loss: 0.0052 - val_acc: 0.9998 - val_dice_coef: 0.9891 - val_precision: 1.0000 - val_sensitivity: 0.9994 - val_specificity: 1.0000\n","Epoch 9/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9999 - dice_coef: 0.9908 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000\n","Epoch 00009: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0043 - acc: 0.9999 - dice_coef: 0.9909 - precision: 0.9999 - sensitivity: 0.9995 - specificity: 1.0000 - val_loss: 0.0039 - val_acc: 0.9999 - val_dice_coef: 0.9920 - val_precision: 0.9999 - val_sensitivity: 0.9995 - val_specificity: 1.0000\n","Epoch 10/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9999 - dice_coef: 0.9924 - precision: 1.0000 - sensitivity: 0.9996 - specificity: 1.0000\n","Epoch 00010: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0035 - acc: 0.9999 - dice_coef: 0.9925 - precision: 1.0000 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 0.0031 - val_acc: 0.9999 - val_dice_coef: 0.9934 - val_precision: 0.9999 - val_sensitivity: 0.9997 - val_specificity: 1.0000\n","Epoch 11/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9999 - dice_coef: 0.9937 - precision: 1.0000 - sensitivity: 0.9996 - specificity: 1.0000\n","Epoch 00011: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0029 - acc: 0.9999 - dice_coef: 0.9937 - precision: 1.0000 - sensitivity: 0.9996 - specificity: 1.0000 - val_loss: 0.0025 - val_acc: 0.9999 - val_dice_coef: 0.9949 - val_precision: 1.0000 - val_sensitivity: 0.9995 - val_specificity: 1.0000\n","Epoch 12/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9999 - dice_coef: 0.9948 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000\n","Epoch 00012: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0024 - acc: 0.9999 - dice_coef: 0.9948 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 0.0020 - val_acc: 0.9999 - val_dice_coef: 0.9957 - val_precision: 0.9999 - val_sensitivity: 0.9997 - val_specificity: 1.0000\n","Epoch 13/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9999 - dice_coef: 0.9955 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000\n","Epoch 00013: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0021 - acc: 0.9999 - dice_coef: 0.9955 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999 - val_dice_coef: 0.9965 - val_precision: 1.0000 - val_sensitivity: 0.9996 - val_specificity: 1.0000\n","Epoch 14/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9999 - dice_coef: 0.9962 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000\n","Epoch 00014: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0018 - acc: 0.9999 - dice_coef: 0.9961 - precision: 1.0000 - sensitivity: 0.9997 - specificity: 1.0000 - val_loss: 0.0016 - val_acc: 0.9999 - val_dice_coef: 0.9967 - val_precision: 1.0000 - val_sensitivity: 0.9997 - val_specificity: 1.0000\n","Epoch 15/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9999 - dice_coef: 0.9965 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00015: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0016 - acc: 0.9999 - dice_coef: 0.9965 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 0.0014 - val_acc: 0.9999 - val_dice_coef: 0.9970 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 16/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9999 - dice_coef: 0.9970 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00016: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0014 - acc: 0.9999 - dice_coef: 0.9970 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 0.0013 - val_acc: 0.9999 - val_dice_coef: 0.9975 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 17/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000 - dice_coef: 0.9974 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00017: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0012 - acc: 1.0000 - dice_coef: 0.9974 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - val_dice_coef: 0.9976 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 18/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 1.0000 - dice_coef: 0.9977 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00018: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0011 - acc: 1.0000 - dice_coef: 0.9977 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 0.0010 - val_acc: 0.9999 - val_dice_coef: 0.9979 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 19/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000 - dice_coef: 0.9978 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00019: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0010 - acc: 1.0000 - dice_coef: 0.9978 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 9.3333e-04 - val_acc: 0.9999 - val_dice_coef: 0.9981 - val_precision: 0.9999 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 20/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 9.0507e-04 - acc: 1.0000 - dice_coef: 0.9981 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00020: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 9.0610e-04 - acc: 1.0000 - dice_coef: 0.9981 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 8.0532e-04 - val_acc: 0.9999 - val_dice_coef: 0.9984 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 21/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 8.2680e-04 - acc: 1.0000 - dice_coef: 0.9982 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00021: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 8.2859e-04 - acc: 1.0000 - dice_coef: 0.9982 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 7.3884e-04 - val_acc: 1.0000 - val_dice_coef: 0.9985 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 22/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 7.3748e-04 - acc: 1.0000 - dice_coef: 0.9984 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00022: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 7.3730e-04 - acc: 1.0000 - dice_coef: 0.9984 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 7.1160e-04 - val_acc: 1.0000 - val_dice_coef: 0.9986 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 23/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 6.8846e-04 - acc: 1.0000 - dice_coef: 0.9986 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00023: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 6.8705e-04 - acc: 1.0000 - dice_coef: 0.9986 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 6.5474e-04 - val_acc: 1.0000 - val_dice_coef: 0.9987 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 24/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 7.3556e-04 - acc: 0.9999 - dice_coef: 0.9985 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00024: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 7.3418e-04 - acc: 0.9999 - dice_coef: 0.9985 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 6.1598e-04 - val_acc: 0.9999 - val_dice_coef: 0.9989 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 25/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 6.0868e-04 - acc: 1.0000 - dice_coef: 0.9987 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00025: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 6.0797e-04 - acc: 1.0000 - dice_coef: 0.9987 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 5.6343e-04 - val_acc: 1.0000 - val_dice_coef: 0.9989 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 26/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 5.5323e-04 - acc: 1.0000 - dice_coef: 0.9988 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00026: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 5.5190e-04 - acc: 1.0000 - dice_coef: 0.9988 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 5.2521e-04 - val_acc: 1.0000 - val_dice_coef: 0.9990 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 27/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 4.9373e-04 - acc: 1.0000 - dice_coef: 0.9990 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00027: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 4.9414e-04 - acc: 1.0000 - dice_coef: 0.9990 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 4.8163e-04 - val_acc: 1.0000 - val_dice_coef: 0.9991 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 28/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 4.6310e-04 - acc: 1.0000 - dice_coef: 0.9990 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00028: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 4.6238e-04 - acc: 1.0000 - dice_coef: 0.9990 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 4.9597e-04 - val_acc: 0.9999 - val_dice_coef: 0.9992 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 29/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 4.3378e-04 - acc: 1.0000 - dice_coef: 0.9991 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00029: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 4.3265e-04 - acc: 1.0000 - dice_coef: 0.9991 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 4.6081e-04 - val_acc: 1.0000 - val_dice_coef: 0.9992 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 30/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 4.1312e-04 - acc: 1.0000 - dice_coef: 0.9992 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00030: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 4.1240e-04 - acc: 1.0000 - dice_coef: 0.9992 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 4.1299e-04 - val_acc: 1.0000 - val_dice_coef: 0.9993 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 31/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 3.7555e-04 - acc: 1.0000 - dice_coef: 0.9992 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00031: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 3.7633e-04 - acc: 1.0000 - dice_coef: 0.9992 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 3.8428e-04 - val_acc: 1.0000 - val_dice_coef: 0.9993 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 32/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 3.5185e-04 - acc: 1.0000 - dice_coef: 0.9993 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00032: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 3.5168e-04 - acc: 1.0000 - dice_coef: 0.9993 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 3.7197e-04 - val_acc: 1.0000 - val_dice_coef: 0.9993 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 33/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 3.3862e-04 - acc: 1.0000 - dice_coef: 0.9993 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00033: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 3.3810e-04 - acc: 1.0000 - dice_coef: 0.9993 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 3.4700e-04 - val_acc: 1.0000 - val_dice_coef: 0.9994 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 34/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 3.2840e-04 - acc: 1.0000 - dice_coef: 0.9993 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00034: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 3.2789e-04 - acc: 1.0000 - dice_coef: 0.9993 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 3.2493e-04 - val_acc: 1.0000 - val_dice_coef: 0.9994 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 35/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 3.1786e-04 - acc: 1.0000 - dice_coef: 0.9994 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00035: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 3.1792e-04 - acc: 1.0000 - dice_coef: 0.9994 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 3.0333e-04 - val_acc: 1.0000 - val_dice_coef: 0.9995 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 36/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 3.1029e-04 - acc: 1.0000 - dice_coef: 0.9994 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00036: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 3.0991e-04 - acc: 1.0000 - dice_coef: 0.9994 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 4.8072e-04 - val_acc: 0.9999 - val_dice_coef: 0.9992 - val_precision: 0.9998 - val_sensitivity: 0.9999 - val_specificity: 0.9999\n","Epoch 37/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 3.1183e-04 - acc: 1.0000 - dice_coef: 0.9994 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00037: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 3.1229e-04 - acc: 1.0000 - dice_coef: 0.9994 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 3.7336e-04 - val_acc: 1.0000 - val_dice_coef: 0.9994 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 38/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 2.8557e-04 - acc: 1.0000 - dice_coef: 0.9995 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00038: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 2.8574e-04 - acc: 1.0000 - dice_coef: 0.9995 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 3.4626e-04 - val_acc: 0.9999 - val_dice_coef: 0.9996 - val_precision: 1.0000 - val_sensitivity: 0.9997 - val_specificity: 1.0000\n","Epoch 39/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 2.5593e-04 - acc: 1.0000 - dice_coef: 0.9995 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00039: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 2.5525e-04 - acc: 1.0000 - dice_coef: 0.9995 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.6977e-04 - val_acc: 1.0000 - val_dice_coef: 0.9996 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 40/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 2.2704e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00040: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 2.2728e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.7081e-04 - val_acc: 1.0000 - val_dice_coef: 0.9996 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 41/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 2.1958e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00041: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 2.1999e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.5690e-04 - val_acc: 1.0000 - val_dice_coef: 0.9996 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 42/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 2.0913e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00042: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 2.1182e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 3.1057e-04 - val_acc: 1.0000 - val_dice_coef: 0.9995 - val_precision: 0.9999 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 43/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 2.1442e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00043: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 2.1530e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.8563e-04 - val_acc: 1.0000 - val_dice_coef: 0.9996 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 44/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 2.1699e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00044: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 2.1741e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.8559e-04 - val_acc: 1.0000 - val_dice_coef: 0.9995 - val_precision: 0.9999 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 45/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 2.9284e-04 - acc: 1.0000 - dice_coef: 0.9995 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000\n","Epoch 00045: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 2.9163e-04 - acc: 1.0000 - dice_coef: 0.9995 - precision: 1.0000 - sensitivity: 0.9998 - specificity: 1.0000 - val_loss: 2.6086e-04 - val_acc: 0.9999 - val_dice_coef: 0.9997 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 46/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.8743e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00046: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 20s 10ms/sample - loss: 1.8719e-04 - acc: 1.0000 - dice_coef: 0.9996 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.0136e-04 - val_acc: 1.0000 - val_dice_coef: 0.9997 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 47/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.6767e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00047: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.6734e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.1080e-04 - val_acc: 1.0000 - val_dice_coef: 0.9997 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 48/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.6798e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00048: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.6840e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 1.9406e-04 - val_acc: 1.0000 - val_dice_coef: 0.9997 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 49/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.5752e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00049: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 21s 11ms/sample - loss: 1.5707e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 1.8562e-04 - val_acc: 1.0000 - val_dice_coef: 0.9997 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 50/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.4357e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00050: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.4345e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 1.6734e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 51/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.4156e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00051: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.4168e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.2256e-04 - val_acc: 1.0000 - val_dice_coef: 0.9997 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 52/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.3921e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00052: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.3906e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.4168e-04 - val_acc: 1.0000 - val_dice_coef: 0.9997 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 53/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.4237e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00053: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.4225e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 1.5394e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 54/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.7276e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00054: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.7275e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 2.3108e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9998 - val_specificity: 1.0000\n","Epoch 55/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.4585e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00055: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.4561e-04 - acc: 1.0000 - dice_coef: 0.9997 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 1.6997e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 56/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.1978e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00056: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.1955e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 1.6306e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 57/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.1522e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","Epoch 00057: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.1522e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000 - val_loss: 1.4237e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 58/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.0941e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 1.0000 - specificity: 1.0000\n","Epoch 00058: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.0956e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 1.0000 - specificity: 1.0000 - val_loss: 1.3507e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 59/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.0279e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 1.0000 - specificity: 1.0000\n","Epoch 00059: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.0321e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 1.0000 - specificity: 1.0000 - val_loss: 1.2800e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","Epoch 60/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 1.0461e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 1.0000 - specificity: 1.0000\n","Epoch 00060: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 1.0429e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 1.0000 - specificity: 1.0000 - val_loss: 1.3634e-04 - val_acc: 1.0000 - val_dice_coef: 0.9998 - val_precision: 1.0000 - val_sensitivity: 0.9999 - val_specificity: 1.0000\n","2499/2499 [==============================] - 8s 3ms/sample - loss: 1.0391e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n","441/441 [==============================] - 2s 4ms/sample - loss: 1.2379e-04 - acc: 1.0000 - dice_coef: 0.9998 - precision: 1.0000 - sensitivity: 0.9999 - specificity: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.0001237945782572143,\n"," 0.9999776,\n"," 0.99982345,\n"," 0.9999937,\n"," 0.99990654,\n"," 0.99999815]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"wQ1AUhwYFcuL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dVsdKbesHf4n","colab_type":"text"},"source":["# **INTERSECTION CODE RESULTS**"]},{"cell_type":"code","metadata":{"id":"EevGbt19Hchz","colab_type":"code","outputId":"39ae82bf-6a68-45f5-eda6-5709abe8ba35","executionInfo":{"status":"ok","timestamp":1585164855194,"user_tz":-330,"elapsed":7496,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import nibabel as nib\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","    \n","def modality(Path,index):\n","    X = []\n","    p=os.listdir(Path) \n","\n","    for i in p[:14]:                                                                      # Loading all the folders in the given path\n","        q = os.listdir(os.path.join(Path,i))     \n","\n","        x = nib.load(os.path.join(Path,i,q[index]))         \n","        f = x.get_fdata()\n","        f = np.asarray(f,'float32')\n","        \n","        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n","            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n","            if(index not in [3,4,5,6,7,8,9] and np.sum(_slice) != 0 ):  \n","                print(\"DONE\")                                         # To check whether the slice is null or not\n","              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n","                _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n","            elif(index in [3,4,5,6,7,8,9]):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n","                _slice = np.array(_slice)\n","                _slice[_slice > 0] = 1.0\n","                _slice[_slice < 0] = 0.0\n","            _slice = _slice.T\n","            _slice = _slice[:,:,np.newaxis]\n","            X.append(_slice)\n","   # X=np.array(X,dtype='float32')\n","    return X"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ORmdqumpIKBw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5f635ab0-7bde-43c7-a05d-dceea085dbf1","executionInfo":{"status":"ok","timestamp":1585205786532,"user_tz":-330,"elapsed":2692,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["from keras import backend as K\n","import numpy as np\n","import tensorflow as tf\n","\n","# Computing Dice_Coefficient\n","def dice_coef(y_true, y_pred, smooth=1.0):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","# Computing Precision \n","def precision(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","# Computing Sensitivity      \n","def sensitivity(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    return true_positives / (possible_positives + K.epsilon())\n","\n","# Computing Specificity\n","def specificity(y_true, y_pred):\n","    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n","    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n","    return true_negatives / (possible_negatives + K.epsilon())"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0A-rOBujIWXy","colab_type":"code","colab":{}},"source":["def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual): \n","     \n","    X=[]\n","    Y=[]\n","    \n","    for i in range(len(X_Dp)):        \n","        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n","        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n","            X.append(final_slice)\n","            Y.append(Y_Manual[i])\n"," \n","#   Converting the list into array  \n","    X=np.array(X,dtype='float32')\n","    Y=np.array(Y,dtype='float32')\n","    \n","    return X,Y\n","\n","\n","#   To store the data in num"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0FZXCR9tIZSa","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","import keras\n","from keras.models import Model, load_model\n","from keras.layers import Input ,BatchNormalization , Activation \n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.merge import concatenate\n","\n","\n","def Convolution(input_tensor,filters):\n","    \n","    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x) \n","    return x\n","\n","def model(input_shape):\n","    \n","    inputs = Input((input_shape))\n","    \n","    conv_1 = Convolution(inputs,32)\n","    \n","    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n","    \n","    conv_2 = Convolution(maxp_1,64)\n","    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n","    \n","    conv_3 = Convolution(maxp_2,128)\n","    \n","    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n","    \n","    conv_4 = Convolution(maxp_3,256)\n","    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n","    \n","    conv_5 = Convolution(maxp_4,512)\n","   \n","    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n","\n","    upsample_6 = concatenate([upsample_6, conv_4])\n","    \n","    conv_6 = Convolution(upsample_6,256)\n","    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n","    \n","    upsample_7 = concatenate([upsample_7, conv_3])\n","    \n","    conv_7 = Convolution(upsample_7,128)\n","    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n","    \n","    upsample_8 = concatenate([upsample_8, conv_2])\n","\n","    conv_8 = Convolution(upsample_8,64)\n","    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n","    \n","    upsample_9 = concatenate([upsample_9, conv_1])\n","    \n","    conv_9 = Convolution(upsample_9,32)\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n","    \n","    model = Model(inputs=[inputs], outputs=[outputs]) \n","    \n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThKjVBPWIfhy","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","Y_1  =   modality(Path,3)\n","Y_2  =   modality(Path,4)\n","Y_3  =   modality(Path,5)\n","Y_4  =   modality(Path,6)\n","Y_5  =   modality(Path,7)\n","Y_6  =   modality(Path,8)\n","Y_7  =   modality(Path,9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QcDoSgI0KWFX","colab_type":"code","colab":{}},"source":["import math\n","def intersection(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7):\n","  Y=[]\n","  sum2=[]\n","  flag=0\n","  #y=np.array()\n","  print(\"A\")\n","  for i in range (len(Y_1)):\n","    #print(Y_1[i])\n","    \n","        f=np.concatenate((Y_1[i],Y_2[i],Y_3[i],Y_4[i],Y_5[i],Y_6[i],Y_7[i]),axis=-1)\n","        sum=np.sum(f,axis=2)\n","       # print(sum)\n","        \n","          #print(j)\n","        sum_1=np.divide(sum,7)\n","        sum_1=np.floor(sum_1)\n","        sum2.append(sum_1)\n","\n","    #sum2=np.array(sum2,dtype='float32')\n","    \n","        \n","  return sum2\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNox6yN6IlPR","colab_type":"code","outputId":"81b9cabb-3e6e-4d9f-ff69-1a95fec6c2cd","executionInfo":{"status":"ok","timestamp":1585164677703,"user_tz":-330,"elapsed":12447,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["Y_Manual=intersection(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7)\n","\n","\n","print(len(Y_Manual))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A\n","5184\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2B2oQciEI17I","colab_type":"code","colab":{}},"source":["Y=np.array(Y_Manual,dtype='float32')\n","np.save(\"drive/My Drive/MS_data/Y_manual_intersection.npy\",Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iORvk1zRL5Q_","colab_type":"code","colab":{}},"source":["Y=np.load(\"drive/My Drive/MS_data/Y_manual_intersection.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5OGRrNHI5cX","colab_type":"code","outputId":"50bd103c-9c75-4216-db0e-b73668e1aea7","executionInfo":{"status":"ok","timestamp":1585164963208,"user_tz":-330,"elapsed":36670,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["Path='drive/My Drive/Pre-processed'\n","X_Dp_t      =   modality(Path,0)\n","X_Flair_t   =   modality(Path,1)\n","X_Gado_t    =   modality(Path,2)\n","X_T1_t      =   modality(Path,10)\n","X_T2_t      =   modality(Path,11)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n","DONE\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oam2Z-PUM3L_","colab_type":"code","colab":{}},"source":["Y_Manual=list(Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rVlgnZRLi6_","colab_type":"code","colab":{}},"source":["X, Y = remove_null_samples(X_Dp_t, X_Flair_t, X_Gado_t, X_T1_t, X_T2_t, Y_Manual)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_xBXXsNI7O4","colab_type":"code","colab":{}},"source":["def store_data(X,Y):\n","    np.save(\"drive/My Drive/MS_data/X_intersection.npy\",X)\n","    np.save(\"drive/My Drive/MS_data/Y_intersection.npy\",Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQ83btm0I-rg","colab_type":"code","outputId":"66227080-425f-4b61-dc64-1ca50795a1c6","executionInfo":{"status":"ok","timestamp":1585165207246,"user_tz":-330,"elapsed":89963,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(Y))\n","store_data(X,Y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2940\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PPSNjlw3I_6B","colab_type":"code","colab":{}},"source":["import numpy as np\n","#X=np.load(\"drive/My Drive/MS_data/X_intersection.npy\")\n","Y=np.load(\"drive/My Drive/MS_data/Y_intersection.npy\")\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GP0GWSy3JCcg","colab_type":"code","colab":{}},"source":["Y_1=Y[:1401]\n","Y_2=Y[1401:]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S1DhGifDJEun","colab_type":"code","outputId":"1b0365d5-c51a-4a0a-8c4e-276b2bfe475e","executionInfo":{"status":"ok","timestamp":1585165296518,"user_tz":-330,"elapsed":65124,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["p=[]\n","y=[]\n","z=[]\n","a=[]\n","n=1\n","for i in Y_1:\n","  print(n)\n","  for j in i:\n","    for k in j:\n","      #print(k)\n","      a.append(k)\n","     # print(a)\n","      z.append(a)\n","      a=[]\n","    #print(z)\n","    y.append(z)\n","    z=[]\n","  p.append(y)\n","  y=[]\n","  n+=1\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","511\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n","540\n","541\n","542\n","543\n","544\n","545\n","546\n","547\n","548\n","549\n","550\n","551\n","552\n","553\n","554\n","555\n","556\n","557\n","558\n","559\n","560\n","561\n","562\n","563\n","564\n","565\n","566\n","567\n","568\n","569\n","570\n","571\n","572\n","573\n","574\n","575\n","576\n","577\n","578\n","579\n","580\n","581\n","582\n","583\n","584\n","585\n","586\n","587\n","588\n","589\n","590\n","591\n","592\n","593\n","594\n","595\n","596\n","597\n","598\n","599\n","600\n","601\n","602\n","603\n","604\n","605\n","606\n","607\n","608\n","609\n","610\n","611\n","612\n","613\n","614\n","615\n","616\n","617\n","618\n","619\n","620\n","621\n","622\n","623\n","624\n","625\n","626\n","627\n","628\n","629\n","630\n","631\n","632\n","633\n","634\n","635\n","636\n","637\n","638\n","639\n","640\n","641\n","642\n","643\n","644\n","645\n","646\n","647\n","648\n","649\n","650\n","651\n","652\n","653\n","654\n","655\n","656\n","657\n","658\n","659\n","660\n","661\n","662\n","663\n","664\n","665\n","666\n","667\n","668\n","669\n","670\n","671\n","672\n","673\n","674\n","675\n","676\n","677\n","678\n","679\n","680\n","681\n","682\n","683\n","684\n","685\n","686\n","687\n","688\n","689\n","690\n","691\n","692\n","693\n","694\n","695\n","696\n","697\n","698\n","699\n","700\n","701\n","702\n","703\n","704\n","705\n","706\n","707\n","708\n","709\n","710\n","711\n","712\n","713\n","714\n","715\n","716\n","717\n","718\n","719\n","720\n","721\n","722\n","723\n","724\n","725\n","726\n","727\n","728\n","729\n","730\n","731\n","732\n","733\n","734\n","735\n","736\n","737\n","738\n","739\n","740\n","741\n","742\n","743\n","744\n","745\n","746\n","747\n","748\n","749\n","750\n","751\n","752\n","753\n","754\n","755\n","756\n","757\n","758\n","759\n","760\n","761\n","762\n","763\n","764\n","765\n","766\n","767\n","768\n","769\n","770\n","771\n","772\n","773\n","774\n","775\n","776\n","777\n","778\n","779\n","780\n","781\n","782\n","783\n","784\n","785\n","786\n","787\n","788\n","789\n","790\n","791\n","792\n","793\n","794\n","795\n","796\n","797\n","798\n","799\n","800\n","801\n","802\n","803\n","804\n","805\n","806\n","807\n","808\n","809\n","810\n","811\n","812\n","813\n","814\n","815\n","816\n","817\n","818\n","819\n","820\n","821\n","822\n","823\n","824\n","825\n","826\n","827\n","828\n","829\n","830\n","831\n","832\n","833\n","834\n","835\n","836\n","837\n","838\n","839\n","840\n","841\n","842\n","843\n","844\n","845\n","846\n","847\n","848\n","849\n","850\n","851\n","852\n","853\n","854\n","855\n","856\n","857\n","858\n","859\n","860\n","861\n","862\n","863\n","864\n","865\n","866\n","867\n","868\n","869\n","870\n","871\n","872\n","873\n","874\n","875\n","876\n","877\n","878\n","879\n","880\n","881\n","882\n","883\n","884\n","885\n","886\n","887\n","888\n","889\n","890\n","891\n","892\n","893\n","894\n","895\n","896\n","897\n","898\n","899\n","900\n","901\n","902\n","903\n","904\n","905\n","906\n","907\n","908\n","909\n","910\n","911\n","912\n","913\n","914\n","915\n","916\n","917\n","918\n","919\n","920\n","921\n","922\n","923\n","924\n","925\n","926\n","927\n","928\n","929\n","930\n","931\n","932\n","933\n","934\n","935\n","936\n","937\n","938\n","939\n","940\n","941\n","942\n","943\n","944\n","945\n","946\n","947\n","948\n","949\n","950\n","951\n","952\n","953\n","954\n","955\n","956\n","957\n","958\n","959\n","960\n","961\n","962\n","963\n","964\n","965\n","966\n","967\n","968\n","969\n","970\n","971\n","972\n","973\n","974\n","975\n","976\n","977\n","978\n","979\n","980\n","981\n","982\n","983\n","984\n","985\n","986\n","987\n","988\n","989\n","990\n","991\n","992\n","993\n","994\n","995\n","996\n","997\n","998\n","999\n","1000\n","1001\n","1002\n","1003\n","1004\n","1005\n","1006\n","1007\n","1008\n","1009\n","1010\n","1011\n","1012\n","1013\n","1014\n","1015\n","1016\n","1017\n","1018\n","1019\n","1020\n","1021\n","1022\n","1023\n","1024\n","1025\n","1026\n","1027\n","1028\n","1029\n","1030\n","1031\n","1032\n","1033\n","1034\n","1035\n","1036\n","1037\n","1038\n","1039\n","1040\n","1041\n","1042\n","1043\n","1044\n","1045\n","1046\n","1047\n","1048\n","1049\n","1050\n","1051\n","1052\n","1053\n","1054\n","1055\n","1056\n","1057\n","1058\n","1059\n","1060\n","1061\n","1062\n","1063\n","1064\n","1065\n","1066\n","1067\n","1068\n","1069\n","1070\n","1071\n","1072\n","1073\n","1074\n","1075\n","1076\n","1077\n","1078\n","1079\n","1080\n","1081\n","1082\n","1083\n","1084\n","1085\n","1086\n","1087\n","1088\n","1089\n","1090\n","1091\n","1092\n","1093\n","1094\n","1095\n","1096\n","1097\n","1098\n","1099\n","1100\n","1101\n","1102\n","1103\n","1104\n","1105\n","1106\n","1107\n","1108\n","1109\n","1110\n","1111\n","1112\n","1113\n","1114\n","1115\n","1116\n","1117\n","1118\n","1119\n","1120\n","1121\n","1122\n","1123\n","1124\n","1125\n","1126\n","1127\n","1128\n","1129\n","1130\n","1131\n","1132\n","1133\n","1134\n","1135\n","1136\n","1137\n","1138\n","1139\n","1140\n","1141\n","1142\n","1143\n","1144\n","1145\n","1146\n","1147\n","1148\n","1149\n","1150\n","1151\n","1152\n","1153\n","1154\n","1155\n","1156\n","1157\n","1158\n","1159\n","1160\n","1161\n","1162\n","1163\n","1164\n","1165\n","1166\n","1167\n","1168\n","1169\n","1170\n","1171\n","1172\n","1173\n","1174\n","1175\n","1176\n","1177\n","1178\n","1179\n","1180\n","1181\n","1182\n","1183\n","1184\n","1185\n","1186\n","1187\n","1188\n","1189\n","1190\n","1191\n","1192\n","1193\n","1194\n","1195\n","1196\n","1197\n","1198\n","1199\n","1200\n","1201\n","1202\n","1203\n","1204\n","1205\n","1206\n","1207\n","1208\n","1209\n","1210\n","1211\n","1212\n","1213\n","1214\n","1215\n","1216\n","1217\n","1218\n","1219\n","1220\n","1221\n","1222\n","1223\n","1224\n","1225\n","1226\n","1227\n","1228\n","1229\n","1230\n","1231\n","1232\n","1233\n","1234\n","1235\n","1236\n","1237\n","1238\n","1239\n","1240\n","1241\n","1242\n","1243\n","1244\n","1245\n","1246\n","1247\n","1248\n","1249\n","1250\n","1251\n","1252\n","1253\n","1254\n","1255\n","1256\n","1257\n","1258\n","1259\n","1260\n","1261\n","1262\n","1263\n","1264\n","1265\n","1266\n","1267\n","1268\n","1269\n","1270\n","1271\n","1272\n","1273\n","1274\n","1275\n","1276\n","1277\n","1278\n","1279\n","1280\n","1281\n","1282\n","1283\n","1284\n","1285\n","1286\n","1287\n","1288\n","1289\n","1290\n","1291\n","1292\n","1293\n","1294\n","1295\n","1296\n","1297\n","1298\n","1299\n","1300\n","1301\n","1302\n","1303\n","1304\n","1305\n","1306\n","1307\n","1308\n","1309\n","1310\n","1311\n","1312\n","1313\n","1314\n","1315\n","1316\n","1317\n","1318\n","1319\n","1320\n","1321\n","1322\n","1323\n","1324\n","1325\n","1326\n","1327\n","1328\n","1329\n","1330\n","1331\n","1332\n","1333\n","1334\n","1335\n","1336\n","1337\n","1338\n","1339\n","1340\n","1341\n","1342\n","1343\n","1344\n","1345\n","1346\n","1347\n","1348\n","1349\n","1350\n","1351\n","1352\n","1353\n","1354\n","1355\n","1356\n","1357\n","1358\n","1359\n","1360\n","1361\n","1362\n","1363\n","1364\n","1365\n","1366\n","1367\n","1368\n","1369\n","1370\n","1371\n","1372\n","1373\n","1374\n","1375\n","1376\n","1377\n","1378\n","1379\n","1380\n","1381\n","1382\n","1383\n","1384\n","1385\n","1386\n","1387\n","1388\n","1389\n","1390\n","1391\n","1392\n","1393\n","1394\n","1395\n","1396\n","1397\n","1398\n","1399\n","1400\n","1401\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bah92b_9JGfl","colab_type":"code","colab":{}},"source":["temp=np.array(p)\n","np.save(\"drive/My Drive/MS_data/temp_1_in.npy\",temp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMpaMI3MJH6B","colab_type":"code","outputId":"8d844d0d-48cf-4004-bcce-7cfbac35987f","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1585205252352,"user_tz":-330,"elapsed":76035,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["q=[]\n","y=[]\n","z=[]\n","a=[]\n","n=1401\n","for i in Y_2:\n","  print(n)\n","  for j in i:\n","    for k in j:\n","      #print(k)\n","      a.append(k)\n","     # print(a)\n","      z.append(a)\n","      a=[]\n","    #print(z)\n","    y.append(z)\n","    z=[]\n","  q.append(y)\n","  y=[]\n","  n+=1"],"execution_count":4,"outputs":[{"output_type":"stream","text":["1401\n","1402\n","1403\n","1404\n","1405\n","1406\n","1407\n","1408\n","1409\n","1410\n","1411\n","1412\n","1413\n","1414\n","1415\n","1416\n","1417\n","1418\n","1419\n","1420\n","1421\n","1422\n","1423\n","1424\n","1425\n","1426\n","1427\n","1428\n","1429\n","1430\n","1431\n","1432\n","1433\n","1434\n","1435\n","1436\n","1437\n","1438\n","1439\n","1440\n","1441\n","1442\n","1443\n","1444\n","1445\n","1446\n","1447\n","1448\n","1449\n","1450\n","1451\n","1452\n","1453\n","1454\n","1455\n","1456\n","1457\n","1458\n","1459\n","1460\n","1461\n","1462\n","1463\n","1464\n","1465\n","1466\n","1467\n","1468\n","1469\n","1470\n","1471\n","1472\n","1473\n","1474\n","1475\n","1476\n","1477\n","1478\n","1479\n","1480\n","1481\n","1482\n","1483\n","1484\n","1485\n","1486\n","1487\n","1488\n","1489\n","1490\n","1491\n","1492\n","1493\n","1494\n","1495\n","1496\n","1497\n","1498\n","1499\n","1500\n","1501\n","1502\n","1503\n","1504\n","1505\n","1506\n","1507\n","1508\n","1509\n","1510\n","1511\n","1512\n","1513\n","1514\n","1515\n","1516\n","1517\n","1518\n","1519\n","1520\n","1521\n","1522\n","1523\n","1524\n","1525\n","1526\n","1527\n","1528\n","1529\n","1530\n","1531\n","1532\n","1533\n","1534\n","1535\n","1536\n","1537\n","1538\n","1539\n","1540\n","1541\n","1542\n","1543\n","1544\n","1545\n","1546\n","1547\n","1548\n","1549\n","1550\n","1551\n","1552\n","1553\n","1554\n","1555\n","1556\n","1557\n","1558\n","1559\n","1560\n","1561\n","1562\n","1563\n","1564\n","1565\n","1566\n","1567\n","1568\n","1569\n","1570\n","1571\n","1572\n","1573\n","1574\n","1575\n","1576\n","1577\n","1578\n","1579\n","1580\n","1581\n","1582\n","1583\n","1584\n","1585\n","1586\n","1587\n","1588\n","1589\n","1590\n","1591\n","1592\n","1593\n","1594\n","1595\n","1596\n","1597\n","1598\n","1599\n","1600\n","1601\n","1602\n","1603\n","1604\n","1605\n","1606\n","1607\n","1608\n","1609\n","1610\n","1611\n","1612\n","1613\n","1614\n","1615\n","1616\n","1617\n","1618\n","1619\n","1620\n","1621\n","1622\n","1623\n","1624\n","1625\n","1626\n","1627\n","1628\n","1629\n","1630\n","1631\n","1632\n","1633\n","1634\n","1635\n","1636\n","1637\n","1638\n","1639\n","1640\n","1641\n","1642\n","1643\n","1644\n","1645\n","1646\n","1647\n","1648\n","1649\n","1650\n","1651\n","1652\n","1653\n","1654\n","1655\n","1656\n","1657\n","1658\n","1659\n","1660\n","1661\n","1662\n","1663\n","1664\n","1665\n","1666\n","1667\n","1668\n","1669\n","1670\n","1671\n","1672\n","1673\n","1674\n","1675\n","1676\n","1677\n","1678\n","1679\n","1680\n","1681\n","1682\n","1683\n","1684\n","1685\n","1686\n","1687\n","1688\n","1689\n","1690\n","1691\n","1692\n","1693\n","1694\n","1695\n","1696\n","1697\n","1698\n","1699\n","1700\n","1701\n","1702\n","1703\n","1704\n","1705\n","1706\n","1707\n","1708\n","1709\n","1710\n","1711\n","1712\n","1713\n","1714\n","1715\n","1716\n","1717\n","1718\n","1719\n","1720\n","1721\n","1722\n","1723\n","1724\n","1725\n","1726\n","1727\n","1728\n","1729\n","1730\n","1731\n","1732\n","1733\n","1734\n","1735\n","1736\n","1737\n","1738\n","1739\n","1740\n","1741\n","1742\n","1743\n","1744\n","1745\n","1746\n","1747\n","1748\n","1749\n","1750\n","1751\n","1752\n","1753\n","1754\n","1755\n","1756\n","1757\n","1758\n","1759\n","1760\n","1761\n","1762\n","1763\n","1764\n","1765\n","1766\n","1767\n","1768\n","1769\n","1770\n","1771\n","1772\n","1773\n","1774\n","1775\n","1776\n","1777\n","1778\n","1779\n","1780\n","1781\n","1782\n","1783\n","1784\n","1785\n","1786\n","1787\n","1788\n","1789\n","1790\n","1791\n","1792\n","1793\n","1794\n","1795\n","1796\n","1797\n","1798\n","1799\n","1800\n","1801\n","1802\n","1803\n","1804\n","1805\n","1806\n","1807\n","1808\n","1809\n","1810\n","1811\n","1812\n","1813\n","1814\n","1815\n","1816\n","1817\n","1818\n","1819\n","1820\n","1821\n","1822\n","1823\n","1824\n","1825\n","1826\n","1827\n","1828\n","1829\n","1830\n","1831\n","1832\n","1833\n","1834\n","1835\n","1836\n","1837\n","1838\n","1839\n","1840\n","1841\n","1842\n","1843\n","1844\n","1845\n","1846\n","1847\n","1848\n","1849\n","1850\n","1851\n","1852\n","1853\n","1854\n","1855\n","1856\n","1857\n","1858\n","1859\n","1860\n","1861\n","1862\n","1863\n","1864\n","1865\n","1866\n","1867\n","1868\n","1869\n","1870\n","1871\n","1872\n","1873\n","1874\n","1875\n","1876\n","1877\n","1878\n","1879\n","1880\n","1881\n","1882\n","1883\n","1884\n","1885\n","1886\n","1887\n","1888\n","1889\n","1890\n","1891\n","1892\n","1893\n","1894\n","1895\n","1896\n","1897\n","1898\n","1899\n","1900\n","1901\n","1902\n","1903\n","1904\n","1905\n","1906\n","1907\n","1908\n","1909\n","1910\n","1911\n","1912\n","1913\n","1914\n","1915\n","1916\n","1917\n","1918\n","1919\n","1920\n","1921\n","1922\n","1923\n","1924\n","1925\n","1926\n","1927\n","1928\n","1929\n","1930\n","1931\n","1932\n","1933\n","1934\n","1935\n","1936\n","1937\n","1938\n","1939\n","1940\n","1941\n","1942\n","1943\n","1944\n","1945\n","1946\n","1947\n","1948\n","1949\n","1950\n","1951\n","1952\n","1953\n","1954\n","1955\n","1956\n","1957\n","1958\n","1959\n","1960\n","1961\n","1962\n","1963\n","1964\n","1965\n","1966\n","1967\n","1968\n","1969\n","1970\n","1971\n","1972\n","1973\n","1974\n","1975\n","1976\n","1977\n","1978\n","1979\n","1980\n","1981\n","1982\n","1983\n","1984\n","1985\n","1986\n","1987\n","1988\n","1989\n","1990\n","1991\n","1992\n","1993\n","1994\n","1995\n","1996\n","1997\n","1998\n","1999\n","2000\n","2001\n","2002\n","2003\n","2004\n","2005\n","2006\n","2007\n","2008\n","2009\n","2010\n","2011\n","2012\n","2013\n","2014\n","2015\n","2016\n","2017\n","2018\n","2019\n","2020\n","2021\n","2022\n","2023\n","2024\n","2025\n","2026\n","2027\n","2028\n","2029\n","2030\n","2031\n","2032\n","2033\n","2034\n","2035\n","2036\n","2037\n","2038\n","2039\n","2040\n","2041\n","2042\n","2043\n","2044\n","2045\n","2046\n","2047\n","2048\n","2049\n","2050\n","2051\n","2052\n","2053\n","2054\n","2055\n","2056\n","2057\n","2058\n","2059\n","2060\n","2061\n","2062\n","2063\n","2064\n","2065\n","2066\n","2067\n","2068\n","2069\n","2070\n","2071\n","2072\n","2073\n","2074\n","2075\n","2076\n","2077\n","2078\n","2079\n","2080\n","2081\n","2082\n","2083\n","2084\n","2085\n","2086\n","2087\n","2088\n","2089\n","2090\n","2091\n","2092\n","2093\n","2094\n","2095\n","2096\n","2097\n","2098\n","2099\n","2100\n","2101\n","2102\n","2103\n","2104\n","2105\n","2106\n","2107\n","2108\n","2109\n","2110\n","2111\n","2112\n","2113\n","2114\n","2115\n","2116\n","2117\n","2118\n","2119\n","2120\n","2121\n","2122\n","2123\n","2124\n","2125\n","2126\n","2127\n","2128\n","2129\n","2130\n","2131\n","2132\n","2133\n","2134\n","2135\n","2136\n","2137\n","2138\n","2139\n","2140\n","2141\n","2142\n","2143\n","2144\n","2145\n","2146\n","2147\n","2148\n","2149\n","2150\n","2151\n","2152\n","2153\n","2154\n","2155\n","2156\n","2157\n","2158\n","2159\n","2160\n","2161\n","2162\n","2163\n","2164\n","2165\n","2166\n","2167\n","2168\n","2169\n","2170\n","2171\n","2172\n","2173\n","2174\n","2175\n","2176\n","2177\n","2178\n","2179\n","2180\n","2181\n","2182\n","2183\n","2184\n","2185\n","2186\n","2187\n","2188\n","2189\n","2190\n","2191\n","2192\n","2193\n","2194\n","2195\n","2196\n","2197\n","2198\n","2199\n","2200\n","2201\n","2202\n","2203\n","2204\n","2205\n","2206\n","2207\n","2208\n","2209\n","2210\n","2211\n","2212\n","2213\n","2214\n","2215\n","2216\n","2217\n","2218\n","2219\n","2220\n","2221\n","2222\n","2223\n","2224\n","2225\n","2226\n","2227\n","2228\n","2229\n","2230\n","2231\n","2232\n","2233\n","2234\n","2235\n","2236\n","2237\n","2238\n","2239\n","2240\n","2241\n","2242\n","2243\n","2244\n","2245\n","2246\n","2247\n","2248\n","2249\n","2250\n","2251\n","2252\n","2253\n","2254\n","2255\n","2256\n","2257\n","2258\n","2259\n","2260\n","2261\n","2262\n","2263\n","2264\n","2265\n","2266\n","2267\n","2268\n","2269\n","2270\n","2271\n","2272\n","2273\n","2274\n","2275\n","2276\n","2277\n","2278\n","2279\n","2280\n","2281\n","2282\n","2283\n","2284\n","2285\n","2286\n","2287\n","2288\n","2289\n","2290\n","2291\n","2292\n","2293\n","2294\n","2295\n","2296\n","2297\n","2298\n","2299\n","2300\n","2301\n","2302\n","2303\n","2304\n","2305\n","2306\n","2307\n","2308\n","2309\n","2310\n","2311\n","2312\n","2313\n","2314\n","2315\n","2316\n","2317\n","2318\n","2319\n","2320\n","2321\n","2322\n","2323\n","2324\n","2325\n","2326\n","2327\n","2328\n","2329\n","2330\n","2331\n","2332\n","2333\n","2334\n","2335\n","2336\n","2337\n","2338\n","2339\n","2340\n","2341\n","2342\n","2343\n","2344\n","2345\n","2346\n","2347\n","2348\n","2349\n","2350\n","2351\n","2352\n","2353\n","2354\n","2355\n","2356\n","2357\n","2358\n","2359\n","2360\n","2361\n","2362\n","2363\n","2364\n","2365\n","2366\n","2367\n","2368\n","2369\n","2370\n","2371\n","2372\n","2373\n","2374\n","2375\n","2376\n","2377\n","2378\n","2379\n","2380\n","2381\n","2382\n","2383\n","2384\n","2385\n","2386\n","2387\n","2388\n","2389\n","2390\n","2391\n","2392\n","2393\n","2394\n","2395\n","2396\n","2397\n","2398\n","2399\n","2400\n","2401\n","2402\n","2403\n","2404\n","2405\n","2406\n","2407\n","2408\n","2409\n","2410\n","2411\n","2412\n","2413\n","2414\n","2415\n","2416\n","2417\n","2418\n","2419\n","2420\n","2421\n","2422\n","2423\n","2424\n","2425\n","2426\n","2427\n","2428\n","2429\n","2430\n","2431\n","2432\n","2433\n","2434\n","2435\n","2436\n","2437\n","2438\n","2439\n","2440\n","2441\n","2442\n","2443\n","2444\n","2445\n","2446\n","2447\n","2448\n","2449\n","2450\n","2451\n","2452\n","2453\n","2454\n","2455\n","2456\n","2457\n","2458\n","2459\n","2460\n","2461\n","2462\n","2463\n","2464\n","2465\n","2466\n","2467\n","2468\n","2469\n","2470\n","2471\n","2472\n","2473\n","2474\n","2475\n","2476\n","2477\n","2478\n","2479\n","2480\n","2481\n","2482\n","2483\n","2484\n","2485\n","2486\n","2487\n","2488\n","2489\n","2490\n","2491\n","2492\n","2493\n","2494\n","2495\n","2496\n","2497\n","2498\n","2499\n","2500\n","2501\n","2502\n","2503\n","2504\n","2505\n","2506\n","2507\n","2508\n","2509\n","2510\n","2511\n","2512\n","2513\n","2514\n","2515\n","2516\n","2517\n","2518\n","2519\n","2520\n","2521\n","2522\n","2523\n","2524\n","2525\n","2526\n","2527\n","2528\n","2529\n","2530\n","2531\n","2532\n","2533\n","2534\n","2535\n","2536\n","2537\n","2538\n","2539\n","2540\n","2541\n","2542\n","2543\n","2544\n","2545\n","2546\n","2547\n","2548\n","2549\n","2550\n","2551\n","2552\n","2553\n","2554\n","2555\n","2556\n","2557\n","2558\n","2559\n","2560\n","2561\n","2562\n","2563\n","2564\n","2565\n","2566\n","2567\n","2568\n","2569\n","2570\n","2571\n","2572\n","2573\n","2574\n","2575\n","2576\n","2577\n","2578\n","2579\n","2580\n","2581\n","2582\n","2583\n","2584\n","2585\n","2586\n","2587\n","2588\n","2589\n","2590\n","2591\n","2592\n","2593\n","2594\n","2595\n","2596\n","2597\n","2598\n","2599\n","2600\n","2601\n","2602\n","2603\n","2604\n","2605\n","2606\n","2607\n","2608\n","2609\n","2610\n","2611\n","2612\n","2613\n","2614\n","2615\n","2616\n","2617\n","2618\n","2619\n","2620\n","2621\n","2622\n","2623\n","2624\n","2625\n","2626\n","2627\n","2628\n","2629\n","2630\n","2631\n","2632\n","2633\n","2634\n","2635\n","2636\n","2637\n","2638\n","2639\n","2640\n","2641\n","2642\n","2643\n","2644\n","2645\n","2646\n","2647\n","2648\n","2649\n","2650\n","2651\n","2652\n","2653\n","2654\n","2655\n","2656\n","2657\n","2658\n","2659\n","2660\n","2661\n","2662\n","2663\n","2664\n","2665\n","2666\n","2667\n","2668\n","2669\n","2670\n","2671\n","2672\n","2673\n","2674\n","2675\n","2676\n","2677\n","2678\n","2679\n","2680\n","2681\n","2682\n","2683\n","2684\n","2685\n","2686\n","2687\n","2688\n","2689\n","2690\n","2691\n","2692\n","2693\n","2694\n","2695\n","2696\n","2697\n","2698\n","2699\n","2700\n","2701\n","2702\n","2703\n","2704\n","2705\n","2706\n","2707\n","2708\n","2709\n","2710\n","2711\n","2712\n","2713\n","2714\n","2715\n","2716\n","2717\n","2718\n","2719\n","2720\n","2721\n","2722\n","2723\n","2724\n","2725\n","2726\n","2727\n","2728\n","2729\n","2730\n","2731\n","2732\n","2733\n","2734\n","2735\n","2736\n","2737\n","2738\n","2739\n","2740\n","2741\n","2742\n","2743\n","2744\n","2745\n","2746\n","2747\n","2748\n","2749\n","2750\n","2751\n","2752\n","2753\n","2754\n","2755\n","2756\n","2757\n","2758\n","2759\n","2760\n","2761\n","2762\n","2763\n","2764\n","2765\n","2766\n","2767\n","2768\n","2769\n","2770\n","2771\n","2772\n","2773\n","2774\n","2775\n","2776\n","2777\n","2778\n","2779\n","2780\n","2781\n","2782\n","2783\n","2784\n","2785\n","2786\n","2787\n","2788\n","2789\n","2790\n","2791\n","2792\n","2793\n","2794\n","2795\n","2796\n","2797\n","2798\n","2799\n","2800\n","2801\n","2802\n","2803\n","2804\n","2805\n","2806\n","2807\n","2808\n","2809\n","2810\n","2811\n","2812\n","2813\n","2814\n","2815\n","2816\n","2817\n","2818\n","2819\n","2820\n","2821\n","2822\n","2823\n","2824\n","2825\n","2826\n","2827\n","2828\n","2829\n","2830\n","2831\n","2832\n","2833\n","2834\n","2835\n","2836\n","2837\n","2838\n","2839\n","2840\n","2841\n","2842\n","2843\n","2844\n","2845\n","2846\n","2847\n","2848\n","2849\n","2850\n","2851\n","2852\n","2853\n","2854\n","2855\n","2856\n","2857\n","2858\n","2859\n","2860\n","2861\n","2862\n","2863\n","2864\n","2865\n","2866\n","2867\n","2868\n","2869\n","2870\n","2871\n","2872\n","2873\n","2874\n","2875\n","2876\n","2877\n","2878\n","2879\n","2880\n","2881\n","2882\n","2883\n","2884\n","2885\n","2886\n","2887\n","2888\n","2889\n","2890\n","2891\n","2892\n","2893\n","2894\n","2895\n","2896\n","2897\n","2898\n","2899\n","2900\n","2901\n","2902\n","2903\n","2904\n","2905\n","2906\n","2907\n","2908\n","2909\n","2910\n","2911\n","2912\n","2913\n","2914\n","2915\n","2916\n","2917\n","2918\n","2919\n","2920\n","2921\n","2922\n","2923\n","2924\n","2925\n","2926\n","2927\n","2928\n","2929\n","2930\n","2931\n","2932\n","2933\n","2934\n","2935\n","2936\n","2937\n","2938\n","2939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XMs1qEKXJJx8","colab_type":"code","colab":{}},"source":["temp2=np.array(q)\n","np.save(\"drive/My Drive/MS_data/temp_2_in.npy\",temp2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lNQvSNhJMfq","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","temp=np.load(\"drive/My Drive/MS_data/temp_1_in.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BkwUxQ4RJP-a","colab_type":"code","colab":{}},"source":["q=list(temp2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F2nX0PmUJRCl","colab_type":"code","colab":{}},"source":["p=list(temp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ogl1MTYwJSbL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9733df12-9cb2-4eb6-9471-ae6ffdcd9818","executionInfo":{"status":"ok","timestamp":1585205540072,"user_tz":-330,"elapsed":1779,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["j=1401\n","for i in q:\n","  print(j)\n","  p.append(i)\n","  j+=1"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1401\n","1402\n","1403\n","1404\n","1405\n","1406\n","1407\n","1408\n","1409\n","1410\n","1411\n","1412\n","1413\n","1414\n","1415\n","1416\n","1417\n","1418\n","1419\n","1420\n","1421\n","1422\n","1423\n","1424\n","1425\n","1426\n","1427\n","1428\n","1429\n","1430\n","1431\n","1432\n","1433\n","1434\n","1435\n","1436\n","1437\n","1438\n","1439\n","1440\n","1441\n","1442\n","1443\n","1444\n","1445\n","1446\n","1447\n","1448\n","1449\n","1450\n","1451\n","1452\n","1453\n","1454\n","1455\n","1456\n","1457\n","1458\n","1459\n","1460\n","1461\n","1462\n","1463\n","1464\n","1465\n","1466\n","1467\n","1468\n","1469\n","1470\n","1471\n","1472\n","1473\n","1474\n","1475\n","1476\n","1477\n","1478\n","1479\n","1480\n","1481\n","1482\n","1483\n","1484\n","1485\n","1486\n","1487\n","1488\n","1489\n","1490\n","1491\n","1492\n","1493\n","1494\n","1495\n","1496\n","1497\n","1498\n","1499\n","1500\n","1501\n","1502\n","1503\n","1504\n","1505\n","1506\n","1507\n","1508\n","1509\n","1510\n","1511\n","1512\n","1513\n","1514\n","1515\n","1516\n","1517\n","1518\n","1519\n","1520\n","1521\n","1522\n","1523\n","1524\n","1525\n","1526\n","1527\n","1528\n","1529\n","1530\n","1531\n","1532\n","1533\n","1534\n","1535\n","1536\n","1537\n","1538\n","1539\n","1540\n","1541\n","1542\n","1543\n","1544\n","1545\n","1546\n","1547\n","1548\n","1549\n","1550\n","1551\n","1552\n","1553\n","1554\n","1555\n","1556\n","1557\n","1558\n","1559\n","1560\n","1561\n","1562\n","1563\n","1564\n","1565\n","1566\n","1567\n","1568\n","1569\n","1570\n","1571\n","1572\n","1573\n","1574\n","1575\n","1576\n","1577\n","1578\n","1579\n","1580\n","1581\n","1582\n","1583\n","1584\n","1585\n","1586\n","1587\n","1588\n","1589\n","1590\n","1591\n","1592\n","1593\n","1594\n","1595\n","1596\n","1597\n","1598\n","1599\n","1600\n","1601\n","1602\n","1603\n","1604\n","1605\n","1606\n","1607\n","1608\n","1609\n","1610\n","1611\n","1612\n","1613\n","1614\n","1615\n","1616\n","1617\n","1618\n","1619\n","1620\n","1621\n","1622\n","1623\n","1624\n","1625\n","1626\n","1627\n","1628\n","1629\n","1630\n","1631\n","1632\n","1633\n","1634\n","1635\n","1636\n","1637\n","1638\n","1639\n","1640\n","1641\n","1642\n","1643\n","1644\n","1645\n","1646\n","1647\n","1648\n","1649\n","1650\n","1651\n","1652\n","1653\n","1654\n","1655\n","1656\n","1657\n","1658\n","1659\n","1660\n","1661\n","1662\n","1663\n","1664\n","1665\n","1666\n","1667\n","1668\n","1669\n","1670\n","1671\n","1672\n","1673\n","1674\n","1675\n","1676\n","1677\n","1678\n","1679\n","1680\n","1681\n","1682\n","1683\n","1684\n","1685\n","1686\n","1687\n","1688\n","1689\n","1690\n","1691\n","1692\n","1693\n","1694\n","1695\n","1696\n","1697\n","1698\n","1699\n","1700\n","1701\n","1702\n","1703\n","1704\n","1705\n","1706\n","1707\n","1708\n","1709\n","1710\n","1711\n","1712\n","1713\n","1714\n","1715\n","1716\n","1717\n","1718\n","1719\n","1720\n","1721\n","1722\n","1723\n","1724\n","1725\n","1726\n","1727\n","1728\n","1729\n","1730\n","1731\n","1732\n","1733\n","1734\n","1735\n","1736\n","1737\n","1738\n","1739\n","1740\n","1741\n","1742\n","1743\n","1744\n","1745\n","1746\n","1747\n","1748\n","1749\n","1750\n","1751\n","1752\n","1753\n","1754\n","1755\n","1756\n","1757\n","1758\n","1759\n","1760\n","1761\n","1762\n","1763\n","1764\n","1765\n","1766\n","1767\n","1768\n","1769\n","1770\n","1771\n","1772\n","1773\n","1774\n","1775\n","1776\n","1777\n","1778\n","1779\n","1780\n","1781\n","1782\n","1783\n","1784\n","1785\n","1786\n","1787\n","1788\n","1789\n","1790\n","1791\n","1792\n","1793\n","1794\n","1795\n","1796\n","1797\n","1798\n","1799\n","1800\n","1801\n","1802\n","1803\n","1804\n","1805\n","1806\n","1807\n","1808\n","1809\n","1810\n","1811\n","1812\n","1813\n","1814\n","1815\n","1816\n","1817\n","1818\n","1819\n","1820\n","1821\n","1822\n","1823\n","1824\n","1825\n","1826\n","1827\n","1828\n","1829\n","1830\n","1831\n","1832\n","1833\n","1834\n","1835\n","1836\n","1837\n","1838\n","1839\n","1840\n","1841\n","1842\n","1843\n","1844\n","1845\n","1846\n","1847\n","1848\n","1849\n","1850\n","1851\n","1852\n","1853\n","1854\n","1855\n","1856\n","1857\n","1858\n","1859\n","1860\n","1861\n","1862\n","1863\n","1864\n","1865\n","1866\n","1867\n","1868\n","1869\n","1870\n","1871\n","1872\n","1873\n","1874\n","1875\n","1876\n","1877\n","1878\n","1879\n","1880\n","1881\n","1882\n","1883\n","1884\n","1885\n","1886\n","1887\n","1888\n","1889\n","1890\n","1891\n","1892\n","1893\n","1894\n","1895\n","1896\n","1897\n","1898\n","1899\n","1900\n","1901\n","1902\n","1903\n","1904\n","1905\n","1906\n","1907\n","1908\n","1909\n","1910\n","1911\n","1912\n","1913\n","1914\n","1915\n","1916\n","1917\n","1918\n","1919\n","1920\n","1921\n","1922\n","1923\n","1924\n","1925\n","1926\n","1927\n","1928\n","1929\n","1930\n","1931\n","1932\n","1933\n","1934\n","1935\n","1936\n","1937\n","1938\n","1939\n","1940\n","1941\n","1942\n","1943\n","1944\n","1945\n","1946\n","1947\n","1948\n","1949\n","1950\n","1951\n","1952\n","1953\n","1954\n","1955\n","1956\n","1957\n","1958\n","1959\n","1960\n","1961\n","1962\n","1963\n","1964\n","1965\n","1966\n","1967\n","1968\n","1969\n","1970\n","1971\n","1972\n","1973\n","1974\n","1975\n","1976\n","1977\n","1978\n","1979\n","1980\n","1981\n","1982\n","1983\n","1984\n","1985\n","1986\n","1987\n","1988\n","1989\n","1990\n","1991\n","1992\n","1993\n","1994\n","1995\n","1996\n","1997\n","1998\n","1999\n","2000\n","2001\n","2002\n","2003\n","2004\n","2005\n","2006\n","2007\n","2008\n","2009\n","2010\n","2011\n","2012\n","2013\n","2014\n","2015\n","2016\n","2017\n","2018\n","2019\n","2020\n","2021\n","2022\n","2023\n","2024\n","2025\n","2026\n","2027\n","2028\n","2029\n","2030\n","2031\n","2032\n","2033\n","2034\n","2035\n","2036\n","2037\n","2038\n","2039\n","2040\n","2041\n","2042\n","2043\n","2044\n","2045\n","2046\n","2047\n","2048\n","2049\n","2050\n","2051\n","2052\n","2053\n","2054\n","2055\n","2056\n","2057\n","2058\n","2059\n","2060\n","2061\n","2062\n","2063\n","2064\n","2065\n","2066\n","2067\n","2068\n","2069\n","2070\n","2071\n","2072\n","2073\n","2074\n","2075\n","2076\n","2077\n","2078\n","2079\n","2080\n","2081\n","2082\n","2083\n","2084\n","2085\n","2086\n","2087\n","2088\n","2089\n","2090\n","2091\n","2092\n","2093\n","2094\n","2095\n","2096\n","2097\n","2098\n","2099\n","2100\n","2101\n","2102\n","2103\n","2104\n","2105\n","2106\n","2107\n","2108\n","2109\n","2110\n","2111\n","2112\n","2113\n","2114\n","2115\n","2116\n","2117\n","2118\n","2119\n","2120\n","2121\n","2122\n","2123\n","2124\n","2125\n","2126\n","2127\n","2128\n","2129\n","2130\n","2131\n","2132\n","2133\n","2134\n","2135\n","2136\n","2137\n","2138\n","2139\n","2140\n","2141\n","2142\n","2143\n","2144\n","2145\n","2146\n","2147\n","2148\n","2149\n","2150\n","2151\n","2152\n","2153\n","2154\n","2155\n","2156\n","2157\n","2158\n","2159\n","2160\n","2161\n","2162\n","2163\n","2164\n","2165\n","2166\n","2167\n","2168\n","2169\n","2170\n","2171\n","2172\n","2173\n","2174\n","2175\n","2176\n","2177\n","2178\n","2179\n","2180\n","2181\n","2182\n","2183\n","2184\n","2185\n","2186\n","2187\n","2188\n","2189\n","2190\n","2191\n","2192\n","2193\n","2194\n","2195\n","2196\n","2197\n","2198\n","2199\n","2200\n","2201\n","2202\n","2203\n","2204\n","2205\n","2206\n","2207\n","2208\n","2209\n","2210\n","2211\n","2212\n","2213\n","2214\n","2215\n","2216\n","2217\n","2218\n","2219\n","2220\n","2221\n","2222\n","2223\n","2224\n","2225\n","2226\n","2227\n","2228\n","2229\n","2230\n","2231\n","2232\n","2233\n","2234\n","2235\n","2236\n","2237\n","2238\n","2239\n","2240\n","2241\n","2242\n","2243\n","2244\n","2245\n","2246\n","2247\n","2248\n","2249\n","2250\n","2251\n","2252\n","2253\n","2254\n","2255\n","2256\n","2257\n","2258\n","2259\n","2260\n","2261\n","2262\n","2263\n","2264\n","2265\n","2266\n","2267\n","2268\n","2269\n","2270\n","2271\n","2272\n","2273\n","2274\n","2275\n","2276\n","2277\n","2278\n","2279\n","2280\n","2281\n","2282\n","2283\n","2284\n","2285\n","2286\n","2287\n","2288\n","2289\n","2290\n","2291\n","2292\n","2293\n","2294\n","2295\n","2296\n","2297\n","2298\n","2299\n","2300\n","2301\n","2302\n","2303\n","2304\n","2305\n","2306\n","2307\n","2308\n","2309\n","2310\n","2311\n","2312\n","2313\n","2314\n","2315\n","2316\n","2317\n","2318\n","2319\n","2320\n","2321\n","2322\n","2323\n","2324\n","2325\n","2326\n","2327\n","2328\n","2329\n","2330\n","2331\n","2332\n","2333\n","2334\n","2335\n","2336\n","2337\n","2338\n","2339\n","2340\n","2341\n","2342\n","2343\n","2344\n","2345\n","2346\n","2347\n","2348\n","2349\n","2350\n","2351\n","2352\n","2353\n","2354\n","2355\n","2356\n","2357\n","2358\n","2359\n","2360\n","2361\n","2362\n","2363\n","2364\n","2365\n","2366\n","2367\n","2368\n","2369\n","2370\n","2371\n","2372\n","2373\n","2374\n","2375\n","2376\n","2377\n","2378\n","2379\n","2380\n","2381\n","2382\n","2383\n","2384\n","2385\n","2386\n","2387\n","2388\n","2389\n","2390\n","2391\n","2392\n","2393\n","2394\n","2395\n","2396\n","2397\n","2398\n","2399\n","2400\n","2401\n","2402\n","2403\n","2404\n","2405\n","2406\n","2407\n","2408\n","2409\n","2410\n","2411\n","2412\n","2413\n","2414\n","2415\n","2416\n","2417\n","2418\n","2419\n","2420\n","2421\n","2422\n","2423\n","2424\n","2425\n","2426\n","2427\n","2428\n","2429\n","2430\n","2431\n","2432\n","2433\n","2434\n","2435\n","2436\n","2437\n","2438\n","2439\n","2440\n","2441\n","2442\n","2443\n","2444\n","2445\n","2446\n","2447\n","2448\n","2449\n","2450\n","2451\n","2452\n","2453\n","2454\n","2455\n","2456\n","2457\n","2458\n","2459\n","2460\n","2461\n","2462\n","2463\n","2464\n","2465\n","2466\n","2467\n","2468\n","2469\n","2470\n","2471\n","2472\n","2473\n","2474\n","2475\n","2476\n","2477\n","2478\n","2479\n","2480\n","2481\n","2482\n","2483\n","2484\n","2485\n","2486\n","2487\n","2488\n","2489\n","2490\n","2491\n","2492\n","2493\n","2494\n","2495\n","2496\n","2497\n","2498\n","2499\n","2500\n","2501\n","2502\n","2503\n","2504\n","2505\n","2506\n","2507\n","2508\n","2509\n","2510\n","2511\n","2512\n","2513\n","2514\n","2515\n","2516\n","2517\n","2518\n","2519\n","2520\n","2521\n","2522\n","2523\n","2524\n","2525\n","2526\n","2527\n","2528\n","2529\n","2530\n","2531\n","2532\n","2533\n","2534\n","2535\n","2536\n","2537\n","2538\n","2539\n","2540\n","2541\n","2542\n","2543\n","2544\n","2545\n","2546\n","2547\n","2548\n","2549\n","2550\n","2551\n","2552\n","2553\n","2554\n","2555\n","2556\n","2557\n","2558\n","2559\n","2560\n","2561\n","2562\n","2563\n","2564\n","2565\n","2566\n","2567\n","2568\n","2569\n","2570\n","2571\n","2572\n","2573\n","2574\n","2575\n","2576\n","2577\n","2578\n","2579\n","2580\n","2581\n","2582\n","2583\n","2584\n","2585\n","2586\n","2587\n","2588\n","2589\n","2590\n","2591\n","2592\n","2593\n","2594\n","2595\n","2596\n","2597\n","2598\n","2599\n","2600\n","2601\n","2602\n","2603\n","2604\n","2605\n","2606\n","2607\n","2608\n","2609\n","2610\n","2611\n","2612\n","2613\n","2614\n","2615\n","2616\n","2617\n","2618\n","2619\n","2620\n","2621\n","2622\n","2623\n","2624\n","2625\n","2626\n","2627\n","2628\n","2629\n","2630\n","2631\n","2632\n","2633\n","2634\n","2635\n","2636\n","2637\n","2638\n","2639\n","2640\n","2641\n","2642\n","2643\n","2644\n","2645\n","2646\n","2647\n","2648\n","2649\n","2650\n","2651\n","2652\n","2653\n","2654\n","2655\n","2656\n","2657\n","2658\n","2659\n","2660\n","2661\n","2662\n","2663\n","2664\n","2665\n","2666\n","2667\n","2668\n","2669\n","2670\n","2671\n","2672\n","2673\n","2674\n","2675\n","2676\n","2677\n","2678\n","2679\n","2680\n","2681\n","2682\n","2683\n","2684\n","2685\n","2686\n","2687\n","2688\n","2689\n","2690\n","2691\n","2692\n","2693\n","2694\n","2695\n","2696\n","2697\n","2698\n","2699\n","2700\n","2701\n","2702\n","2703\n","2704\n","2705\n","2706\n","2707\n","2708\n","2709\n","2710\n","2711\n","2712\n","2713\n","2714\n","2715\n","2716\n","2717\n","2718\n","2719\n","2720\n","2721\n","2722\n","2723\n","2724\n","2725\n","2726\n","2727\n","2728\n","2729\n","2730\n","2731\n","2732\n","2733\n","2734\n","2735\n","2736\n","2737\n","2738\n","2739\n","2740\n","2741\n","2742\n","2743\n","2744\n","2745\n","2746\n","2747\n","2748\n","2749\n","2750\n","2751\n","2752\n","2753\n","2754\n","2755\n","2756\n","2757\n","2758\n","2759\n","2760\n","2761\n","2762\n","2763\n","2764\n","2765\n","2766\n","2767\n","2768\n","2769\n","2770\n","2771\n","2772\n","2773\n","2774\n","2775\n","2776\n","2777\n","2778\n","2779\n","2780\n","2781\n","2782\n","2783\n","2784\n","2785\n","2786\n","2787\n","2788\n","2789\n","2790\n","2791\n","2792\n","2793\n","2794\n","2795\n","2796\n","2797\n","2798\n","2799\n","2800\n","2801\n","2802\n","2803\n","2804\n","2805\n","2806\n","2807\n","2808\n","2809\n","2810\n","2811\n","2812\n","2813\n","2814\n","2815\n","2816\n","2817\n","2818\n","2819\n","2820\n","2821\n","2822\n","2823\n","2824\n","2825\n","2826\n","2827\n","2828\n","2829\n","2830\n","2831\n","2832\n","2833\n","2834\n","2835\n","2836\n","2837\n","2838\n","2839\n","2840\n","2841\n","2842\n","2843\n","2844\n","2845\n","2846\n","2847\n","2848\n","2849\n","2850\n","2851\n","2852\n","2853\n","2854\n","2855\n","2856\n","2857\n","2858\n","2859\n","2860\n","2861\n","2862\n","2863\n","2864\n","2865\n","2866\n","2867\n","2868\n","2869\n","2870\n","2871\n","2872\n","2873\n","2874\n","2875\n","2876\n","2877\n","2878\n","2879\n","2880\n","2881\n","2882\n","2883\n","2884\n","2885\n","2886\n","2887\n","2888\n","2889\n","2890\n","2891\n","2892\n","2893\n","2894\n","2895\n","2896\n","2897\n","2898\n","2899\n","2900\n","2901\n","2902\n","2903\n","2904\n","2905\n","2906\n","2907\n","2908\n","2909\n","2910\n","2911\n","2912\n","2913\n","2914\n","2915\n","2916\n","2917\n","2918\n","2919\n","2920\n","2921\n","2922\n","2923\n","2924\n","2925\n","2926\n","2927\n","2928\n","2929\n","2930\n","2931\n","2932\n","2933\n","2934\n","2935\n","2936\n","2937\n","2938\n","2939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VFt-oTwKJU4N","colab_type":"code","colab":{}},"source":["np.save(\"drive/My Drive/MS_data/Y_Manual_in_2.npy\",p)\n","Y=np.load(\"drive/My Drive/MS_data/Y_Manual_in_2.npy\")\n","X=np.load(\"drive/My Drive/MS_data/X_intersection.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3s52t7TfJV-m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":117},"outputId":"5819ff68-a916-45b5-8e19-01f776992cbc","executionInfo":{"status":"ok","timestamp":1585205690397,"user_tz":-330,"elapsed":12306,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","#print(X_train)\n","#print(X_test)\n","print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n","#print(Y_train)\n","#print(Y_test)\n","# Loding the modified U-net "],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ca94mekZJaDu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"76d97a81-5fe5-44f4-f403-910928aa0f57","executionInfo":{"status":"ok","timestamp":1585206977399,"user_tz":-330,"elapsed":1174293,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","model = model(input_shape = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('drive/My Drive/MS_data/Modified_UNet_intersection.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('drive/My Drive/MS_data/Modified_UNet.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)\n","#Loss_Graph(history)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 5) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 32) 1472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 256)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 16, 16, 512)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 32, 32, 512)  0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 768)  0           up_sampling2d[0][0]              \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 256)  1769728     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_1[0][0]            \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 64, 64, 128)  442496      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_2[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 128, 128, 64) 110656      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_3[0][0]            \n","                                                                 activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 256, 256, 32) 27680       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 256, 256, 32) 128         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 256, 256, 32) 0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 256, 256, 1)  33          activation_8[0][0]               \n","==================================================================================================\n","Total params: 3,925,633\n","Trainable params: 3,922,689\n","Non-trainable params: 2,944\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 1999 samples, validate on 500 samples\n","Epoch 1/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9958 - dice_coef: 0.0297 - precision: 0.5092 - sensitivity: 0.7167 - specificity: 0.9964\n","Epoch 00001: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 30s 15ms/sample - loss: 0.1169 - acc: 0.9958 - dice_coef: 0.0307 - precision: 0.5105 - sensitivity: 0.7191 - specificity: 0.9964 - val_loss: 0.1476 - val_acc: 0.9972 - val_dice_coef: 0.0251 - val_precision: 0.4192 - val_sensitivity: 0.9202 - val_specificity: 0.9974\n","Epoch 2/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9988 - dice_coef: 0.0688 - precision: 0.7154 - sensitivity: 0.6780 - specificity: 0.9994\n","Epoch 00002: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0360 - acc: 0.9988 - dice_coef: 0.0687 - precision: 0.7141 - sensitivity: 0.6782 - specificity: 0.9994 - val_loss: 0.0466 - val_acc: 0.9987 - val_dice_coef: 0.0677 - val_precision: 0.6959 - val_sensitivity: 0.8313 - val_specificity: 0.9991\n","Epoch 3/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9989 - dice_coef: 0.1133 - precision: 0.7367 - sensitivity: 0.7201 - specificity: 0.9995\n","Epoch 00003: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0209 - acc: 0.9989 - dice_coef: 0.1139 - precision: 0.7325 - sensitivity: 0.7233 - specificity: 0.9995 - val_loss: 0.0225 - val_acc: 0.9989 - val_dice_coef: 0.1143 - val_precision: 0.7613 - val_sensitivity: 0.7049 - val_specificity: 0.9995\n","Epoch 4/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9989 - dice_coef: 0.1662 - precision: 0.7441 - sensitivity: 0.7251 - specificity: 0.9995\n","Epoch 00004: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0136 - acc: 0.9989 - dice_coef: 0.1648 - precision: 0.7405 - sensitivity: 0.7279 - specificity: 0.9995 - val_loss: 0.0138 - val_acc: 0.9988 - val_dice_coef: 0.1799 - val_precision: 0.8036 - val_sensitivity: 0.6756 - val_specificity: 0.9995\n","Epoch 5/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9990 - dice_coef: 0.2130 - precision: 0.7509 - sensitivity: 0.7238 - specificity: 0.9995\n","Epoch 00005: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0101 - acc: 0.9990 - dice_coef: 0.2125 - precision: 0.7463 - sensitivity: 0.7226 - specificity: 0.9995 - val_loss: 0.0093 - val_acc: 0.9989 - val_dice_coef: 0.2256 - val_precision: 0.8004 - val_sensitivity: 0.6447 - val_specificity: 0.9997\n","Epoch 6/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9990 - dice_coef: 0.2573 - precision: 0.7619 - sensitivity: 0.7347 - specificity: 0.9996\n","Epoch 00006: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0079 - acc: 0.9990 - dice_coef: 0.2597 - precision: 0.7621 - sensitivity: 0.7362 - specificity: 0.9995 - val_loss: 0.0075 - val_acc: 0.9988 - val_dice_coef: 0.3490 - val_precision: 0.6785 - val_sensitivity: 0.8563 - val_specificity: 0.9991\n","Epoch 7/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9990 - dice_coef: 0.3053 - precision: 0.7604 - sensitivity: 0.7394 - specificity: 0.9995\n","Epoch 00007: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0065 - acc: 0.9990 - dice_coef: 0.3076 - precision: 0.7639 - sensitivity: 0.7392 - specificity: 0.9995 - val_loss: 0.0060 - val_acc: 0.9990 - val_dice_coef: 0.3614 - val_precision: 0.7616 - val_sensitivity: 0.7656 - val_specificity: 0.9995\n","Epoch 8/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9990 - dice_coef: 0.3432 - precision: 0.7602 - sensitivity: 0.7473 - specificity: 0.9995\n","Epoch 00008: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0056 - acc: 0.9990 - dice_coef: 0.3435 - precision: 0.7608 - sensitivity: 0.7474 - specificity: 0.9996 - val_loss: 0.0053 - val_acc: 0.9989 - val_dice_coef: 0.4372 - val_precision: 0.7455 - val_sensitivity: 0.7958 - val_specificity: 0.9994\n","Epoch 9/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9990 - dice_coef: 0.3869 - precision: 0.7653 - sensitivity: 0.7386 - specificity: 0.9995\n","Epoch 00009: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0050 - acc: 0.9990 - dice_coef: 0.3869 - precision: 0.7658 - sensitivity: 0.7393 - specificity: 0.9995 - val_loss: 0.0047 - val_acc: 0.9989 - val_dice_coef: 0.3912 - val_precision: 0.8735 - val_sensitivity: 0.5777 - val_specificity: 0.9998\n","Epoch 10/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9991 - dice_coef: 0.4119 - precision: 0.7763 - sensitivity: 0.7450 - specificity: 0.9996\n","Epoch 00010: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0043 - acc: 0.9991 - dice_coef: 0.4135 - precision: 0.7767 - sensitivity: 0.7451 - specificity: 0.9996 - val_loss: 0.0042 - val_acc: 0.9990 - val_dice_coef: 0.4796 - val_precision: 0.7828 - val_sensitivity: 0.7522 - val_specificity: 0.9995\n","Epoch 11/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9991 - dice_coef: 0.4435 - precision: 0.7718 - sensitivity: 0.7494 - specificity: 0.9996\n","Epoch 00011: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0040 - acc: 0.9991 - dice_coef: 0.4455 - precision: 0.7731 - sensitivity: 0.7503 - specificity: 0.9996 - val_loss: 0.0038 - val_acc: 0.9990 - val_dice_coef: 0.4844 - val_precision: 0.8535 - val_sensitivity: 0.6749 - val_specificity: 0.9997\n","Epoch 12/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9991 - dice_coef: 0.4692 - precision: 0.7832 - sensitivity: 0.7489 - specificity: 0.9996\n","Epoch 00012: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0036 - acc: 0.9991 - dice_coef: 0.4693 - precision: 0.7839 - sensitivity: 0.7502 - specificity: 0.9996 - val_loss: 0.0037 - val_acc: 0.9990 - val_dice_coef: 0.5286 - val_precision: 0.7309 - val_sensitivity: 0.8291 - val_specificity: 0.9994\n","Epoch 13/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9991 - dice_coef: 0.4927 - precision: 0.7883 - sensitivity: 0.7514 - specificity: 0.9996\n","Epoch 00013: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 20s 10ms/sample - loss: 0.0034 - acc: 0.9991 - dice_coef: 0.4919 - precision: 0.7841 - sensitivity: 0.7527 - specificity: 0.9996 - val_loss: 0.0033 - val_acc: 0.9991 - val_dice_coef: 0.5679 - val_precision: 0.7757 - val_sensitivity: 0.8050 - val_specificity: 0.9995\n","Epoch 14/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9992 - dice_coef: 0.5243 - precision: 0.8009 - sensitivity: 0.7637 - specificity: 0.9996\n","Epoch 00014: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0031 - acc: 0.9992 - dice_coef: 0.5212 - precision: 0.7950 - sensitivity: 0.7616 - specificity: 0.9996 - val_loss: 0.0032 - val_acc: 0.9991 - val_dice_coef: 0.5636 - val_precision: 0.8565 - val_sensitivity: 0.7162 - val_specificity: 0.9997\n","Epoch 15/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992 - dice_coef: 0.5406 - precision: 0.7942 - sensitivity: 0.7707 - specificity: 0.9996\n","Epoch 00015: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0029 - acc: 0.9992 - dice_coef: 0.5411 - precision: 0.7964 - sensitivity: 0.7695 - specificity: 0.9996 - val_loss: 0.0029 - val_acc: 0.9991 - val_dice_coef: 0.5866 - val_precision: 0.8156 - val_sensitivity: 0.7740 - val_specificity: 0.9996\n","Epoch 16/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992 - dice_coef: 0.5517 - precision: 0.7986 - sensitivity: 0.7654 - specificity: 0.9996\n","Epoch 00016: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0028 - acc: 0.9992 - dice_coef: 0.5538 - precision: 0.7994 - sensitivity: 0.7663 - specificity: 0.9996 - val_loss: 0.0028 - val_acc: 0.9991 - val_dice_coef: 0.6100 - val_precision: 0.8093 - val_sensitivity: 0.7508 - val_specificity: 0.9996\n","Epoch 17/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9992 - dice_coef: 0.5653 - precision: 0.7893 - sensitivity: 0.7790 - specificity: 0.9996\n","Epoch 00017: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0027 - acc: 0.9992 - dice_coef: 0.5640 - precision: 0.7880 - sensitivity: 0.7788 - specificity: 0.9996 - val_loss: 0.0029 - val_acc: 0.9990 - val_dice_coef: 0.5896 - val_precision: 0.7577 - val_sensitivity: 0.7743 - val_specificity: 0.9995\n","Epoch 18/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9992 - dice_coef: 0.5784 - precision: 0.8028 - sensitivity: 0.7654 - specificity: 0.9996\n","Epoch 00018: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0026 - acc: 0.9992 - dice_coef: 0.5781 - precision: 0.8033 - sensitivity: 0.7636 - specificity: 0.9996 - val_loss: 0.0027 - val_acc: 0.9991 - val_dice_coef: 0.6566 - val_precision: 0.7795 - val_sensitivity: 0.8305 - val_specificity: 0.9995\n","Epoch 19/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9992 - dice_coef: 0.5983 - precision: 0.8051 - sensitivity: 0.7819 - specificity: 0.9996\n","Epoch 00019: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0025 - acc: 0.9992 - dice_coef: 0.5996 - precision: 0.8059 - sensitivity: 0.7819 - specificity: 0.9996 - val_loss: 0.0027 - val_acc: 0.9991 - val_dice_coef: 0.6431 - val_precision: 0.7769 - val_sensitivity: 0.8090 - val_specificity: 0.9995\n","Epoch 20/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9993 - dice_coef: 0.6227 - precision: 0.8147 - sensitivity: 0.7932 - specificity: 0.9997\n","Epoch 00020: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0023 - acc: 0.9993 - dice_coef: 0.6243 - precision: 0.8162 - sensitivity: 0.7933 - specificity: 0.9997 - val_loss: 0.0026 - val_acc: 0.9991 - val_dice_coef: 0.6550 - val_precision: 0.7705 - val_sensitivity: 0.8558 - val_specificity: 0.9994\n","Epoch 21/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9993 - dice_coef: 0.6232 - precision: 0.8146 - sensitivity: 0.7882 - specificity: 0.9997\n","Epoch 00021: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0023 - acc: 0.9993 - dice_coef: 0.6214 - precision: 0.8167 - sensitivity: 0.7856 - specificity: 0.9997 - val_loss: 0.0030 - val_acc: 0.9990 - val_dice_coef: 0.6174 - val_precision: 0.8839 - val_sensitivity: 0.6491 - val_specificity: 0.9998\n","Epoch 22/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992 - dice_coef: 0.6319 - precision: 0.8113 - sensitivity: 0.7850 - specificity: 0.9996\n","Epoch 00022: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0023 - acc: 0.9992 - dice_coef: 0.6329 - precision: 0.8128 - sensitivity: 0.7839 - specificity: 0.9996 - val_loss: 0.0024 - val_acc: 0.9992 - val_dice_coef: 0.6716 - val_precision: 0.8502 - val_sensitivity: 0.7658 - val_specificity: 0.9997\n","Epoch 23/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993 - dice_coef: 0.6483 - precision: 0.8224 - sensitivity: 0.7978 - specificity: 0.9997\n","Epoch 00023: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0021 - acc: 0.9993 - dice_coef: 0.6491 - precision: 0.8222 - sensitivity: 0.7985 - specificity: 0.9997 - val_loss: 0.0027 - val_acc: 0.9990 - val_dice_coef: 0.6873 - val_precision: 0.7446 - val_sensitivity: 0.8765 - val_specificity: 0.9993\n","Epoch 24/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993 - dice_coef: 0.6534 - precision: 0.8134 - sensitivity: 0.8000 - specificity: 0.9997\n","Epoch 00024: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0021 - acc: 0.9993 - dice_coef: 0.6547 - precision: 0.8156 - sensitivity: 0.7993 - specificity: 0.9997 - val_loss: 0.0023 - val_acc: 0.9992 - val_dice_coef: 0.6870 - val_precision: 0.7880 - val_sensitivity: 0.8390 - val_specificity: 0.9995\n","Epoch 25/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.6668 - precision: 0.8273 - sensitivity: 0.8061 - specificity: 0.9997\n","Epoch 00025: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.6675 - precision: 0.8265 - sensitivity: 0.8078 - specificity: 0.9997 - val_loss: 0.0027 - val_acc: 0.9990 - val_dice_coef: 0.6984 - val_precision: 0.7135 - val_sensitivity: 0.9041 - val_specificity: 0.9992\n","Epoch 26/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.6676 - precision: 0.8299 - sensitivity: 0.8050 - specificity: 0.9997\n","Epoch 00026: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0020 - acc: 0.9993 - dice_coef: 0.6666 - precision: 0.8287 - sensitivity: 0.8041 - specificity: 0.9997 - val_loss: 0.0023 - val_acc: 0.9992 - val_dice_coef: 0.6999 - val_precision: 0.7777 - val_sensitivity: 0.8386 - val_specificity: 0.9995\n","Epoch 27/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.6894 - precision: 0.8388 - sensitivity: 0.8136 - specificity: 0.9997\n","Epoch 00027: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0019 - acc: 0.9993 - dice_coef: 0.6902 - precision: 0.8396 - sensitivity: 0.8128 - specificity: 0.9997 - val_loss: 0.0023 - val_acc: 0.9991 - val_dice_coef: 0.7047 - val_precision: 0.7537 - val_sensitivity: 0.8637 - val_specificity: 0.9994\n","Epoch 28/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9994 - dice_coef: 0.6914 - precision: 0.8326 - sensitivity: 0.8203 - specificity: 0.9997\n","Epoch 00028: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.6930 - precision: 0.8322 - sensitivity: 0.8215 - specificity: 0.9997 - val_loss: 0.0023 - val_acc: 0.9992 - val_dice_coef: 0.6768 - val_precision: 0.8596 - val_sensitivity: 0.7150 - val_specificity: 0.9997\n","Epoch 29/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9994 - dice_coef: 0.7013 - precision: 0.8417 - sensitivity: 0.8144 - specificity: 0.9997\n","Epoch 00029: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0018 - acc: 0.9994 - dice_coef: 0.7003 - precision: 0.8416 - sensitivity: 0.8137 - specificity: 0.9997 - val_loss: 0.0022 - val_acc: 0.9992 - val_dice_coef: 0.7219 - val_precision: 0.7921 - val_sensitivity: 0.8455 - val_specificity: 0.9995\n","Epoch 30/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.6987 - precision: 0.8380 - sensitivity: 0.8109 - specificity: 0.9997\n","Epoch 00030: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.6985 - precision: 0.8376 - sensitivity: 0.8117 - specificity: 0.9997 - val_loss: 0.0021 - val_acc: 0.9992 - val_dice_coef: 0.7014 - val_precision: 0.8403 - val_sensitivity: 0.7830 - val_specificity: 0.9997\n","Epoch 31/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.7164 - precision: 0.8478 - sensitivity: 0.8266 - specificity: 0.9997\n","Epoch 00031: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.7166 - precision: 0.8482 - sensitivity: 0.8262 - specificity: 0.9997 - val_loss: 0.0022 - val_acc: 0.9992 - val_dice_coef: 0.7011 - val_precision: 0.8348 - val_sensitivity: 0.7665 - val_specificity: 0.9997\n","Epoch 32/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.7253 - precision: 0.8464 - sensitivity: 0.8339 - specificity: 0.9997\n","Epoch 00032: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.7255 - precision: 0.8466 - sensitivity: 0.8335 - specificity: 0.9997 - val_loss: 0.0020 - val_acc: 0.9992 - val_dice_coef: 0.7290 - val_precision: 0.8413 - val_sensitivity: 0.7961 - val_specificity: 0.9997\n","Epoch 33/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.7121 - precision: 0.8396 - sensitivity: 0.8168 - specificity: 0.9997\n","Epoch 00033: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.7120 - precision: 0.8390 - sensitivity: 0.8175 - specificity: 0.9997 - val_loss: 0.0022 - val_acc: 0.9992 - val_dice_coef: 0.6852 - val_precision: 0.8339 - val_sensitivity: 0.7293 - val_specificity: 0.9997\n","Epoch 34/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.7185 - precision: 0.8398 - sensitivity: 0.8247 - specificity: 0.9997\n","Epoch 00034: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0017 - acc: 0.9994 - dice_coef: 0.7202 - precision: 0.8409 - sensitivity: 0.8255 - specificity: 0.9997 - val_loss: 0.0021 - val_acc: 0.9992 - val_dice_coef: 0.7254 - val_precision: 0.7781 - val_sensitivity: 0.8449 - val_specificity: 0.9995\n","Epoch 35/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.7384 - precision: 0.8549 - sensitivity: 0.8361 - specificity: 0.9997\n","Epoch 00035: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0016 - acc: 0.9994 - dice_coef: 0.7367 - precision: 0.8556 - sensitivity: 0.8328 - specificity: 0.9997 - val_loss: 0.0022 - val_acc: 0.9992 - val_dice_coef: 0.7117 - val_precision: 0.8682 - val_sensitivity: 0.7267 - val_specificity: 0.9997\n","Epoch 36/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.7470 - precision: 0.8515 - sensitivity: 0.8467 - specificity: 0.9997\n","Epoch 00036: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.7473 - precision: 0.8528 - sensitivity: 0.8456 - specificity: 0.9997 - val_loss: 0.0023 - val_acc: 0.9991 - val_dice_coef: 0.7376 - val_precision: 0.7522 - val_sensitivity: 0.8928 - val_specificity: 0.9993\n","Epoch 37/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.7423 - precision: 0.8514 - sensitivity: 0.8386 - specificity: 0.9997\n","Epoch 00037: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0015 - acc: 0.9994 - dice_coef: 0.7410 - precision: 0.8512 - sensitivity: 0.8364 - specificity: 0.9997 - val_loss: 0.0022 - val_acc: 0.9991 - val_dice_coef: 0.7465 - val_precision: 0.7645 - val_sensitivity: 0.8877 - val_specificity: 0.9994\n","Epoch 38/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.7593 - precision: 0.8633 - sensitivity: 0.8472 - specificity: 0.9997\n","Epoch 00038: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.7595 - precision: 0.8638 - sensitivity: 0.8469 - specificity: 0.9997 - val_loss: 0.0020 - val_acc: 0.9992 - val_dice_coef: 0.7499 - val_precision: 0.8377 - val_sensitivity: 0.8113 - val_specificity: 0.9997\n","Epoch 39/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.7715 - precision: 0.8702 - sensitivity: 0.8505 - specificity: 0.9997\n","Epoch 00039: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.7682 - precision: 0.8656 - sensitivity: 0.8509 - specificity: 0.9997 - val_loss: 0.0022 - val_acc: 0.9992 - val_dice_coef: 0.7556 - val_precision: 0.7694 - val_sensitivity: 0.8828 - val_specificity: 0.9994\n","Epoch 40/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.7600 - precision: 0.8578 - sensitivity: 0.8473 - specificity: 0.9997\n","Epoch 00040: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.7615 - precision: 0.8591 - sensitivity: 0.8476 - specificity: 0.9997 - val_loss: 0.0020 - val_acc: 0.9992 - val_dice_coef: 0.7555 - val_precision: 0.8341 - val_sensitivity: 0.8117 - val_specificity: 0.9996\n","Epoch 41/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9994 - dice_coef: 0.7643 - precision: 0.8573 - sensitivity: 0.8477 - specificity: 0.9997\n","Epoch 00041: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0014 - acc: 0.9994 - dice_coef: 0.7651 - precision: 0.8580 - sensitivity: 0.8479 - specificity: 0.9997 - val_loss: 0.0029 - val_acc: 0.9990 - val_dice_coef: 0.6969 - val_precision: 0.9311 - val_sensitivity: 0.6171 - val_specificity: 0.9999\n","Epoch 42/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.7759 - precision: 0.8649 - sensitivity: 0.8553 - specificity: 0.9997\n","Epoch 00042: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0014 - acc: 0.9995 - dice_coef: 0.7773 - precision: 0.8661 - sensitivity: 0.8561 - specificity: 0.9997 - val_loss: 0.0021 - val_acc: 0.9992 - val_dice_coef: 0.7619 - val_precision: 0.8164 - val_sensitivity: 0.8275 - val_specificity: 0.9996\n","Epoch 43/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7806 - precision: 0.8679 - sensitivity: 0.8620 - specificity: 0.9998\n","Epoch 00043: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 20s 10ms/sample - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7809 - precision: 0.8687 - sensitivity: 0.8613 - specificity: 0.9998 - val_loss: 0.0020 - val_acc: 0.9992 - val_dice_coef: 0.7391 - val_precision: 0.8486 - val_sensitivity: 0.7787 - val_specificity: 0.9997\n","Epoch 44/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9994 - dice_coef: 0.7686 - precision: 0.8592 - sensitivity: 0.8533 - specificity: 0.9997\n","Epoch 00044: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0014 - acc: 0.9994 - dice_coef: 0.7653 - precision: 0.8603 - sensitivity: 0.8481 - specificity: 0.9997 - val_loss: 0.0022 - val_acc: 0.9992 - val_dice_coef: 0.7257 - val_precision: 0.8982 - val_sensitivity: 0.7090 - val_specificity: 0.9998\n","Epoch 45/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7754 - precision: 0.8658 - sensitivity: 0.8558 - specificity: 0.9997\n","Epoch 00045: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7746 - precision: 0.8658 - sensitivity: 0.8543 - specificity: 0.9998 - val_loss: 0.0022 - val_acc: 0.9992 - val_dice_coef: 0.7279 - val_precision: 0.8700 - val_sensitivity: 0.7337 - val_specificity: 0.9998\n","Epoch 46/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7853 - precision: 0.8717 - sensitivity: 0.8597 - specificity: 0.9998\n","Epoch 00046: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7854 - precision: 0.8722 - sensitivity: 0.8607 - specificity: 0.9998 - val_loss: 0.0020 - val_acc: 0.9993 - val_dice_coef: 0.7499 - val_precision: 0.8784 - val_sensitivity: 0.7578 - val_specificity: 0.9998\n","Epoch 47/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7827 - precision: 0.8691 - sensitivity: 0.8610 - specificity: 0.9998\n","Epoch 00047: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7832 - precision: 0.8695 - sensitivity: 0.8609 - specificity: 0.9998 - val_loss: 0.0021 - val_acc: 0.9992 - val_dice_coef: 0.7505 - val_precision: 0.8604 - val_sensitivity: 0.7737 - val_specificity: 0.9997\n","Epoch 48/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7907 - precision: 0.8714 - sensitivity: 0.8629 - specificity: 0.9998\n","Epoch 00048: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.7900 - precision: 0.8722 - sensitivity: 0.8608 - specificity: 0.9998 - val_loss: 0.0021 - val_acc: 0.9992 - val_dice_coef: 0.7390 - val_precision: 0.8739 - val_sensitivity: 0.7327 - val_specificity: 0.9998\n","Epoch 49/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.7920 - precision: 0.8660 - sensitivity: 0.8715 - specificity: 0.9998\n","Epoch 00049: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.7919 - precision: 0.8658 - sensitivity: 0.8715 - specificity: 0.9998 - val_loss: 0.0019 - val_acc: 0.9993 - val_dice_coef: 0.7629 - val_precision: 0.8455 - val_sensitivity: 0.8085 - val_specificity: 0.9997\n","Epoch 50/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.7950 - precision: 0.8732 - sensitivity: 0.8651 - specificity: 0.9998\n","Epoch 00050: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.7964 - precision: 0.8744 - sensitivity: 0.8657 - specificity: 0.9998 - val_loss: 0.0019 - val_acc: 0.9993 - val_dice_coef: 0.7642 - val_precision: 0.8376 - val_sensitivity: 0.8159 - val_specificity: 0.9997\n","Epoch 51/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.8056 - precision: 0.8779 - sensitivity: 0.8737 - specificity: 0.9998\n","Epoch 00051: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.8063 - precision: 0.8785 - sensitivity: 0.8738 - specificity: 0.9998 - val_loss: 0.0019 - val_acc: 0.9992 - val_dice_coef: 0.7718 - val_precision: 0.8128 - val_sensitivity: 0.8414 - val_specificity: 0.9996\n","Epoch 52/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.8079 - precision: 0.8790 - sensitivity: 0.8785 - specificity: 0.9998\n","Epoch 00052: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.8071 - precision: 0.8766 - sensitivity: 0.8796 - specificity: 0.9998 - val_loss: 0.0025 - val_acc: 0.9991 - val_dice_coef: 0.7251 - val_precision: 0.9164 - val_sensitivity: 0.6643 - val_specificity: 0.9999\n","Epoch 53/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.8058 - precision: 0.8785 - sensitivity: 0.8740 - specificity: 0.9998\n","Epoch 00053: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0012 - acc: 0.9995 - dice_coef: 0.8056 - precision: 0.8780 - sensitivity: 0.8744 - specificity: 0.9998 - val_loss: 0.0023 - val_acc: 0.9992 - val_dice_coef: 0.7474 - val_precision: 0.8753 - val_sensitivity: 0.7277 - val_specificity: 0.9998\n","Epoch 54/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9995 - dice_coef: 0.8140 - precision: 0.8831 - sensitivity: 0.8781 - specificity: 0.9998\n","Epoch 00054: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0011 - acc: 0.9995 - dice_coef: 0.8137 - precision: 0.8832 - sensitivity: 0.8777 - specificity: 0.9998 - val_loss: 0.0020 - val_acc: 0.9993 - val_dice_coef: 0.7462 - val_precision: 0.8753 - val_sensitivity: 0.7350 - val_specificity: 0.9998\n","Epoch 55/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8261 - precision: 0.8917 - sensitivity: 0.8871 - specificity: 0.9998\n","Epoch 00055: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8238 - precision: 0.8906 - sensitivity: 0.8881 - specificity: 0.9998 - val_loss: 0.0019 - val_acc: 0.9993 - val_dice_coef: 0.7913 - val_precision: 0.8484 - val_sensitivity: 0.8245 - val_specificity: 0.9997\n","Epoch 56/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8218 - precision: 0.8859 - sensitivity: 0.8835 - specificity: 0.9998\n","Epoch 00056: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8219 - precision: 0.8864 - sensitivity: 0.8831 - specificity: 0.9998 - val_loss: 0.0021 - val_acc: 0.9992 - val_dice_coef: 0.7613 - val_precision: 0.8760 - val_sensitivity: 0.7590 - val_specificity: 0.9997\n","Epoch 57/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8204 - precision: 0.8857 - sensitivity: 0.8839 - specificity: 0.9998\n","Epoch 00057: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8190 - precision: 0.8845 - sensitivity: 0.8829 - specificity: 0.9998 - val_loss: 0.0022 - val_acc: 0.9992 - val_dice_coef: 0.7545 - val_precision: 0.8777 - val_sensitivity: 0.7369 - val_specificity: 0.9998\n","Epoch 58/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8219 - precision: 0.8867 - sensitivity: 0.8813 - specificity: 0.9998\n","Epoch 00058: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8212 - precision: 0.8863 - sensitivity: 0.8813 - specificity: 0.9998 - val_loss: 0.0020 - val_acc: 0.9993 - val_dice_coef: 0.7776 - val_precision: 0.8324 - val_sensitivity: 0.8127 - val_specificity: 0.9996\n","Epoch 59/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9996 - dice_coef: 0.8322 - precision: 0.8918 - sensitivity: 0.8923 - specificity: 0.9998\n","Epoch 00059: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0010 - acc: 0.9996 - dice_coef: 0.8316 - precision: 0.8921 - sensitivity: 0.8915 - specificity: 0.9998 - val_loss: 0.0020 - val_acc: 0.9992 - val_dice_coef: 0.7747 - val_precision: 0.8480 - val_sensitivity: 0.7958 - val_specificity: 0.9997\n","Epoch 60/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8269 - precision: 0.8907 - sensitivity: 0.8845 - specificity: 0.9998\n","Epoch 00060: saving model to drive/My Drive/MS_data/Modified_UNet_intersection.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0011 - acc: 0.9996 - dice_coef: 0.8230 - precision: 0.8864 - sensitivity: 0.8855 - specificity: 0.9998 - val_loss: 0.0021 - val_acc: 0.9992 - val_dice_coef: 0.7843 - val_precision: 0.7808 - val_sensitivity: 0.8746 - val_specificity: 0.9995\n","2499/2499 [==============================] - 8s 3ms/sample - loss: 0.0013 - acc: 0.9995 - dice_coef: 0.8152 - precision: 0.8220 - sensitivity: 0.9128 - specificity: 0.9996\n","441/441 [==============================] - 2s 4ms/sample - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.7734 - precision: 0.7836 - sensitivity: 0.8558 - specificity: 0.9995\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.001962868071503329, 0.999233, 0.77337795, 0.7836261, 0.85580677, 0.99952596]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"35wJF77Spb1H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GDxk6QIHpd6w","colab_type":"text"},"source":["# **MAJORITY MODEL RESULTS**"]},{"cell_type":"code","metadata":{"id":"_z0vdW3mpnJP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"outputId":"4701237d-e094-488b-86ba-e00ae41eb339","executionInfo":{"status":"ok","timestamp":1585224197212,"user_tz":-330,"elapsed":3646,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import nibabel as nib\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","    \n","def modality(Path,index):\n","    X = []\n","    p=os.listdir(Path) \n","\n","    for i in p[:14]:                                                                      # Loading all the folders in the given path\n","        q = os.listdir(os.path.join(Path,i))     \n","\n","        x = nib.load(os.path.join(Path,i,q[index]))         \n","        f = x.get_fdata()\n","        f = np.asarray(f,'float32')\n","        \n","        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n","            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n","            if(index not in [3,4,5,6,7,8,9] and np.sum(_slice) != 0 ):  \n","                print(\"DONE\")                                         # To check whether the slice is null or not\n","              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n","                _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n","            elif(index in [3,4,5,6,7,8,9]):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n","                _slice = np.array(_slice)\n","                _slice[_slice > 0] = 1.0\n","                _slice[_slice < 0] = 0.0\n","            _slice = _slice.T\n","            _slice = _slice[:,:,np.newaxis]\n","            X.append(_slice)\n","   # X=np.array(X,dtype='float32')\n","    return X"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"eTp4Kjx_qqUf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"bf0430d7-2eba-4262-83e7-33c4e3cbbd48","executionInfo":{"status":"ok","timestamp":1585225199422,"user_tz":-330,"elapsed":1406,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["from keras import backend as K\n","import numpy as np\n","import tensorflow as tf\n","\n","# Computing Dice_Coefficient\n","def dice_coef(y_true, y_pred, smooth=1.0):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","# Computing Precision \n","def precision(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","# Computing Sensitivity      \n","def sensitivity(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    return true_positives / (possible_positives + K.epsilon())\n","\n","# Computing Specificity\n","def specificity(y_true, y_pred):\n","    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n","    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n","    return true_negatives / (possible_negatives + K.epsilon())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Jpo993eiqyvf","colab_type":"code","colab":{}},"source":["def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual): \n","     \n","    X=[]\n","    Y=[]\n","    \n","    for i in range(len(X_Dp)):        \n","        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n","        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n","            X.append(final_slice)\n","            Y.append(Y_Manual[i])\n"," \n","#   Converting the list into array  \n","    X=np.array(X,dtype='float32')\n","    Y=np.array(Y,dtype='float32')\n","    \n","    return X,Y\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kYbXtHyq7J3","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","import keras\n","from keras.models import Model, load_model\n","from keras.layers import Input ,BatchNormalization , Activation \n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.merge import concatenate\n","\n","\n","def Convolution(input_tensor,filters):\n","    \n","    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x) \n","    return x\n","\n","def model(input_shape):\n","    \n","    inputs = Input((input_shape))\n","    \n","    conv_1 = Convolution(inputs,32)\n","    \n","    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)\n","    \n","    conv_2 = Convolution(maxp_1,64)\n","    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)\n","    \n","    conv_3 = Convolution(maxp_2,128)\n","    \n","    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)\n","    \n","    conv_4 = Convolution(maxp_3,256)\n","    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)\n","    \n","    conv_5 = Convolution(maxp_4,512)\n","   \n","    upsample_6 = UpSampling2D((2, 2)) (conv_5)\n","\n","    upsample_6 = concatenate([upsample_6, conv_4])\n","    \n","    conv_6 = Convolution(upsample_6,256)\n","    upsample_7 = UpSampling2D((2, 2)) (conv_6)\n","    \n","    upsample_7 = concatenate([upsample_7, conv_3])\n","    \n","    conv_7 = Convolution(upsample_7,128)\n","    upsample_8 = UpSampling2D((2, 2)) (conv_7)\n","    \n","    upsample_8 = concatenate([upsample_8, conv_2])\n","\n","    conv_8 = Convolution(upsample_8,64)\n","    upsample_9 = UpSampling2D((2, 2)) (conv_8)\n","    \n","    upsample_9 = concatenate([upsample_9, conv_1])\n","    \n","    conv_9 = Convolution(upsample_9,32)\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)\n","    \n","    model = Model(inputs=[inputs], outputs=[outputs]) \n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M9gGVQK9q8Gm","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","#import dataPrepare as process\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n","#import Modified_UNet \n","#import plots\n","#import Metrics\n","\n","# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","\n","\n","\n","# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n","Y_1  =   modality(Path,3)\n","Y_2  =   modality(Path,4)\n","Y_3  =   modality(Path,5)\n","Y_4  =   modality(Path,6)\n","Y_5  =   modality(Path,7)\n","Y_6  =   modality(Path,8)\n","Y_7  =   modality(Path,9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzDH-wadrEdM","colab_type":"code","colab":{}},"source":["import math\n","def Major(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7):\n","  Y=[]\n","  sum2=[]\n","  flag=0\n","  #y=np.array()\n","  print(\"A\")\n","  for i in range (len(Y_1)):\n","    #print(Y_1[i])\n","    \n","        f=np.concatenate((Y_1[i],Y_2[i],Y_3[i],Y_4[i],Y_5[i],Y_6[i],Y_7[i]),axis=-1)\n","        sum=np.sum(f,axis=2)\n","       # print(sum)\n","        \n","          #print(j)\n","        sum_1=np.divide(sum,4)\n","        sum_1=np.floor(sum_1)\n","        sum2.append(sum_1)\n","\n","    #sum2=np.array(sum2,dtype='float32')\n","    \n","        \n","  return sum2\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jp1pJKw7rHgX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"3160e4bb-5d6b-49bd-ee16-21e57ea00915","executionInfo":{"status":"ok","timestamp":1585224034755,"user_tz":-330,"elapsed":15360,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["Y_Manual=Major(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7)\n","\n","\n","print(len(Y_Manual))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["A\n","5184\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pPOOOklerJxC","colab_type":"code","colab":{}},"source":["Y=np.array(Y_Manual,dtype='float32')\n","np.save(\"drive/My Drive/MS_data/Y_manual_Major.npy\",Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"txyPylCzrLz3","colab_type":"code","colab":{}},"source":["# Setting the path\n","Path='drive/My Drive/Pre-processed'\n","X_Dp_t      =   modality(Path,0)\n","X_Flair_t   =   modality(Path,1)\n","X_Gado_t    =   modality(Path,2)\n","X_T1_t      =   modality(Path,10)\n","X_T2_t      =   modality(Path,11)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vn6QW251rSHg","colab_type":"code","colab":{}},"source":["\n","Y=np.load(\"drive/My Drive/MS_data/Y_manual_Major.npy\")\n","Y_Manual=list(Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LS0fmV9Frd_z","colab_type":"code","colab":{}},"source":["X, Y = remove_null_samples(X_Dp_t, X_Flair_t, X_Gado_t, X_T1_t, X_T2_t, Y_Manual)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-cbgT987rgBQ","colab_type":"code","colab":{}},"source":["def store_data(X,Y):\n","    np.save(\"drive/My Drive/MS_data/X_Major.npy\",X)\n","    np.save(\"drive/My Drive/MS_data/Y_Major.npy\",Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8-yNup-rh_v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"699c5580-9018-4b0b-85a5-840cb5cfad4a","executionInfo":{"status":"ok","timestamp":1585224427002,"user_tz":-330,"elapsed":87312,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["print(len(Y))\n","store_data(X,Y)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2940\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q7pRGkW7rqEj","colab_type":"code","colab":{}},"source":["import numpy as np\n","#X=np.load(\"drive/My Drive/MS_data/X_Major.npy\")\n","Y=np.load(\"drive/My Drive/MS_data/Y_Major.npy\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-tcQRxkhrrTU","colab_type":"code","colab":{}},"source":["Y=list(Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sHAVyfhrxJN","colab_type":"code","colab":{}},"source":["Y_1=Y[:1401]\n","Y_2=Y[1401:]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UC6F6ZwRry0q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"eb7a6477-d6ed-4f3a-fad7-8bf2ec76c411","executionInfo":{"status":"ok","timestamp":1585224508644,"user_tz":-330,"elapsed":70622,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["p=[]\n","y=[]\n","z=[]\n","a=[]\n","n=1\n","for i in Y_1:\n","  print(n)\n","  for j in i:\n","    for k in j:\n","      #print(k)\n","      a.append(k)\n","     # print(a)\n","      z.append(a)\n","      a=[]\n","    #print(z)\n","    y.append(z)\n","    z=[]\n","  p.append(y)\n","  y=[]\n","  n+=1"],"execution_count":14,"outputs":[{"output_type":"stream","text":["1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","511\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n","540\n","541\n","542\n","543\n","544\n","545\n","546\n","547\n","548\n","549\n","550\n","551\n","552\n","553\n","554\n","555\n","556\n","557\n","558\n","559\n","560\n","561\n","562\n","563\n","564\n","565\n","566\n","567\n","568\n","569\n","570\n","571\n","572\n","573\n","574\n","575\n","576\n","577\n","578\n","579\n","580\n","581\n","582\n","583\n","584\n","585\n","586\n","587\n","588\n","589\n","590\n","591\n","592\n","593\n","594\n","595\n","596\n","597\n","598\n","599\n","600\n","601\n","602\n","603\n","604\n","605\n","606\n","607\n","608\n","609\n","610\n","611\n","612\n","613\n","614\n","615\n","616\n","617\n","618\n","619\n","620\n","621\n","622\n","623\n","624\n","625\n","626\n","627\n","628\n","629\n","630\n","631\n","632\n","633\n","634\n","635\n","636\n","637\n","638\n","639\n","640\n","641\n","642\n","643\n","644\n","645\n","646\n","647\n","648\n","649\n","650\n","651\n","652\n","653\n","654\n","655\n","656\n","657\n","658\n","659\n","660\n","661\n","662\n","663\n","664\n","665\n","666\n","667\n","668\n","669\n","670\n","671\n","672\n","673\n","674\n","675\n","676\n","677\n","678\n","679\n","680\n","681\n","682\n","683\n","684\n","685\n","686\n","687\n","688\n","689\n","690\n","691\n","692\n","693\n","694\n","695\n","696\n","697\n","698\n","699\n","700\n","701\n","702\n","703\n","704\n","705\n","706\n","707\n","708\n","709\n","710\n","711\n","712\n","713\n","714\n","715\n","716\n","717\n","718\n","719\n","720\n","721\n","722\n","723\n","724\n","725\n","726\n","727\n","728\n","729\n","730\n","731\n","732\n","733\n","734\n","735\n","736\n","737\n","738\n","739\n","740\n","741\n","742\n","743\n","744\n","745\n","746\n","747\n","748\n","749\n","750\n","751\n","752\n","753\n","754\n","755\n","756\n","757\n","758\n","759\n","760\n","761\n","762\n","763\n","764\n","765\n","766\n","767\n","768\n","769\n","770\n","771\n","772\n","773\n","774\n","775\n","776\n","777\n","778\n","779\n","780\n","781\n","782\n","783\n","784\n","785\n","786\n","787\n","788\n","789\n","790\n","791\n","792\n","793\n","794\n","795\n","796\n","797\n","798\n","799\n","800\n","801\n","802\n","803\n","804\n","805\n","806\n","807\n","808\n","809\n","810\n","811\n","812\n","813\n","814\n","815\n","816\n","817\n","818\n","819\n","820\n","821\n","822\n","823\n","824\n","825\n","826\n","827\n","828\n","829\n","830\n","831\n","832\n","833\n","834\n","835\n","836\n","837\n","838\n","839\n","840\n","841\n","842\n","843\n","844\n","845\n","846\n","847\n","848\n","849\n","850\n","851\n","852\n","853\n","854\n","855\n","856\n","857\n","858\n","859\n","860\n","861\n","862\n","863\n","864\n","865\n","866\n","867\n","868\n","869\n","870\n","871\n","872\n","873\n","874\n","875\n","876\n","877\n","878\n","879\n","880\n","881\n","882\n","883\n","884\n","885\n","886\n","887\n","888\n","889\n","890\n","891\n","892\n","893\n","894\n","895\n","896\n","897\n","898\n","899\n","900\n","901\n","902\n","903\n","904\n","905\n","906\n","907\n","908\n","909\n","910\n","911\n","912\n","913\n","914\n","915\n","916\n","917\n","918\n","919\n","920\n","921\n","922\n","923\n","924\n","925\n","926\n","927\n","928\n","929\n","930\n","931\n","932\n","933\n","934\n","935\n","936\n","937\n","938\n","939\n","940\n","941\n","942\n","943\n","944\n","945\n","946\n","947\n","948\n","949\n","950\n","951\n","952\n","953\n","954\n","955\n","956\n","957\n","958\n","959\n","960\n","961\n","962\n","963\n","964\n","965\n","966\n","967\n","968\n","969\n","970\n","971\n","972\n","973\n","974\n","975\n","976\n","977\n","978\n","979\n","980\n","981\n","982\n","983\n","984\n","985\n","986\n","987\n","988\n","989\n","990\n","991\n","992\n","993\n","994\n","995\n","996\n","997\n","998\n","999\n","1000\n","1001\n","1002\n","1003\n","1004\n","1005\n","1006\n","1007\n","1008\n","1009\n","1010\n","1011\n","1012\n","1013\n","1014\n","1015\n","1016\n","1017\n","1018\n","1019\n","1020\n","1021\n","1022\n","1023\n","1024\n","1025\n","1026\n","1027\n","1028\n","1029\n","1030\n","1031\n","1032\n","1033\n","1034\n","1035\n","1036\n","1037\n","1038\n","1039\n","1040\n","1041\n","1042\n","1043\n","1044\n","1045\n","1046\n","1047\n","1048\n","1049\n","1050\n","1051\n","1052\n","1053\n","1054\n","1055\n","1056\n","1057\n","1058\n","1059\n","1060\n","1061\n","1062\n","1063\n","1064\n","1065\n","1066\n","1067\n","1068\n","1069\n","1070\n","1071\n","1072\n","1073\n","1074\n","1075\n","1076\n","1077\n","1078\n","1079\n","1080\n","1081\n","1082\n","1083\n","1084\n","1085\n","1086\n","1087\n","1088\n","1089\n","1090\n","1091\n","1092\n","1093\n","1094\n","1095\n","1096\n","1097\n","1098\n","1099\n","1100\n","1101\n","1102\n","1103\n","1104\n","1105\n","1106\n","1107\n","1108\n","1109\n","1110\n","1111\n","1112\n","1113\n","1114\n","1115\n","1116\n","1117\n","1118\n","1119\n","1120\n","1121\n","1122\n","1123\n","1124\n","1125\n","1126\n","1127\n","1128\n","1129\n","1130\n","1131\n","1132\n","1133\n","1134\n","1135\n","1136\n","1137\n","1138\n","1139\n","1140\n","1141\n","1142\n","1143\n","1144\n","1145\n","1146\n","1147\n","1148\n","1149\n","1150\n","1151\n","1152\n","1153\n","1154\n","1155\n","1156\n","1157\n","1158\n","1159\n","1160\n","1161\n","1162\n","1163\n","1164\n","1165\n","1166\n","1167\n","1168\n","1169\n","1170\n","1171\n","1172\n","1173\n","1174\n","1175\n","1176\n","1177\n","1178\n","1179\n","1180\n","1181\n","1182\n","1183\n","1184\n","1185\n","1186\n","1187\n","1188\n","1189\n","1190\n","1191\n","1192\n","1193\n","1194\n","1195\n","1196\n","1197\n","1198\n","1199\n","1200\n","1201\n","1202\n","1203\n","1204\n","1205\n","1206\n","1207\n","1208\n","1209\n","1210\n","1211\n","1212\n","1213\n","1214\n","1215\n","1216\n","1217\n","1218\n","1219\n","1220\n","1221\n","1222\n","1223\n","1224\n","1225\n","1226\n","1227\n","1228\n","1229\n","1230\n","1231\n","1232\n","1233\n","1234\n","1235\n","1236\n","1237\n","1238\n","1239\n","1240\n","1241\n","1242\n","1243\n","1244\n","1245\n","1246\n","1247\n","1248\n","1249\n","1250\n","1251\n","1252\n","1253\n","1254\n","1255\n","1256\n","1257\n","1258\n","1259\n","1260\n","1261\n","1262\n","1263\n","1264\n","1265\n","1266\n","1267\n","1268\n","1269\n","1270\n","1271\n","1272\n","1273\n","1274\n","1275\n","1276\n","1277\n","1278\n","1279\n","1280\n","1281\n","1282\n","1283\n","1284\n","1285\n","1286\n","1287\n","1288\n","1289\n","1290\n","1291\n","1292\n","1293\n","1294\n","1295\n","1296\n","1297\n","1298\n","1299\n","1300\n","1301\n","1302\n","1303\n","1304\n","1305\n","1306\n","1307\n","1308\n","1309\n","1310\n","1311\n","1312\n","1313\n","1314\n","1315\n","1316\n","1317\n","1318\n","1319\n","1320\n","1321\n","1322\n","1323\n","1324\n","1325\n","1326\n","1327\n","1328\n","1329\n","1330\n","1331\n","1332\n","1333\n","1334\n","1335\n","1336\n","1337\n","1338\n","1339\n","1340\n","1341\n","1342\n","1343\n","1344\n","1345\n","1346\n","1347\n","1348\n","1349\n","1350\n","1351\n","1352\n","1353\n","1354\n","1355\n","1356\n","1357\n","1358\n","1359\n","1360\n","1361\n","1362\n","1363\n","1364\n","1365\n","1366\n","1367\n","1368\n","1369\n","1370\n","1371\n","1372\n","1373\n","1374\n","1375\n","1376\n","1377\n","1378\n","1379\n","1380\n","1381\n","1382\n","1383\n","1384\n","1385\n","1386\n","1387\n","1388\n","1389\n","1390\n","1391\n","1392\n","1393\n","1394\n","1395\n","1396\n","1397\n","1398\n","1399\n","1400\n","1401\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q97J27Ilr02a","colab_type":"code","colab":{}},"source":["temp=np.array(p)\n","np.save(\"drive/My Drive/MS_data/temp_1_maj.npy\",temp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESq6o8lXr24u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0ec1b111-46e7-4560-c6e9-b11fd49ab382","executionInfo":{"status":"ok","timestamp":1585224921907,"user_tz":-330,"elapsed":80298,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["q=[]\n","y=[]\n","z=[]\n","a=[]\n","n=1401\n","for i in Y_2:\n","  print(n)\n","  for j in i:\n","    for k in j:\n","      #print(k)\n","      a.append(k)\n","     # print(a)\n","      z.append(a)\n","      a=[]\n","    #print(z)\n","    y.append(z)\n","    z=[]\n","  q.append(y)\n","  y=[]\n","  n+=1"],"execution_count":4,"outputs":[{"output_type":"stream","text":["1401\n","1402\n","1403\n","1404\n","1405\n","1406\n","1407\n","1408\n","1409\n","1410\n","1411\n","1412\n","1413\n","1414\n","1415\n","1416\n","1417\n","1418\n","1419\n","1420\n","1421\n","1422\n","1423\n","1424\n","1425\n","1426\n","1427\n","1428\n","1429\n","1430\n","1431\n","1432\n","1433\n","1434\n","1435\n","1436\n","1437\n","1438\n","1439\n","1440\n","1441\n","1442\n","1443\n","1444\n","1445\n","1446\n","1447\n","1448\n","1449\n","1450\n","1451\n","1452\n","1453\n","1454\n","1455\n","1456\n","1457\n","1458\n","1459\n","1460\n","1461\n","1462\n","1463\n","1464\n","1465\n","1466\n","1467\n","1468\n","1469\n","1470\n","1471\n","1472\n","1473\n","1474\n","1475\n","1476\n","1477\n","1478\n","1479\n","1480\n","1481\n","1482\n","1483\n","1484\n","1485\n","1486\n","1487\n","1488\n","1489\n","1490\n","1491\n","1492\n","1493\n","1494\n","1495\n","1496\n","1497\n","1498\n","1499\n","1500\n","1501\n","1502\n","1503\n","1504\n","1505\n","1506\n","1507\n","1508\n","1509\n","1510\n","1511\n","1512\n","1513\n","1514\n","1515\n","1516\n","1517\n","1518\n","1519\n","1520\n","1521\n","1522\n","1523\n","1524\n","1525\n","1526\n","1527\n","1528\n","1529\n","1530\n","1531\n","1532\n","1533\n","1534\n","1535\n","1536\n","1537\n","1538\n","1539\n","1540\n","1541\n","1542\n","1543\n","1544\n","1545\n","1546\n","1547\n","1548\n","1549\n","1550\n","1551\n","1552\n","1553\n","1554\n","1555\n","1556\n","1557\n","1558\n","1559\n","1560\n","1561\n","1562\n","1563\n","1564\n","1565\n","1566\n","1567\n","1568\n","1569\n","1570\n","1571\n","1572\n","1573\n","1574\n","1575\n","1576\n","1577\n","1578\n","1579\n","1580\n","1581\n","1582\n","1583\n","1584\n","1585\n","1586\n","1587\n","1588\n","1589\n","1590\n","1591\n","1592\n","1593\n","1594\n","1595\n","1596\n","1597\n","1598\n","1599\n","1600\n","1601\n","1602\n","1603\n","1604\n","1605\n","1606\n","1607\n","1608\n","1609\n","1610\n","1611\n","1612\n","1613\n","1614\n","1615\n","1616\n","1617\n","1618\n","1619\n","1620\n","1621\n","1622\n","1623\n","1624\n","1625\n","1626\n","1627\n","1628\n","1629\n","1630\n","1631\n","1632\n","1633\n","1634\n","1635\n","1636\n","1637\n","1638\n","1639\n","1640\n","1641\n","1642\n","1643\n","1644\n","1645\n","1646\n","1647\n","1648\n","1649\n","1650\n","1651\n","1652\n","1653\n","1654\n","1655\n","1656\n","1657\n","1658\n","1659\n","1660\n","1661\n","1662\n","1663\n","1664\n","1665\n","1666\n","1667\n","1668\n","1669\n","1670\n","1671\n","1672\n","1673\n","1674\n","1675\n","1676\n","1677\n","1678\n","1679\n","1680\n","1681\n","1682\n","1683\n","1684\n","1685\n","1686\n","1687\n","1688\n","1689\n","1690\n","1691\n","1692\n","1693\n","1694\n","1695\n","1696\n","1697\n","1698\n","1699\n","1700\n","1701\n","1702\n","1703\n","1704\n","1705\n","1706\n","1707\n","1708\n","1709\n","1710\n","1711\n","1712\n","1713\n","1714\n","1715\n","1716\n","1717\n","1718\n","1719\n","1720\n","1721\n","1722\n","1723\n","1724\n","1725\n","1726\n","1727\n","1728\n","1729\n","1730\n","1731\n","1732\n","1733\n","1734\n","1735\n","1736\n","1737\n","1738\n","1739\n","1740\n","1741\n","1742\n","1743\n","1744\n","1745\n","1746\n","1747\n","1748\n","1749\n","1750\n","1751\n","1752\n","1753\n","1754\n","1755\n","1756\n","1757\n","1758\n","1759\n","1760\n","1761\n","1762\n","1763\n","1764\n","1765\n","1766\n","1767\n","1768\n","1769\n","1770\n","1771\n","1772\n","1773\n","1774\n","1775\n","1776\n","1777\n","1778\n","1779\n","1780\n","1781\n","1782\n","1783\n","1784\n","1785\n","1786\n","1787\n","1788\n","1789\n","1790\n","1791\n","1792\n","1793\n","1794\n","1795\n","1796\n","1797\n","1798\n","1799\n","1800\n","1801\n","1802\n","1803\n","1804\n","1805\n","1806\n","1807\n","1808\n","1809\n","1810\n","1811\n","1812\n","1813\n","1814\n","1815\n","1816\n","1817\n","1818\n","1819\n","1820\n","1821\n","1822\n","1823\n","1824\n","1825\n","1826\n","1827\n","1828\n","1829\n","1830\n","1831\n","1832\n","1833\n","1834\n","1835\n","1836\n","1837\n","1838\n","1839\n","1840\n","1841\n","1842\n","1843\n","1844\n","1845\n","1846\n","1847\n","1848\n","1849\n","1850\n","1851\n","1852\n","1853\n","1854\n","1855\n","1856\n","1857\n","1858\n","1859\n","1860\n","1861\n","1862\n","1863\n","1864\n","1865\n","1866\n","1867\n","1868\n","1869\n","1870\n","1871\n","1872\n","1873\n","1874\n","1875\n","1876\n","1877\n","1878\n","1879\n","1880\n","1881\n","1882\n","1883\n","1884\n","1885\n","1886\n","1887\n","1888\n","1889\n","1890\n","1891\n","1892\n","1893\n","1894\n","1895\n","1896\n","1897\n","1898\n","1899\n","1900\n","1901\n","1902\n","1903\n","1904\n","1905\n","1906\n","1907\n","1908\n","1909\n","1910\n","1911\n","1912\n","1913\n","1914\n","1915\n","1916\n","1917\n","1918\n","1919\n","1920\n","1921\n","1922\n","1923\n","1924\n","1925\n","1926\n","1927\n","1928\n","1929\n","1930\n","1931\n","1932\n","1933\n","1934\n","1935\n","1936\n","1937\n","1938\n","1939\n","1940\n","1941\n","1942\n","1943\n","1944\n","1945\n","1946\n","1947\n","1948\n","1949\n","1950\n","1951\n","1952\n","1953\n","1954\n","1955\n","1956\n","1957\n","1958\n","1959\n","1960\n","1961\n","1962\n","1963\n","1964\n","1965\n","1966\n","1967\n","1968\n","1969\n","1970\n","1971\n","1972\n","1973\n","1974\n","1975\n","1976\n","1977\n","1978\n","1979\n","1980\n","1981\n","1982\n","1983\n","1984\n","1985\n","1986\n","1987\n","1988\n","1989\n","1990\n","1991\n","1992\n","1993\n","1994\n","1995\n","1996\n","1997\n","1998\n","1999\n","2000\n","2001\n","2002\n","2003\n","2004\n","2005\n","2006\n","2007\n","2008\n","2009\n","2010\n","2011\n","2012\n","2013\n","2014\n","2015\n","2016\n","2017\n","2018\n","2019\n","2020\n","2021\n","2022\n","2023\n","2024\n","2025\n","2026\n","2027\n","2028\n","2029\n","2030\n","2031\n","2032\n","2033\n","2034\n","2035\n","2036\n","2037\n","2038\n","2039\n","2040\n","2041\n","2042\n","2043\n","2044\n","2045\n","2046\n","2047\n","2048\n","2049\n","2050\n","2051\n","2052\n","2053\n","2054\n","2055\n","2056\n","2057\n","2058\n","2059\n","2060\n","2061\n","2062\n","2063\n","2064\n","2065\n","2066\n","2067\n","2068\n","2069\n","2070\n","2071\n","2072\n","2073\n","2074\n","2075\n","2076\n","2077\n","2078\n","2079\n","2080\n","2081\n","2082\n","2083\n","2084\n","2085\n","2086\n","2087\n","2088\n","2089\n","2090\n","2091\n","2092\n","2093\n","2094\n","2095\n","2096\n","2097\n","2098\n","2099\n","2100\n","2101\n","2102\n","2103\n","2104\n","2105\n","2106\n","2107\n","2108\n","2109\n","2110\n","2111\n","2112\n","2113\n","2114\n","2115\n","2116\n","2117\n","2118\n","2119\n","2120\n","2121\n","2122\n","2123\n","2124\n","2125\n","2126\n","2127\n","2128\n","2129\n","2130\n","2131\n","2132\n","2133\n","2134\n","2135\n","2136\n","2137\n","2138\n","2139\n","2140\n","2141\n","2142\n","2143\n","2144\n","2145\n","2146\n","2147\n","2148\n","2149\n","2150\n","2151\n","2152\n","2153\n","2154\n","2155\n","2156\n","2157\n","2158\n","2159\n","2160\n","2161\n","2162\n","2163\n","2164\n","2165\n","2166\n","2167\n","2168\n","2169\n","2170\n","2171\n","2172\n","2173\n","2174\n","2175\n","2176\n","2177\n","2178\n","2179\n","2180\n","2181\n","2182\n","2183\n","2184\n","2185\n","2186\n","2187\n","2188\n","2189\n","2190\n","2191\n","2192\n","2193\n","2194\n","2195\n","2196\n","2197\n","2198\n","2199\n","2200\n","2201\n","2202\n","2203\n","2204\n","2205\n","2206\n","2207\n","2208\n","2209\n","2210\n","2211\n","2212\n","2213\n","2214\n","2215\n","2216\n","2217\n","2218\n","2219\n","2220\n","2221\n","2222\n","2223\n","2224\n","2225\n","2226\n","2227\n","2228\n","2229\n","2230\n","2231\n","2232\n","2233\n","2234\n","2235\n","2236\n","2237\n","2238\n","2239\n","2240\n","2241\n","2242\n","2243\n","2244\n","2245\n","2246\n","2247\n","2248\n","2249\n","2250\n","2251\n","2252\n","2253\n","2254\n","2255\n","2256\n","2257\n","2258\n","2259\n","2260\n","2261\n","2262\n","2263\n","2264\n","2265\n","2266\n","2267\n","2268\n","2269\n","2270\n","2271\n","2272\n","2273\n","2274\n","2275\n","2276\n","2277\n","2278\n","2279\n","2280\n","2281\n","2282\n","2283\n","2284\n","2285\n","2286\n","2287\n","2288\n","2289\n","2290\n","2291\n","2292\n","2293\n","2294\n","2295\n","2296\n","2297\n","2298\n","2299\n","2300\n","2301\n","2302\n","2303\n","2304\n","2305\n","2306\n","2307\n","2308\n","2309\n","2310\n","2311\n","2312\n","2313\n","2314\n","2315\n","2316\n","2317\n","2318\n","2319\n","2320\n","2321\n","2322\n","2323\n","2324\n","2325\n","2326\n","2327\n","2328\n","2329\n","2330\n","2331\n","2332\n","2333\n","2334\n","2335\n","2336\n","2337\n","2338\n","2339\n","2340\n","2341\n","2342\n","2343\n","2344\n","2345\n","2346\n","2347\n","2348\n","2349\n","2350\n","2351\n","2352\n","2353\n","2354\n","2355\n","2356\n","2357\n","2358\n","2359\n","2360\n","2361\n","2362\n","2363\n","2364\n","2365\n","2366\n","2367\n","2368\n","2369\n","2370\n","2371\n","2372\n","2373\n","2374\n","2375\n","2376\n","2377\n","2378\n","2379\n","2380\n","2381\n","2382\n","2383\n","2384\n","2385\n","2386\n","2387\n","2388\n","2389\n","2390\n","2391\n","2392\n","2393\n","2394\n","2395\n","2396\n","2397\n","2398\n","2399\n","2400\n","2401\n","2402\n","2403\n","2404\n","2405\n","2406\n","2407\n","2408\n","2409\n","2410\n","2411\n","2412\n","2413\n","2414\n","2415\n","2416\n","2417\n","2418\n","2419\n","2420\n","2421\n","2422\n","2423\n","2424\n","2425\n","2426\n","2427\n","2428\n","2429\n","2430\n","2431\n","2432\n","2433\n","2434\n","2435\n","2436\n","2437\n","2438\n","2439\n","2440\n","2441\n","2442\n","2443\n","2444\n","2445\n","2446\n","2447\n","2448\n","2449\n","2450\n","2451\n","2452\n","2453\n","2454\n","2455\n","2456\n","2457\n","2458\n","2459\n","2460\n","2461\n","2462\n","2463\n","2464\n","2465\n","2466\n","2467\n","2468\n","2469\n","2470\n","2471\n","2472\n","2473\n","2474\n","2475\n","2476\n","2477\n","2478\n","2479\n","2480\n","2481\n","2482\n","2483\n","2484\n","2485\n","2486\n","2487\n","2488\n","2489\n","2490\n","2491\n","2492\n","2493\n","2494\n","2495\n","2496\n","2497\n","2498\n","2499\n","2500\n","2501\n","2502\n","2503\n","2504\n","2505\n","2506\n","2507\n","2508\n","2509\n","2510\n","2511\n","2512\n","2513\n","2514\n","2515\n","2516\n","2517\n","2518\n","2519\n","2520\n","2521\n","2522\n","2523\n","2524\n","2525\n","2526\n","2527\n","2528\n","2529\n","2530\n","2531\n","2532\n","2533\n","2534\n","2535\n","2536\n","2537\n","2538\n","2539\n","2540\n","2541\n","2542\n","2543\n","2544\n","2545\n","2546\n","2547\n","2548\n","2549\n","2550\n","2551\n","2552\n","2553\n","2554\n","2555\n","2556\n","2557\n","2558\n","2559\n","2560\n","2561\n","2562\n","2563\n","2564\n","2565\n","2566\n","2567\n","2568\n","2569\n","2570\n","2571\n","2572\n","2573\n","2574\n","2575\n","2576\n","2577\n","2578\n","2579\n","2580\n","2581\n","2582\n","2583\n","2584\n","2585\n","2586\n","2587\n","2588\n","2589\n","2590\n","2591\n","2592\n","2593\n","2594\n","2595\n","2596\n","2597\n","2598\n","2599\n","2600\n","2601\n","2602\n","2603\n","2604\n","2605\n","2606\n","2607\n","2608\n","2609\n","2610\n","2611\n","2612\n","2613\n","2614\n","2615\n","2616\n","2617\n","2618\n","2619\n","2620\n","2621\n","2622\n","2623\n","2624\n","2625\n","2626\n","2627\n","2628\n","2629\n","2630\n","2631\n","2632\n","2633\n","2634\n","2635\n","2636\n","2637\n","2638\n","2639\n","2640\n","2641\n","2642\n","2643\n","2644\n","2645\n","2646\n","2647\n","2648\n","2649\n","2650\n","2651\n","2652\n","2653\n","2654\n","2655\n","2656\n","2657\n","2658\n","2659\n","2660\n","2661\n","2662\n","2663\n","2664\n","2665\n","2666\n","2667\n","2668\n","2669\n","2670\n","2671\n","2672\n","2673\n","2674\n","2675\n","2676\n","2677\n","2678\n","2679\n","2680\n","2681\n","2682\n","2683\n","2684\n","2685\n","2686\n","2687\n","2688\n","2689\n","2690\n","2691\n","2692\n","2693\n","2694\n","2695\n","2696\n","2697\n","2698\n","2699\n","2700\n","2701\n","2702\n","2703\n","2704\n","2705\n","2706\n","2707\n","2708\n","2709\n","2710\n","2711\n","2712\n","2713\n","2714\n","2715\n","2716\n","2717\n","2718\n","2719\n","2720\n","2721\n","2722\n","2723\n","2724\n","2725\n","2726\n","2727\n","2728\n","2729\n","2730\n","2731\n","2732\n","2733\n","2734\n","2735\n","2736\n","2737\n","2738\n","2739\n","2740\n","2741\n","2742\n","2743\n","2744\n","2745\n","2746\n","2747\n","2748\n","2749\n","2750\n","2751\n","2752\n","2753\n","2754\n","2755\n","2756\n","2757\n","2758\n","2759\n","2760\n","2761\n","2762\n","2763\n","2764\n","2765\n","2766\n","2767\n","2768\n","2769\n","2770\n","2771\n","2772\n","2773\n","2774\n","2775\n","2776\n","2777\n","2778\n","2779\n","2780\n","2781\n","2782\n","2783\n","2784\n","2785\n","2786\n","2787\n","2788\n","2789\n","2790\n","2791\n","2792\n","2793\n","2794\n","2795\n","2796\n","2797\n","2798\n","2799\n","2800\n","2801\n","2802\n","2803\n","2804\n","2805\n","2806\n","2807\n","2808\n","2809\n","2810\n","2811\n","2812\n","2813\n","2814\n","2815\n","2816\n","2817\n","2818\n","2819\n","2820\n","2821\n","2822\n","2823\n","2824\n","2825\n","2826\n","2827\n","2828\n","2829\n","2830\n","2831\n","2832\n","2833\n","2834\n","2835\n","2836\n","2837\n","2838\n","2839\n","2840\n","2841\n","2842\n","2843\n","2844\n","2845\n","2846\n","2847\n","2848\n","2849\n","2850\n","2851\n","2852\n","2853\n","2854\n","2855\n","2856\n","2857\n","2858\n","2859\n","2860\n","2861\n","2862\n","2863\n","2864\n","2865\n","2866\n","2867\n","2868\n","2869\n","2870\n","2871\n","2872\n","2873\n","2874\n","2875\n","2876\n","2877\n","2878\n","2879\n","2880\n","2881\n","2882\n","2883\n","2884\n","2885\n","2886\n","2887\n","2888\n","2889\n","2890\n","2891\n","2892\n","2893\n","2894\n","2895\n","2896\n","2897\n","2898\n","2899\n","2900\n","2901\n","2902\n","2903\n","2904\n","2905\n","2906\n","2907\n","2908\n","2909\n","2910\n","2911\n","2912\n","2913\n","2914\n","2915\n","2916\n","2917\n","2918\n","2919\n","2920\n","2921\n","2922\n","2923\n","2924\n","2925\n","2926\n","2927\n","2928\n","2929\n","2930\n","2931\n","2932\n","2933\n","2934\n","2935\n","2936\n","2937\n","2938\n","2939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ltCJNja7r4uc","colab_type":"code","colab":{}},"source":["temp2=np.array(q)\n","np.save(\"drive/My Drive/MS_data/temp_2_maj.npy\",temp2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cJIcF8fr6EG","colab_type":"code","colab":{}},"source":["q=list(temp2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mt1TxoQBxeRL","colab_type":"code","colab":{}},"source":["temp=np.load(\"drive/My Drive/MS_data/temp_1_maj.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGolKny4r7yO","colab_type":"code","colab":{}},"source":["p=list(temp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ft6YG_kZxUyy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2fc64bb2-212f-4806-8ba8-a973fb049b7c","executionInfo":{"status":"ok","timestamp":1585225046851,"user_tz":-330,"elapsed":1356,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["j=1401\n","for i in q:\n","  print(j)\n","  p.append(i)\n","  j+=1"],"execution_count":9,"outputs":[{"output_type":"stream","text":["1401\n","1402\n","1403\n","1404\n","1405\n","1406\n","1407\n","1408\n","1409\n","1410\n","1411\n","1412\n","1413\n","1414\n","1415\n","1416\n","1417\n","1418\n","1419\n","1420\n","1421\n","1422\n","1423\n","1424\n","1425\n","1426\n","1427\n","1428\n","1429\n","1430\n","1431\n","1432\n","1433\n","1434\n","1435\n","1436\n","1437\n","1438\n","1439\n","1440\n","1441\n","1442\n","1443\n","1444\n","1445\n","1446\n","1447\n","1448\n","1449\n","1450\n","1451\n","1452\n","1453\n","1454\n","1455\n","1456\n","1457\n","1458\n","1459\n","1460\n","1461\n","1462\n","1463\n","1464\n","1465\n","1466\n","1467\n","1468\n","1469\n","1470\n","1471\n","1472\n","1473\n","1474\n","1475\n","1476\n","1477\n","1478\n","1479\n","1480\n","1481\n","1482\n","1483\n","1484\n","1485\n","1486\n","1487\n","1488\n","1489\n","1490\n","1491\n","1492\n","1493\n","1494\n","1495\n","1496\n","1497\n","1498\n","1499\n","1500\n","1501\n","1502\n","1503\n","1504\n","1505\n","1506\n","1507\n","1508\n","1509\n","1510\n","1511\n","1512\n","1513\n","1514\n","1515\n","1516\n","1517\n","1518\n","1519\n","1520\n","1521\n","1522\n","1523\n","1524\n","1525\n","1526\n","1527\n","1528\n","1529\n","1530\n","1531\n","1532\n","1533\n","1534\n","1535\n","1536\n","1537\n","1538\n","1539\n","1540\n","1541\n","1542\n","1543\n","1544\n","1545\n","1546\n","1547\n","1548\n","1549\n","1550\n","1551\n","1552\n","1553\n","1554\n","1555\n","1556\n","1557\n","1558\n","1559\n","1560\n","1561\n","1562\n","1563\n","1564\n","1565\n","1566\n","1567\n","1568\n","1569\n","1570\n","1571\n","1572\n","1573\n","1574\n","1575\n","1576\n","1577\n","1578\n","1579\n","1580\n","1581\n","1582\n","1583\n","1584\n","1585\n","1586\n","1587\n","1588\n","1589\n","1590\n","1591\n","1592\n","1593\n","1594\n","1595\n","1596\n","1597\n","1598\n","1599\n","1600\n","1601\n","1602\n","1603\n","1604\n","1605\n","1606\n","1607\n","1608\n","1609\n","1610\n","1611\n","1612\n","1613\n","1614\n","1615\n","1616\n","1617\n","1618\n","1619\n","1620\n","1621\n","1622\n","1623\n","1624\n","1625\n","1626\n","1627\n","1628\n","1629\n","1630\n","1631\n","1632\n","1633\n","1634\n","1635\n","1636\n","1637\n","1638\n","1639\n","1640\n","1641\n","1642\n","1643\n","1644\n","1645\n","1646\n","1647\n","1648\n","1649\n","1650\n","1651\n","1652\n","1653\n","1654\n","1655\n","1656\n","1657\n","1658\n","1659\n","1660\n","1661\n","1662\n","1663\n","1664\n","1665\n","1666\n","1667\n","1668\n","1669\n","1670\n","1671\n","1672\n","1673\n","1674\n","1675\n","1676\n","1677\n","1678\n","1679\n","1680\n","1681\n","1682\n","1683\n","1684\n","1685\n","1686\n","1687\n","1688\n","1689\n","1690\n","1691\n","1692\n","1693\n","1694\n","1695\n","1696\n","1697\n","1698\n","1699\n","1700\n","1701\n","1702\n","1703\n","1704\n","1705\n","1706\n","1707\n","1708\n","1709\n","1710\n","1711\n","1712\n","1713\n","1714\n","1715\n","1716\n","1717\n","1718\n","1719\n","1720\n","1721\n","1722\n","1723\n","1724\n","1725\n","1726\n","1727\n","1728\n","1729\n","1730\n","1731\n","1732\n","1733\n","1734\n","1735\n","1736\n","1737\n","1738\n","1739\n","1740\n","1741\n","1742\n","1743\n","1744\n","1745\n","1746\n","1747\n","1748\n","1749\n","1750\n","1751\n","1752\n","1753\n","1754\n","1755\n","1756\n","1757\n","1758\n","1759\n","1760\n","1761\n","1762\n","1763\n","1764\n","1765\n","1766\n","1767\n","1768\n","1769\n","1770\n","1771\n","1772\n","1773\n","1774\n","1775\n","1776\n","1777\n","1778\n","1779\n","1780\n","1781\n","1782\n","1783\n","1784\n","1785\n","1786\n","1787\n","1788\n","1789\n","1790\n","1791\n","1792\n","1793\n","1794\n","1795\n","1796\n","1797\n","1798\n","1799\n","1800\n","1801\n","1802\n","1803\n","1804\n","1805\n","1806\n","1807\n","1808\n","1809\n","1810\n","1811\n","1812\n","1813\n","1814\n","1815\n","1816\n","1817\n","1818\n","1819\n","1820\n","1821\n","1822\n","1823\n","1824\n","1825\n","1826\n","1827\n","1828\n","1829\n","1830\n","1831\n","1832\n","1833\n","1834\n","1835\n","1836\n","1837\n","1838\n","1839\n","1840\n","1841\n","1842\n","1843\n","1844\n","1845\n","1846\n","1847\n","1848\n","1849\n","1850\n","1851\n","1852\n","1853\n","1854\n","1855\n","1856\n","1857\n","1858\n","1859\n","1860\n","1861\n","1862\n","1863\n","1864\n","1865\n","1866\n","1867\n","1868\n","1869\n","1870\n","1871\n","1872\n","1873\n","1874\n","1875\n","1876\n","1877\n","1878\n","1879\n","1880\n","1881\n","1882\n","1883\n","1884\n","1885\n","1886\n","1887\n","1888\n","1889\n","1890\n","1891\n","1892\n","1893\n","1894\n","1895\n","1896\n","1897\n","1898\n","1899\n","1900\n","1901\n","1902\n","1903\n","1904\n","1905\n","1906\n","1907\n","1908\n","1909\n","1910\n","1911\n","1912\n","1913\n","1914\n","1915\n","1916\n","1917\n","1918\n","1919\n","1920\n","1921\n","1922\n","1923\n","1924\n","1925\n","1926\n","1927\n","1928\n","1929\n","1930\n","1931\n","1932\n","1933\n","1934\n","1935\n","1936\n","1937\n","1938\n","1939\n","1940\n","1941\n","1942\n","1943\n","1944\n","1945\n","1946\n","1947\n","1948\n","1949\n","1950\n","1951\n","1952\n","1953\n","1954\n","1955\n","1956\n","1957\n","1958\n","1959\n","1960\n","1961\n","1962\n","1963\n","1964\n","1965\n","1966\n","1967\n","1968\n","1969\n","1970\n","1971\n","1972\n","1973\n","1974\n","1975\n","1976\n","1977\n","1978\n","1979\n","1980\n","1981\n","1982\n","1983\n","1984\n","1985\n","1986\n","1987\n","1988\n","1989\n","1990\n","1991\n","1992\n","1993\n","1994\n","1995\n","1996\n","1997\n","1998\n","1999\n","2000\n","2001\n","2002\n","2003\n","2004\n","2005\n","2006\n","2007\n","2008\n","2009\n","2010\n","2011\n","2012\n","2013\n","2014\n","2015\n","2016\n","2017\n","2018\n","2019\n","2020\n","2021\n","2022\n","2023\n","2024\n","2025\n","2026\n","2027\n","2028\n","2029\n","2030\n","2031\n","2032\n","2033\n","2034\n","2035\n","2036\n","2037\n","2038\n","2039\n","2040\n","2041\n","2042\n","2043\n","2044\n","2045\n","2046\n","2047\n","2048\n","2049\n","2050\n","2051\n","2052\n","2053\n","2054\n","2055\n","2056\n","2057\n","2058\n","2059\n","2060\n","2061\n","2062\n","2063\n","2064\n","2065\n","2066\n","2067\n","2068\n","2069\n","2070\n","2071\n","2072\n","2073\n","2074\n","2075\n","2076\n","2077\n","2078\n","2079\n","2080\n","2081\n","2082\n","2083\n","2084\n","2085\n","2086\n","2087\n","2088\n","2089\n","2090\n","2091\n","2092\n","2093\n","2094\n","2095\n","2096\n","2097\n","2098\n","2099\n","2100\n","2101\n","2102\n","2103\n","2104\n","2105\n","2106\n","2107\n","2108\n","2109\n","2110\n","2111\n","2112\n","2113\n","2114\n","2115\n","2116\n","2117\n","2118\n","2119\n","2120\n","2121\n","2122\n","2123\n","2124\n","2125\n","2126\n","2127\n","2128\n","2129\n","2130\n","2131\n","2132\n","2133\n","2134\n","2135\n","2136\n","2137\n","2138\n","2139\n","2140\n","2141\n","2142\n","2143\n","2144\n","2145\n","2146\n","2147\n","2148\n","2149\n","2150\n","2151\n","2152\n","2153\n","2154\n","2155\n","2156\n","2157\n","2158\n","2159\n","2160\n","2161\n","2162\n","2163\n","2164\n","2165\n","2166\n","2167\n","2168\n","2169\n","2170\n","2171\n","2172\n","2173\n","2174\n","2175\n","2176\n","2177\n","2178\n","2179\n","2180\n","2181\n","2182\n","2183\n","2184\n","2185\n","2186\n","2187\n","2188\n","2189\n","2190\n","2191\n","2192\n","2193\n","2194\n","2195\n","2196\n","2197\n","2198\n","2199\n","2200\n","2201\n","2202\n","2203\n","2204\n","2205\n","2206\n","2207\n","2208\n","2209\n","2210\n","2211\n","2212\n","2213\n","2214\n","2215\n","2216\n","2217\n","2218\n","2219\n","2220\n","2221\n","2222\n","2223\n","2224\n","2225\n","2226\n","2227\n","2228\n","2229\n","2230\n","2231\n","2232\n","2233\n","2234\n","2235\n","2236\n","2237\n","2238\n","2239\n","2240\n","2241\n","2242\n","2243\n","2244\n","2245\n","2246\n","2247\n","2248\n","2249\n","2250\n","2251\n","2252\n","2253\n","2254\n","2255\n","2256\n","2257\n","2258\n","2259\n","2260\n","2261\n","2262\n","2263\n","2264\n","2265\n","2266\n","2267\n","2268\n","2269\n","2270\n","2271\n","2272\n","2273\n","2274\n","2275\n","2276\n","2277\n","2278\n","2279\n","2280\n","2281\n","2282\n","2283\n","2284\n","2285\n","2286\n","2287\n","2288\n","2289\n","2290\n","2291\n","2292\n","2293\n","2294\n","2295\n","2296\n","2297\n","2298\n","2299\n","2300\n","2301\n","2302\n","2303\n","2304\n","2305\n","2306\n","2307\n","2308\n","2309\n","2310\n","2311\n","2312\n","2313\n","2314\n","2315\n","2316\n","2317\n","2318\n","2319\n","2320\n","2321\n","2322\n","2323\n","2324\n","2325\n","2326\n","2327\n","2328\n","2329\n","2330\n","2331\n","2332\n","2333\n","2334\n","2335\n","2336\n","2337\n","2338\n","2339\n","2340\n","2341\n","2342\n","2343\n","2344\n","2345\n","2346\n","2347\n","2348\n","2349\n","2350\n","2351\n","2352\n","2353\n","2354\n","2355\n","2356\n","2357\n","2358\n","2359\n","2360\n","2361\n","2362\n","2363\n","2364\n","2365\n","2366\n","2367\n","2368\n","2369\n","2370\n","2371\n","2372\n","2373\n","2374\n","2375\n","2376\n","2377\n","2378\n","2379\n","2380\n","2381\n","2382\n","2383\n","2384\n","2385\n","2386\n","2387\n","2388\n","2389\n","2390\n","2391\n","2392\n","2393\n","2394\n","2395\n","2396\n","2397\n","2398\n","2399\n","2400\n","2401\n","2402\n","2403\n","2404\n","2405\n","2406\n","2407\n","2408\n","2409\n","2410\n","2411\n","2412\n","2413\n","2414\n","2415\n","2416\n","2417\n","2418\n","2419\n","2420\n","2421\n","2422\n","2423\n","2424\n","2425\n","2426\n","2427\n","2428\n","2429\n","2430\n","2431\n","2432\n","2433\n","2434\n","2435\n","2436\n","2437\n","2438\n","2439\n","2440\n","2441\n","2442\n","2443\n","2444\n","2445\n","2446\n","2447\n","2448\n","2449\n","2450\n","2451\n","2452\n","2453\n","2454\n","2455\n","2456\n","2457\n","2458\n","2459\n","2460\n","2461\n","2462\n","2463\n","2464\n","2465\n","2466\n","2467\n","2468\n","2469\n","2470\n","2471\n","2472\n","2473\n","2474\n","2475\n","2476\n","2477\n","2478\n","2479\n","2480\n","2481\n","2482\n","2483\n","2484\n","2485\n","2486\n","2487\n","2488\n","2489\n","2490\n","2491\n","2492\n","2493\n","2494\n","2495\n","2496\n","2497\n","2498\n","2499\n","2500\n","2501\n","2502\n","2503\n","2504\n","2505\n","2506\n","2507\n","2508\n","2509\n","2510\n","2511\n","2512\n","2513\n","2514\n","2515\n","2516\n","2517\n","2518\n","2519\n","2520\n","2521\n","2522\n","2523\n","2524\n","2525\n","2526\n","2527\n","2528\n","2529\n","2530\n","2531\n","2532\n","2533\n","2534\n","2535\n","2536\n","2537\n","2538\n","2539\n","2540\n","2541\n","2542\n","2543\n","2544\n","2545\n","2546\n","2547\n","2548\n","2549\n","2550\n","2551\n","2552\n","2553\n","2554\n","2555\n","2556\n","2557\n","2558\n","2559\n","2560\n","2561\n","2562\n","2563\n","2564\n","2565\n","2566\n","2567\n","2568\n","2569\n","2570\n","2571\n","2572\n","2573\n","2574\n","2575\n","2576\n","2577\n","2578\n","2579\n","2580\n","2581\n","2582\n","2583\n","2584\n","2585\n","2586\n","2587\n","2588\n","2589\n","2590\n","2591\n","2592\n","2593\n","2594\n","2595\n","2596\n","2597\n","2598\n","2599\n","2600\n","2601\n","2602\n","2603\n","2604\n","2605\n","2606\n","2607\n","2608\n","2609\n","2610\n","2611\n","2612\n","2613\n","2614\n","2615\n","2616\n","2617\n","2618\n","2619\n","2620\n","2621\n","2622\n","2623\n","2624\n","2625\n","2626\n","2627\n","2628\n","2629\n","2630\n","2631\n","2632\n","2633\n","2634\n","2635\n","2636\n","2637\n","2638\n","2639\n","2640\n","2641\n","2642\n","2643\n","2644\n","2645\n","2646\n","2647\n","2648\n","2649\n","2650\n","2651\n","2652\n","2653\n","2654\n","2655\n","2656\n","2657\n","2658\n","2659\n","2660\n","2661\n","2662\n","2663\n","2664\n","2665\n","2666\n","2667\n","2668\n","2669\n","2670\n","2671\n","2672\n","2673\n","2674\n","2675\n","2676\n","2677\n","2678\n","2679\n","2680\n","2681\n","2682\n","2683\n","2684\n","2685\n","2686\n","2687\n","2688\n","2689\n","2690\n","2691\n","2692\n","2693\n","2694\n","2695\n","2696\n","2697\n","2698\n","2699\n","2700\n","2701\n","2702\n","2703\n","2704\n","2705\n","2706\n","2707\n","2708\n","2709\n","2710\n","2711\n","2712\n","2713\n","2714\n","2715\n","2716\n","2717\n","2718\n","2719\n","2720\n","2721\n","2722\n","2723\n","2724\n","2725\n","2726\n","2727\n","2728\n","2729\n","2730\n","2731\n","2732\n","2733\n","2734\n","2735\n","2736\n","2737\n","2738\n","2739\n","2740\n","2741\n","2742\n","2743\n","2744\n","2745\n","2746\n","2747\n","2748\n","2749\n","2750\n","2751\n","2752\n","2753\n","2754\n","2755\n","2756\n","2757\n","2758\n","2759\n","2760\n","2761\n","2762\n","2763\n","2764\n","2765\n","2766\n","2767\n","2768\n","2769\n","2770\n","2771\n","2772\n","2773\n","2774\n","2775\n","2776\n","2777\n","2778\n","2779\n","2780\n","2781\n","2782\n","2783\n","2784\n","2785\n","2786\n","2787\n","2788\n","2789\n","2790\n","2791\n","2792\n","2793\n","2794\n","2795\n","2796\n","2797\n","2798\n","2799\n","2800\n","2801\n","2802\n","2803\n","2804\n","2805\n","2806\n","2807\n","2808\n","2809\n","2810\n","2811\n","2812\n","2813\n","2814\n","2815\n","2816\n","2817\n","2818\n","2819\n","2820\n","2821\n","2822\n","2823\n","2824\n","2825\n","2826\n","2827\n","2828\n","2829\n","2830\n","2831\n","2832\n","2833\n","2834\n","2835\n","2836\n","2837\n","2838\n","2839\n","2840\n","2841\n","2842\n","2843\n","2844\n","2845\n","2846\n","2847\n","2848\n","2849\n","2850\n","2851\n","2852\n","2853\n","2854\n","2855\n","2856\n","2857\n","2858\n","2859\n","2860\n","2861\n","2862\n","2863\n","2864\n","2865\n","2866\n","2867\n","2868\n","2869\n","2870\n","2871\n","2872\n","2873\n","2874\n","2875\n","2876\n","2877\n","2878\n","2879\n","2880\n","2881\n","2882\n","2883\n","2884\n","2885\n","2886\n","2887\n","2888\n","2889\n","2890\n","2891\n","2892\n","2893\n","2894\n","2895\n","2896\n","2897\n","2898\n","2899\n","2900\n","2901\n","2902\n","2903\n","2904\n","2905\n","2906\n","2907\n","2908\n","2909\n","2910\n","2911\n","2912\n","2913\n","2914\n","2915\n","2916\n","2917\n","2918\n","2919\n","2920\n","2921\n","2922\n","2923\n","2924\n","2925\n","2926\n","2927\n","2928\n","2929\n","2930\n","2931\n","2932\n","2933\n","2934\n","2935\n","2936\n","2937\n","2938\n","2939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RHdlisEpr9bd","colab_type":"code","colab":{}},"source":["np.save(\"drive/My Drive/MS_data/Y_Manual_major_2.npy\",p)\n","Y=np.load(\"drive/My Drive/MS_data/Y_Manual_major_2.npy\")\n","X=np.load(\"drive/My Drive/MS_data/X_Major.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2M4p2w8Mr_ON","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":117},"outputId":"209de441-588c-472d-f8ea-83a23a5b0188","executionInfo":{"status":"ok","timestamp":1585225181096,"user_tz":-330,"elapsed":12234,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","\n","X_train , X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=32)\n","#print(X_train)\n","#print(X_test)\n","print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n","#print(Y_train)\n","#print(Y_test)\n","# Loding the modified U-net "],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q7n3-ZAwsBT_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"08120fc0-ee05-4f0a-f384-67ae2ad4cdc4","executionInfo":{"status":"ok","timestamp":1585226370605,"user_tz":-330,"elapsed":1159056,"user":{"displayName":"Abhijit Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX2n-gWIRF_x-gkbJUtgh662nGStzO1tMPFZMbKQ=s64","userId":"08205692553559323056"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","#import keras\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","model = model(input_shape = (256,256,5))\n","model.summary()\n","\n","checkpointer = ModelCheckpoint('drive/My Drive/MS_data/Modified_UNet_union.h5', verbose=1)\n","callback_list=[checkpointer]\n","\n","# Compiling the model\n","k_adam=Adam(lr=0.001)\n","model.compile(optimizer=k_adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])\n","# Fitting the model over the data\n","history = model.fit(X_train,Y_train,batch_size=32,epochs=60,validation_split=0.20,verbose=1,initial_epoch=0,callbacks=callback_list)\n","\n","# Saving the model\n","model.save('drive/My Drive/MS_data/Modified_UNet.h5')\n","history.history\n","\n","# Evaluating the model on the training and testing data \n","model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)\n","model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)\n","\n","# Plotting the Graphs of Accuracy, Dice_coefficient, Loss at each epoch on Training and Testing data\n","#Accuarcy_Graph(history)\n","#Dice_coefficient_Graph(history)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 5) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 32) 1472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 256)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 16, 16, 512)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 32, 32, 512)  0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 768)  0           up_sampling2d[0][0]              \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 256)  1769728     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_1[0][0]            \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 64, 64, 128)  442496      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_2[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 128, 128, 64) 110656      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_3[0][0]            \n","                                                                 activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 256, 256, 32) 27680       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 256, 256, 32) 128         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 256, 256, 32) 0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 256, 256, 1)  33          activation_8[0][0]               \n","==================================================================================================\n","Total params: 3,925,633\n","Trainable params: 3,922,689\n","Non-trainable params: 2,944\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 1999 samples, validate on 500 samples\n","Epoch 1/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.2471 - acc: 0.9808 - dice_coef: 0.0479 - precision: 0.5827 - sensitivity: 0.7931 - specificity: 0.9819\n","Epoch 00001: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 29s 15ms/sample - loss: 0.2463 - acc: 0.9809 - dice_coef: 0.0491 - precision: 0.5878 - sensitivity: 0.7923 - specificity: 0.9822 - val_loss: 0.2364 - val_acc: 0.9972 - val_dice_coef: 0.0403 - val_precision: 0.8269 - val_sensitivity: 0.6928 - val_specificity: 0.9991\n","Epoch 2/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9976 - dice_coef: 0.0891 - precision: 0.8546 - sensitivity: 0.7053 - specificity: 0.9993\n","Epoch 00002: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0942 - acc: 0.9977 - dice_coef: 0.0883 - precision: 0.8533 - sensitivity: 0.7038 - specificity: 0.9993 - val_loss: 0.1022 - val_acc: 0.9976 - val_dice_coef: 0.0874 - val_precision: 0.8625 - val_sensitivity: 0.7132 - val_specificity: 0.9993\n","Epoch 3/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9977 - dice_coef: 0.1462 - precision: 0.8887 - sensitivity: 0.6765 - specificity: 0.9995\n","Epoch 00003: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0506 - acc: 0.9977 - dice_coef: 0.1475 - precision: 0.8894 - sensitivity: 0.6758 - specificity: 0.9995 - val_loss: 0.0482 - val_acc: 0.9974 - val_dice_coef: 0.1706 - val_precision: 0.8133 - val_sensitivity: 0.7532 - val_specificity: 0.9989\n","Epoch 4/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9978 - dice_coef: 0.2178 - precision: 0.8861 - sensitivity: 0.6915 - specificity: 0.9995\n","Epoch 00004: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0317 - acc: 0.9978 - dice_coef: 0.2188 - precision: 0.8863 - sensitivity: 0.6915 - specificity: 0.9995 - val_loss: 0.0285 - val_acc: 0.9977 - val_dice_coef: 0.2554 - val_precision: 0.8921 - val_sensitivity: 0.7055 - val_specificity: 0.9995\n","Epoch 5/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9978 - dice_coef: 0.2831 - precision: 0.8795 - sensitivity: 0.7082 - specificity: 0.9995\n","Epoch 00005: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0226 - acc: 0.9978 - dice_coef: 0.2810 - precision: 0.8786 - sensitivity: 0.7038 - specificity: 0.9995 - val_loss: 0.0211 - val_acc: 0.9976 - val_dice_coef: 0.3168 - val_precision: 0.9180 - val_sensitivity: 0.6613 - val_specificity: 0.9996\n","Epoch 6/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9979 - dice_coef: 0.3440 - precision: 0.8810 - sensitivity: 0.7120 - specificity: 0.9995\n","Epoch 00006: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0175 - acc: 0.9979 - dice_coef: 0.3445 - precision: 0.8824 - sensitivity: 0.7123 - specificity: 0.9995 - val_loss: 0.0157 - val_acc: 0.9977 - val_dice_coef: 0.4060 - val_precision: 0.8749 - val_sensitivity: 0.7160 - val_specificity: 0.9994\n","Epoch 7/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9979 - dice_coef: 0.4056 - precision: 0.8805 - sensitivity: 0.7295 - specificity: 0.9995\n","Epoch 00007: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0143 - acc: 0.9979 - dice_coef: 0.4078 - precision: 0.8812 - sensitivity: 0.7295 - specificity: 0.9995 - val_loss: 0.0127 - val_acc: 0.9978 - val_dice_coef: 0.4751 - val_precision: 0.8958 - val_sensitivity: 0.7227 - val_specificity: 0.9995\n","Epoch 8/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9980 - dice_coef: 0.4534 - precision: 0.8798 - sensitivity: 0.7371 - specificity: 0.9995\n","Epoch 00008: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0123 - acc: 0.9980 - dice_coef: 0.4539 - precision: 0.8786 - sensitivity: 0.7372 - specificity: 0.9994 - val_loss: 0.0112 - val_acc: 0.9979 - val_dice_coef: 0.5208 - val_precision: 0.9021 - val_sensitivity: 0.7286 - val_specificity: 0.9995\n","Epoch 9/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9980 - dice_coef: 0.4923 - precision: 0.8801 - sensitivity: 0.7394 - specificity: 0.9994\n","Epoch 00009: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0109 - acc: 0.9980 - dice_coef: 0.4940 - precision: 0.8806 - sensitivity: 0.7396 - specificity: 0.9994 - val_loss: 0.0099 - val_acc: 0.9979 - val_dice_coef: 0.5652 - val_precision: 0.8879 - val_sensitivity: 0.7325 - val_specificity: 0.9995\n","Epoch 10/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9980 - dice_coef: 0.5321 - precision: 0.8833 - sensitivity: 0.7505 - specificity: 0.9994\n","Epoch 00010: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0100 - acc: 0.9980 - dice_coef: 0.5309 - precision: 0.8833 - sensitivity: 0.7500 - specificity: 0.9994 - val_loss: 0.0099 - val_acc: 0.9978 - val_dice_coef: 0.5875 - val_precision: 0.8713 - val_sensitivity: 0.7542 - val_specificity: 0.9993\n","Epoch 11/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9980 - dice_coef: 0.5545 - precision: 0.8813 - sensitivity: 0.7493 - specificity: 0.9994\n","Epoch 00011: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0093 - acc: 0.9980 - dice_coef: 0.5508 - precision: 0.8810 - sensitivity: 0.7513 - specificity: 0.9994 - val_loss: 0.0089 - val_acc: 0.9979 - val_dice_coef: 0.6443 - val_precision: 0.8766 - val_sensitivity: 0.7666 - val_specificity: 0.9993\n","Epoch 12/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9981 - dice_coef: 0.5814 - precision: 0.8783 - sensitivity: 0.7508 - specificity: 0.9994\n","Epoch 00012: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0087 - acc: 0.9980 - dice_coef: 0.5811 - precision: 0.8781 - sensitivity: 0.7498 - specificity: 0.9994 - val_loss: 0.0085 - val_acc: 0.9979 - val_dice_coef: 0.6318 - val_precision: 0.9243 - val_sensitivity: 0.7244 - val_specificity: 0.9996\n","Epoch 13/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9981 - dice_coef: 0.6030 - precision: 0.8842 - sensitivity: 0.7547 - specificity: 0.9995\n","Epoch 00013: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0081 - acc: 0.9981 - dice_coef: 0.6038 - precision: 0.8846 - sensitivity: 0.7557 - specificity: 0.9995 - val_loss: 0.0079 - val_acc: 0.9980 - val_dice_coef: 0.6578 - val_precision: 0.8844 - val_sensitivity: 0.7703 - val_specificity: 0.9994\n","Epoch 14/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9981 - dice_coef: 0.6158 - precision: 0.8791 - sensitivity: 0.7563 - specificity: 0.9994\n","Epoch 00014: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0078 - acc: 0.9981 - dice_coef: 0.6182 - precision: 0.8804 - sensitivity: 0.7569 - specificity: 0.9994 - val_loss: 0.0079 - val_acc: 0.9980 - val_dice_coef: 0.6698 - val_precision: 0.8979 - val_sensitivity: 0.7459 - val_specificity: 0.9995\n","Epoch 15/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9981 - dice_coef: 0.6356 - precision: 0.8859 - sensitivity: 0.7600 - specificity: 0.9995\n","Epoch 00015: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0074 - acc: 0.9981 - dice_coef: 0.6353 - precision: 0.8858 - sensitivity: 0.7607 - specificity: 0.9995 - val_loss: 0.0076 - val_acc: 0.9980 - val_dice_coef: 0.6798 - val_precision: 0.8824 - val_sensitivity: 0.7812 - val_specificity: 0.9993\n","Epoch 16/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9981 - dice_coef: 0.6504 - precision: 0.8870 - sensitivity: 0.7647 - specificity: 0.9995\n","Epoch 00016: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0071 - acc: 0.9981 - dice_coef: 0.6507 - precision: 0.8861 - sensitivity: 0.7649 - specificity: 0.9995 - val_loss: 0.0076 - val_acc: 0.9978 - val_dice_coef: 0.6965 - val_precision: 0.8286 - val_sensitivity: 0.8117 - val_specificity: 0.9990\n","Epoch 17/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9981 - dice_coef: 0.6624 - precision: 0.8848 - sensitivity: 0.7649 - specificity: 0.9994\n","Epoch 00017: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0069 - acc: 0.9981 - dice_coef: 0.6640 - precision: 0.8850 - sensitivity: 0.7667 - specificity: 0.9994 - val_loss: 0.0078 - val_acc: 0.9979 - val_dice_coef: 0.6408 - val_precision: 0.8374 - val_sensitivity: 0.7906 - val_specificity: 0.9991\n","Epoch 18/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9981 - dice_coef: 0.6712 - precision: 0.8834 - sensitivity: 0.7668 - specificity: 0.9994\n","Epoch 00018: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0067 - acc: 0.9981 - dice_coef: 0.6717 - precision: 0.8839 - sensitivity: 0.7667 - specificity: 0.9994 - val_loss: 0.0073 - val_acc: 0.9980 - val_dice_coef: 0.7085 - val_precision: 0.8917 - val_sensitivity: 0.7739 - val_specificity: 0.9994\n","Epoch 19/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9982 - dice_coef: 0.6827 - precision: 0.8851 - sensitivity: 0.7704 - specificity: 0.9995\n","Epoch 00019: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0064 - acc: 0.9982 - dice_coef: 0.6835 - precision: 0.8853 - sensitivity: 0.7715 - specificity: 0.9995 - val_loss: 0.0072 - val_acc: 0.9980 - val_dice_coef: 0.6828 - val_precision: 0.8708 - val_sensitivity: 0.7794 - val_specificity: 0.9993\n","Epoch 20/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9982 - dice_coef: 0.6875 - precision: 0.8844 - sensitivity: 0.7714 - specificity: 0.9994\n","Epoch 00020: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0063 - acc: 0.9982 - dice_coef: 0.6867 - precision: 0.8843 - sensitivity: 0.7708 - specificity: 0.9994 - val_loss: 0.0068 - val_acc: 0.9980 - val_dice_coef: 0.7163 - val_precision: 0.9039 - val_sensitivity: 0.7596 - val_specificity: 0.9995\n","Epoch 21/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9982 - dice_coef: 0.7024 - precision: 0.8884 - sensitivity: 0.7823 - specificity: 0.9994\n","Epoch 00021: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0060 - acc: 0.9982 - dice_coef: 0.7031 - precision: 0.8893 - sensitivity: 0.7823 - specificity: 0.9994 - val_loss: 0.0066 - val_acc: 0.9981 - val_dice_coef: 0.7225 - val_precision: 0.8910 - val_sensitivity: 0.7691 - val_specificity: 0.9994\n","Epoch 22/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9982 - dice_coef: 0.7025 - precision: 0.8821 - sensitivity: 0.7798 - specificity: 0.9994\n","Epoch 00022: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0059 - acc: 0.9982 - dice_coef: 0.7041 - precision: 0.8831 - sensitivity: 0.7800 - specificity: 0.9994 - val_loss: 0.0069 - val_acc: 0.9981 - val_dice_coef: 0.7394 - val_precision: 0.8974 - val_sensitivity: 0.7748 - val_specificity: 0.9994\n","Epoch 23/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9982 - dice_coef: 0.7108 - precision: 0.8844 - sensitivity: 0.7822 - specificity: 0.9994\n","Epoch 00023: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0058 - acc: 0.9982 - dice_coef: 0.7102 - precision: 0.8853 - sensitivity: 0.7810 - specificity: 0.9994 - val_loss: 0.0065 - val_acc: 0.9981 - val_dice_coef: 0.7094 - val_precision: 0.8724 - val_sensitivity: 0.7839 - val_specificity: 0.9993\n","Epoch 24/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9982 - dice_coef: 0.7201 - precision: 0.8892 - sensitivity: 0.7861 - specificity: 0.9994\n","Epoch 00024: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0057 - acc: 0.9982 - dice_coef: 0.7191 - precision: 0.8885 - sensitivity: 0.7849 - specificity: 0.9994 - val_loss: 0.0065 - val_acc: 0.9981 - val_dice_coef: 0.7460 - val_precision: 0.9034 - val_sensitivity: 0.7687 - val_specificity: 0.9995\n","Epoch 25/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9983 - dice_coef: 0.7287 - precision: 0.8895 - sensitivity: 0.7944 - specificity: 0.9995\n","Epoch 00025: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0054 - acc: 0.9983 - dice_coef: 0.7291 - precision: 0.8899 - sensitivity: 0.7941 - specificity: 0.9995 - val_loss: 0.0064 - val_acc: 0.9981 - val_dice_coef: 0.7428 - val_precision: 0.9036 - val_sensitivity: 0.7643 - val_specificity: 0.9995\n","Epoch 26/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9983 - dice_coef: 0.7298 - precision: 0.8848 - sensitivity: 0.7972 - specificity: 0.9994\n","Epoch 00026: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0054 - acc: 0.9983 - dice_coef: 0.7292 - precision: 0.8847 - sensitivity: 0.7961 - specificity: 0.9994 - val_loss: 0.0064 - val_acc: 0.9981 - val_dice_coef: 0.7492 - val_precision: 0.9176 - val_sensitivity: 0.7524 - val_specificity: 0.9996\n","Epoch 27/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9983 - dice_coef: 0.7398 - precision: 0.8904 - sensitivity: 0.7996 - specificity: 0.9995\n","Epoch 00027: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0052 - acc: 0.9983 - dice_coef: 0.7401 - precision: 0.8907 - sensitivity: 0.7991 - specificity: 0.9995 - val_loss: 0.0061 - val_acc: 0.9981 - val_dice_coef: 0.7378 - val_precision: 0.8534 - val_sensitivity: 0.8030 - val_specificity: 0.9992\n","Epoch 28/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9983 - dice_coef: 0.7418 - precision: 0.8891 - sensitivity: 0.8016 - specificity: 0.9994\n","Epoch 00028: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0051 - acc: 0.9983 - dice_coef: 0.7413 - precision: 0.8886 - sensitivity: 0.8011 - specificity: 0.9994 - val_loss: 0.0061 - val_acc: 0.9981 - val_dice_coef: 0.7585 - val_precision: 0.8885 - val_sensitivity: 0.7875 - val_specificity: 0.9994\n","Epoch 29/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9984 - dice_coef: 0.7507 - precision: 0.8931 - sensitivity: 0.8067 - specificity: 0.9995\n","Epoch 00029: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0049 - acc: 0.9984 - dice_coef: 0.7503 - precision: 0.8928 - sensitivity: 0.8071 - specificity: 0.9995 - val_loss: 0.0068 - val_acc: 0.9980 - val_dice_coef: 0.7507 - val_precision: 0.9364 - val_sensitivity: 0.7141 - val_specificity: 0.9997\n","Epoch 30/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9984 - dice_coef: 0.7624 - precision: 0.8941 - sensitivity: 0.8190 - specificity: 0.9995\n","Epoch 00030: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0046 - acc: 0.9984 - dice_coef: 0.7625 - precision: 0.8934 - sensitivity: 0.8193 - specificity: 0.9995 - val_loss: 0.0060 - val_acc: 0.9982 - val_dice_coef: 0.7676 - val_precision: 0.8898 - val_sensitivity: 0.7941 - val_specificity: 0.9994\n","Epoch 31/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9985 - dice_coef: 0.7703 - precision: 0.8979 - sensitivity: 0.8234 - specificity: 0.9995\n","Epoch 00031: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0045 - acc: 0.9985 - dice_coef: 0.7696 - precision: 0.8971 - sensitivity: 0.8224 - specificity: 0.9995 - val_loss: 0.0058 - val_acc: 0.9982 - val_dice_coef: 0.7564 - val_precision: 0.8980 - val_sensitivity: 0.7851 - val_specificity: 0.9995\n","Epoch 32/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9985 - dice_coef: 0.7718 - precision: 0.8987 - sensitivity: 0.8240 - specificity: 0.9995\n","Epoch 00032: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0044 - acc: 0.9985 - dice_coef: 0.7686 - precision: 0.8976 - sensitivity: 0.8226 - specificity: 0.9995 - val_loss: 0.0063 - val_acc: 0.9982 - val_dice_coef: 0.7676 - val_precision: 0.9267 - val_sensitivity: 0.7484 - val_specificity: 0.9996\n","Epoch 33/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9986 - dice_coef: 0.7826 - precision: 0.9023 - sensitivity: 0.8313 - specificity: 0.9995\n","Epoch 00033: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0042 - acc: 0.9986 - dice_coef: 0.7818 - precision: 0.9029 - sensitivity: 0.8297 - specificity: 0.9995 - val_loss: 0.0059 - val_acc: 0.9981 - val_dice_coef: 0.7714 - val_precision: 0.8624 - val_sensitivity: 0.8124 - val_specificity: 0.9992\n","Epoch 34/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9986 - dice_coef: 0.7872 - precision: 0.8988 - sensitivity: 0.8395 - specificity: 0.9995\n","Epoch 00034: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0041 - acc: 0.9986 - dice_coef: 0.7878 - precision: 0.8996 - sensitivity: 0.8396 - specificity: 0.9995 - val_loss: 0.0059 - val_acc: 0.9982 - val_dice_coef: 0.7582 - val_precision: 0.9266 - val_sensitivity: 0.7496 - val_specificity: 0.9996\n","Epoch 35/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9986 - dice_coef: 0.7891 - precision: 0.9019 - sensitivity: 0.8377 - specificity: 0.9995\n","Epoch 00035: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0041 - acc: 0.9986 - dice_coef: 0.7888 - precision: 0.9019 - sensitivity: 0.8376 - specificity: 0.9995 - val_loss: 0.0056 - val_acc: 0.9982 - val_dice_coef: 0.7767 - val_precision: 0.9007 - val_sensitivity: 0.7908 - val_specificity: 0.9995\n","Epoch 36/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9986 - dice_coef: 0.7965 - precision: 0.9041 - sensitivity: 0.8438 - specificity: 0.9995\n","Epoch 00036: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0039 - acc: 0.9986 - dice_coef: 0.7958 - precision: 0.9043 - sensitivity: 0.8428 - specificity: 0.9995 - val_loss: 0.0059 - val_acc: 0.9982 - val_dice_coef: 0.7800 - val_precision: 0.9255 - val_sensitivity: 0.7653 - val_specificity: 0.9996\n","Epoch 37/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9987 - dice_coef: 0.8044 - precision: 0.9065 - sensitivity: 0.8520 - specificity: 0.9995\n","Epoch 00037: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0037 - acc: 0.9987 - dice_coef: 0.8042 - precision: 0.9066 - sensitivity: 0.8514 - specificity: 0.9995 - val_loss: 0.0055 - val_acc: 0.9983 - val_dice_coef: 0.7720 - val_precision: 0.9040 - val_sensitivity: 0.7922 - val_specificity: 0.9995\n","Epoch 38/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9987 - dice_coef: 0.8073 - precision: 0.9064 - sensitivity: 0.8529 - specificity: 0.9995\n","Epoch 00038: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0036 - acc: 0.9987 - dice_coef: 0.8062 - precision: 0.9059 - sensitivity: 0.8515 - specificity: 0.9995 - val_loss: 0.0056 - val_acc: 0.9982 - val_dice_coef: 0.7781 - val_precision: 0.8761 - val_sensitivity: 0.8046 - val_specificity: 0.9993\n","Epoch 39/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9987 - dice_coef: 0.8150 - precision: 0.9108 - sensitivity: 0.8596 - specificity: 0.9995\n","Epoch 00039: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0034 - acc: 0.9987 - dice_coef: 0.8155 - precision: 0.9110 - sensitivity: 0.8602 - specificity: 0.9995 - val_loss: 0.0066 - val_acc: 0.9981 - val_dice_coef: 0.7734 - val_precision: 0.9485 - val_sensitivity: 0.7174 - val_specificity: 0.9998\n","Epoch 40/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9988 - dice_coef: 0.8212 - precision: 0.9109 - sensitivity: 0.8646 - specificity: 0.9995\n","Epoch 00040: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0033 - acc: 0.9988 - dice_coef: 0.8205 - precision: 0.9100 - sensitivity: 0.8650 - specificity: 0.9995 - val_loss: 0.0058 - val_acc: 0.9982 - val_dice_coef: 0.7810 - val_precision: 0.9000 - val_sensitivity: 0.7863 - val_specificity: 0.9995\n","Epoch 41/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9988 - dice_coef: 0.8219 - precision: 0.9106 - sensitivity: 0.8645 - specificity: 0.9995\n","Epoch 00041: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0033 - acc: 0.9988 - dice_coef: 0.8224 - precision: 0.9112 - sensitivity: 0.8648 - specificity: 0.9995 - val_loss: 0.0057 - val_acc: 0.9982 - val_dice_coef: 0.7857 - val_precision: 0.9006 - val_sensitivity: 0.7908 - val_specificity: 0.9995\n","Epoch 42/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9988 - dice_coef: 0.8313 - precision: 0.9153 - sensitivity: 0.8710 - specificity: 0.9995\n","Epoch 00042: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0031 - acc: 0.9988 - dice_coef: 0.8315 - precision: 0.9155 - sensitivity: 0.8711 - specificity: 0.9996 - val_loss: 0.0056 - val_acc: 0.9983 - val_dice_coef: 0.7800 - val_precision: 0.9227 - val_sensitivity: 0.7702 - val_specificity: 0.9996\n","Epoch 43/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9988 - dice_coef: 0.8301 - precision: 0.9132 - sensitivity: 0.8705 - specificity: 0.9995\n","Epoch 00043: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0031 - acc: 0.9988 - dice_coef: 0.8303 - precision: 0.9139 - sensitivity: 0.8698 - specificity: 0.9995 - val_loss: 0.0059 - val_acc: 0.9981 - val_dice_coef: 0.7921 - val_precision: 0.8571 - val_sensitivity: 0.8249 - val_specificity: 0.9992\n","Epoch 44/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9988 - dice_coef: 0.8314 - precision: 0.9132 - sensitivity: 0.8731 - specificity: 0.9995\n","Epoch 00044: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0031 - acc: 0.9988 - dice_coef: 0.8314 - precision: 0.9133 - sensitivity: 0.8733 - specificity: 0.9995 - val_loss: 0.0062 - val_acc: 0.9982 - val_dice_coef: 0.7975 - val_precision: 0.9204 - val_sensitivity: 0.7752 - val_specificity: 0.9996\n","Epoch 45/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9989 - dice_coef: 0.8446 - precision: 0.9201 - sensitivity: 0.8824 - specificity: 0.9996\n","Epoch 00045: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0029 - acc: 0.9989 - dice_coef: 0.8447 - precision: 0.9202 - sensitivity: 0.8826 - specificity: 0.9996 - val_loss: 0.0058 - val_acc: 0.9982 - val_dice_coef: 0.8002 - val_precision: 0.8804 - val_sensitivity: 0.8047 - val_specificity: 0.9993\n","Epoch 46/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9989 - dice_coef: 0.8434 - precision: 0.9159 - sensitivity: 0.8845 - specificity: 0.9996\n","Epoch 00046: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0028 - acc: 0.9989 - dice_coef: 0.8431 - precision: 0.9155 - sensitivity: 0.8842 - specificity: 0.9996 - val_loss: 0.0062 - val_acc: 0.9983 - val_dice_coef: 0.8076 - val_precision: 0.9256 - val_sensitivity: 0.7778 - val_specificity: 0.9996\n","Epoch 47/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9990 - dice_coef: 0.8503 - precision: 0.9218 - sensitivity: 0.8861 - specificity: 0.9996\n","Epoch 00047: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0027 - acc: 0.9990 - dice_coef: 0.8484 - precision: 0.9203 - sensitivity: 0.8856 - specificity: 0.9996 - val_loss: 0.0057 - val_acc: 0.9982 - val_dice_coef: 0.7967 - val_precision: 0.8890 - val_sensitivity: 0.8022 - val_specificity: 0.9994\n","Epoch 48/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9990 - dice_coef: 0.8578 - precision: 0.9241 - sensitivity: 0.8946 - specificity: 0.9996\n","Epoch 00048: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0026 - acc: 0.9990 - dice_coef: 0.8582 - precision: 0.9238 - sensitivity: 0.8956 - specificity: 0.9996 - val_loss: 0.0057 - val_acc: 0.9981 - val_dice_coef: 0.7993 - val_precision: 0.8391 - val_sensitivity: 0.8523 - val_specificity: 0.9990\n","Epoch 49/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9990 - dice_coef: 0.8621 - precision: 0.9251 - sensitivity: 0.8986 - specificity: 0.9996\n","Epoch 00049: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0025 - acc: 0.9990 - dice_coef: 0.8618 - precision: 0.9251 - sensitivity: 0.8976 - specificity: 0.9996 - val_loss: 0.0061 - val_acc: 0.9982 - val_dice_coef: 0.7982 - val_precision: 0.9415 - val_sensitivity: 0.7500 - val_specificity: 0.9997\n","Epoch 50/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9990 - dice_coef: 0.8607 - precision: 0.9229 - sensitivity: 0.8981 - specificity: 0.9996\n","Epoch 00050: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0025 - acc: 0.9990 - dice_coef: 0.8597 - precision: 0.9225 - sensitivity: 0.8968 - specificity: 0.9996 - val_loss: 0.0059 - val_acc: 0.9983 - val_dice_coef: 0.8235 - val_precision: 0.9002 - val_sensitivity: 0.8125 - val_specificity: 0.9994\n","Epoch 51/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9990 - dice_coef: 0.8665 - precision: 0.9266 - sensitivity: 0.9018 - specificity: 0.9996\n","Epoch 00051: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0024 - acc: 0.9990 - dice_coef: 0.8666 - precision: 0.9268 - sensitivity: 0.9018 - specificity: 0.9996 - val_loss: 0.0061 - val_acc: 0.9982 - val_dice_coef: 0.7998 - val_precision: 0.9354 - val_sensitivity: 0.7576 - val_specificity: 0.9997\n","Epoch 52/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9991 - dice_coef: 0.8732 - precision: 0.9307 - sensitivity: 0.9061 - specificity: 0.9996\n","Epoch 00052: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0023 - acc: 0.9991 - dice_coef: 0.8714 - precision: 0.9300 - sensitivity: 0.9046 - specificity: 0.9996 - val_loss: 0.0064 - val_acc: 0.9983 - val_dice_coef: 0.8155 - val_precision: 0.9137 - val_sensitivity: 0.7839 - val_specificity: 0.9996\n","Epoch 53/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9991 - dice_coef: 0.8723 - precision: 0.9278 - sensitivity: 0.9079 - specificity: 0.9996\n","Epoch 00053: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0023 - acc: 0.9991 - dice_coef: 0.8722 - precision: 0.9276 - sensitivity: 0.9079 - specificity: 0.9996 - val_loss: 0.0062 - val_acc: 0.9983 - val_dice_coef: 0.8262 - val_precision: 0.9081 - val_sensitivity: 0.8000 - val_specificity: 0.9995\n","Epoch 54/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8815 - precision: 0.9331 - sensitivity: 0.9138 - specificity: 0.9996\n","Epoch 00054: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 18s 9ms/sample - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8810 - precision: 0.9326 - sensitivity: 0.9133 - specificity: 0.9996 - val_loss: 0.0059 - val_acc: 0.9983 - val_dice_coef: 0.8223 - val_precision: 0.8909 - val_sensitivity: 0.8178 - val_specificity: 0.9994\n","Epoch 55/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9991 - dice_coef: 0.8778 - precision: 0.9317 - sensitivity: 0.9104 - specificity: 0.9996\n","Epoch 00055: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0022 - acc: 0.9991 - dice_coef: 0.8775 - precision: 0.9318 - sensitivity: 0.9100 - specificity: 0.9996 - val_loss: 0.0061 - val_acc: 0.9983 - val_dice_coef: 0.8223 - val_precision: 0.9134 - val_sensitivity: 0.7971 - val_specificity: 0.9995\n","Epoch 56/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8839 - precision: 0.9348 - sensitivity: 0.9141 - specificity: 0.9996\n","Epoch 00056: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 10ms/sample - loss: 0.0021 - acc: 0.9992 - dice_coef: 0.8840 - precision: 0.9343 - sensitivity: 0.9147 - specificity: 0.9996 - val_loss: 0.0058 - val_acc: 0.9983 - val_dice_coef: 0.8140 - val_precision: 0.8791 - val_sensitivity: 0.8200 - val_specificity: 0.9993\n","Epoch 57/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8899 - precision: 0.9372 - sensitivity: 0.9208 - specificity: 0.9997\n","Epoch 00057: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8893 - precision: 0.9366 - sensitivity: 0.9206 - specificity: 0.9997 - val_loss: 0.0059 - val_acc: 0.9983 - val_dice_coef: 0.8196 - val_precision: 0.8915 - val_sensitivity: 0.8127 - val_specificity: 0.9994\n","Epoch 58/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8890 - precision: 0.9370 - sensitivity: 0.9189 - specificity: 0.9997\n","Epoch 00058: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 20s 10ms/sample - loss: 0.0020 - acc: 0.9992 - dice_coef: 0.8888 - precision: 0.9370 - sensitivity: 0.9187 - specificity: 0.9997 - val_loss: 0.0061 - val_acc: 0.9982 - val_dice_coef: 0.8166 - val_precision: 0.8858 - val_sensitivity: 0.8053 - val_specificity: 0.9994\n","Epoch 59/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9992 - dice_coef: 0.8929 - precision: 0.9366 - sensitivity: 0.9240 - specificity: 0.9997\n","Epoch 00059: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 19s 9ms/sample - loss: 0.0019 - acc: 0.9992 - dice_coef: 0.8926 - precision: 0.9365 - sensitivity: 0.9240 - specificity: 0.9997 - val_loss: 0.0060 - val_acc: 0.9983 - val_dice_coef: 0.8253 - val_precision: 0.8851 - val_sensitivity: 0.8217 - val_specificity: 0.9994\n","Epoch 60/60\n","1984/1999 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8979 - precision: 0.9408 - sensitivity: 0.9270 - specificity: 0.9997\n","Epoch 00060: saving model to drive/My Drive/MS_data/Modified_UNet_union.h5\n","1999/1999 [==============================] - 21s 11ms/sample - loss: 0.0018 - acc: 0.9993 - dice_coef: 0.8979 - precision: 0.9411 - sensitivity: 0.9267 - specificity: 0.9997 - val_loss: 0.0061 - val_acc: 0.9982 - val_dice_coef: 0.8286 - val_precision: 0.8626 - val_sensitivity: 0.8432 - val_specificity: 0.9992\n","2499/2499 [==============================] - 8s 3ms/sample - loss: 0.0026 - acc: 0.9991 - dice_coef: 0.8742 - precision: 0.9015 - sensitivity: 0.9143 - specificity: 0.9995\n","441/441 [==============================] - 2s 4ms/sample - loss: 0.0058 - acc: 0.9983 - dice_coef: 0.8280 - precision: 0.8634 - sensitivity: 0.8425 - specificity: 0.9992\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.005795290116051765, 0.99828, 0.82804215, 0.86342204, 0.84253913, 0.999209]"]},"metadata":{"tags":[]},"execution_count":15}]}]}