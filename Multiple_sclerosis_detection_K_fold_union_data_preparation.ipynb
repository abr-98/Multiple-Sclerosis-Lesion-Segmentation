{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiple_sclerosis_detection_K_fold_union_data_preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7LFyFVoaFEE",
        "colab_type": "text"
      },
      "source": [
        "# Drive Mounter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0wf2Df4cEe_",
        "colab_type": "code",
        "outputId": "81cff756-b46b-4a92-a1f4-71ddd2d4468b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!pip install tensorboardcolab"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnaRF_mNZ2nX",
        "colab_type": "code",
        "outputId": "c6541621-715a-45c6-d826-958ebef08a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ0T6J3JdyYo",
        "colab_type": "text"
      },
      "source": [
        "## Function declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqdasbMjVx9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Computing Dice_Coefficient\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Computing Precision \n",
        "def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "# Computing Sensitivity      \n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "# Computing Specificity\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87xpotnlWdR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "    \n",
        "def modality(Path,index):\n",
        "    X = []\n",
        "    X_per_paitent = []\n",
        "    p=os.listdir(Path) \n",
        "    recs_in=[]\n",
        "    counter=0\n",
        "    counter_2=0\n",
        "\n",
        "    for i in p[:14]:                                                                      # Loading all the folders in the given path\n",
        "        q = os.listdir(os.path.join(Path,i))     \n",
        "\n",
        "        x = nib.load(os.path.join(Path,i,q[index]))         \n",
        "        f = x.get_fdata()\n",
        "        f = np.asarray(f,'float32')\n",
        "        \n",
        "        ct=0\n",
        "        recs_in.append(f.shape[2])\n",
        "        #print(counter_2)\n",
        "        counter_2+=1\n",
        "        for j in range(f.shape[2]):                                                        # Processing the MRI Scan in the axial view\n",
        "            _slice = cv.resize(f[:,:,j],(256,256),interpolation=cv.INTER_NEAREST)             # Resizing the slice to the shape(256,256)\n",
        "            if(index not in [3,4,5,6,7,8,9] and np.sum(_slice) != 0 ):  \n",
        "                if index==1:\n",
        "                  ct+=1 \n",
        "                  counter+=1                                         # To check whether the slice is null or not\n",
        "              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n",
        "                  _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001)\n",
        "                   # Standardization\n",
        "                else:\n",
        "                                              # To check whether the slice is null or not\n",
        "              #  _slice = _slice / (np.max(_slice) + 0.00001)                               # Normalization\n",
        "                  _slice = (_slice - np.mean(_slice) + 0.00001) / (np.std(_slice) + 0.00001) # Standardization\n",
        "            elif(index in [3,4,5,6,7,8,9]):   # if index = 3, Then it is output mask and we don't normalize or standardize it \n",
        "                _slice = np.array(_slice)\n",
        "                _slice[_slice > 0] = 1.0\n",
        "                _slice[_slice < 0] = 0.0\n",
        "            _slice = _slice.T\n",
        "            _slice = _slice[:,:,np.newaxis]\n",
        "            X.append(_slice)\n",
        "   # X=np.array(X,dtype='float32')\n",
        "    return X,recs_in"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUSAbkC6YX66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_null_samples(X_Dp, X_Flair, X_Gado, X_T1, X_T2, Y_Manual,recs): \n",
        "     \n",
        "    X=[]\n",
        "    Y=[]\n",
        "    counter=0\n",
        "    counter_2=0\n",
        "    mult=0;\n",
        "    count=0\n",
        "    rec=[]\n",
        "    keep_count=[]\n",
        "    keep=[]\n",
        "    print(recs)\n",
        "    r=np.array(recs,dtype='float32')\n",
        "    print(np.sum(r))\n",
        "    print(len(X_Dp))\n",
        "\n",
        "    for i in range(len(X_Dp)):  \n",
        "        if counter==(recs[mult]):\n",
        "          print(counter)\n",
        "          mult+=1\n",
        "          rec.append(count)\n",
        "          counter=0\n",
        "          print(counter_2)\n",
        "          count=0\n",
        "        final_slice = np.concatenate((X_Dp[i],X_Flair[i],X_Gado[i],X_T1[i],X_T2[i]), axis = -1)\n",
        "        if(np.sum(final_slice) != 0):        # checking whether the final slice is empty or not             \n",
        "            X.append(final_slice)\n",
        "            Y.append(Y_Manual[i])\n",
        "            \n",
        "            count+=1\n",
        "        counter+=1\n",
        "        counter_2+=1\n",
        "\n",
        "    \n",
        "    rec.append(count)\n",
        "#   Converting the list into array  \n",
        "    X=np.array(X,dtype='float32')\n",
        "    Y=np.array(Y,dtype='float32')\n",
        "    rec=np.array(rec,dtype='float32')\n",
        "    \n",
        "    return X,Y,rec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROccBBdcYjpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_data(X,Y,rec):\n",
        "    np.save(\"drive/My Drive/MS_data/X_union_new.npy\",X)\n",
        "    np.save(\"drive/My Drive/MS_data/Y_union_new.npy\",Y)\n",
        "    np.save(\"drive/My Drive/MS_data/union_new_rec_after_removal.npy\",rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IcBwYR5Ym32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def union(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7):\n",
        "  Y=[]\n",
        "  sum2=[]\n",
        "  flag=0\n",
        "  #y=np.array()\n",
        "  print(\"A\")\n",
        "  for i in range (len(Y_1)):\n",
        "    #print(Y_1[i])\n",
        "    \n",
        "        f=np.concatenate((Y_1[i],Y_2[i],Y_3[i],Y_4[i],Y_5[i],Y_6[i],Y_7[i]),axis=-1)\n",
        "        sum=np.sum(f,axis=2)\n",
        "       # print(sum)\n",
        "        \n",
        "          #print(j)\n",
        "        sum_1=np.divide(sum,7)\n",
        "        sum_1=np.ceil(sum_1)\n",
        "        sum2.append(sum_1)\n",
        "\n",
        "    #sum2=np.array(sum2,dtype='float32')\n",
        "    \n",
        "        \n",
        "  return sum2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK0k89T0gAxA",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSH_vufUaXJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import dataPrepare as process\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n",
        "#import Modified_UNet \n",
        "#import plots\n",
        "#import Metrics\n",
        "\n",
        "# Setting the path\n",
        "Path='drive/My Drive/Pre-processed'\n",
        "\n",
        "\n",
        "\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual Segmentation\n",
        "X_Dp_t,rec      =   modality(Path,0)\n",
        "X_Flair_t,rec_1   =   modality(Path,1)\n",
        "X_Gado_t,rec    =   modality(Path,2)\n",
        "X_T1_t,rec      =   modality(Path,10)\n",
        "X_T2_t,rec      =   modality(Path,11)\n",
        "rec=np.array(rec_1,dtype='float32')\n",
        "np.save(\"drive/My Drive/MS_data/union_new_rec_before_removal.npy\",rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3Tle7mzagTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input ,BatchNormalization , Activation \n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#import dataPrepare as process\n",
        "# Loading all the 5 different modalities of each MRI Scan of all 15 different patients and 1st rater Manual SegmentationX_Dp      =   modality(Path,0)\n",
        "#import Modified_UNet \n",
        "#import plots\n",
        "#import Metrics\n",
        "\n",
        "# Setting the path\n",
        "Path='drive/My Drive/Pre-processed'\n",
        "Y_1,rec  =   modality(Path,3)\n",
        "Y_2,rec  =   modality(Path,4)\n",
        "Y_3,rec  =   modality(Path,5)\n",
        "Y_4,rec  =   modality(Path,6)\n",
        "Y_5,rec  =   modality(Path,7)\n",
        "Y_6,rec  =   modality(Path,8)\n",
        "Y_7,rec  =   modality(Path,9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0--q1oVfedwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=union(Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VX5ZRKZe2jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.save(\"drive/My Drive/MS_data/Y_manual_new.npy\",Y_Manual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMWCB-BLfHC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_manual=list(Y_Manual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgxmMj5le6iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=np.load(\"drive/My Drive/MS_data/Y_manual_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goAAL10Ze80r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y,rec = remove_null_samples(X_Dp_t, X_Flair_t, X_Gado_t, X_T1_t, X_T2_t, Y_manual,rec_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ-ZFwhpfOJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "store_data(X,Y,rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqjvU2Urf-mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "Y=np.load(\"drive/My Drive/MS_data/Y_union_new.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dRywTCzgSEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Manual=list(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EA-WGRygUO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_1=Y_Manual[:1401]\n",
        "Y_2=Y_Manual[1401:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFbr6tHHgXPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p=[]\n",
        "y=[]\n",
        "z=[]\n",
        "a=[]\n",
        "n=1\n",
        "for i in Y_1:\n",
        "  print(n)\n",
        "  for j in i:\n",
        "    for k in j:\n",
        "      #print(k)\n",
        "      a.append(k)\n",
        "     # print(a)\n",
        "      z.append(a)\n",
        "      a=[]\n",
        "    #print(z)\n",
        "    y.append(z)\n",
        "    z=[]\n",
        "  p.append(y)\n",
        "  y=[]\n",
        "  n+=1\n",
        "\n",
        "\n",
        "#print(p)\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ncgh9SOgo5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=np.array(p)\n",
        "np.save(\"drive/My Drive/MS_data/temp_1_new.npy\",temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiLTzt0_g9EQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q=[]\n",
        "y=[]\n",
        "z=[]\n",
        "a=[]\n",
        "n=1401\n",
        "for i in Y_2:\n",
        "  print(n)\n",
        "  for j in i:\n",
        "    for k in j:\n",
        "      #print(k)\n",
        "      a.append(k)\n",
        "     # print(a)\n",
        "      z.append(a)\n",
        "      a=[]\n",
        "    #print(z)\n",
        "    y.append(z)\n",
        "    z=[]\n",
        "  q.append(y)\n",
        "  y=[]\n",
        "  n+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWkfWXjYg-eX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp2=np.array(q)\n",
        "np.save(\"drive/My Drive/MS_data/temp_2_new.npy\",temp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Nrqc_jhVrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp=np.load(\"drive/My Drive/MS_data/temp_1_new.npy\")\n",
        "p=list(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXhxPVjJhZdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j=1401\n",
        "for i in q:\n",
        "  print(j)\n",
        "  p.append(i)\n",
        "  j+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FihK4Np_hdYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\",p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC_yBrO3iaKd",
        "colab_type": "text"
      },
      "source": [
        "## creating train test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TEPIJ8IiKzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r=np.load(\"drive/My Drive/MS_data/union_new_rec_after_removal.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g5l9a8PivG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec=list(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0idtse3ixs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "i=0\n",
        "file_w=\"drive/My Drive/MS_data/per_paitent_records.json\"\n",
        "prev=0\n",
        "total=0\n",
        "dict_k={}\n",
        "while i<len(r):\n",
        "  current=r[i]\n",
        "  j=i+1\n",
        "  dict_k[str(j)]={}\n",
        "  dict_k[str(j)][\"Starting\"]=prev\n",
        "  dict_k[str(j)][\"Ending\"]=total+current-1\n",
        "  total+=current\n",
        "  prev=total\n",
        "  i+=1\n",
        "\n",
        "with open(file_w, \"w\") as outfile:\n",
        "\t\t\tjson.dump(dict_k, outfile) \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzjoMYjyp7Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import json\n",
        "dict_l={}\n",
        "list_val=[]\n",
        "list_train=[]\n",
        "file_w=\"drive/My Drive/MS_data/set_divisions.json\"\n",
        "list_test=[]\n",
        "for i in range(5):\n",
        "  patient_list=['1','2','3','4','5','6','7','8','9','10','11','12','13','14']\n",
        "  for j in range(7):\n",
        "    flag=0\n",
        "    while(flag!=1):\n",
        "      num=random.randint(1,14)\n",
        "      if patient_list.count(str(num))> 0:\n",
        "        list_train.append(str(num))\n",
        "        patient_list.remove(str(num))\n",
        "        flag=1\n",
        "  if dict_l.get(\"train\") is None:\n",
        "    dict_l[\"train\"]=[list_train]\n",
        "  else:\n",
        "    dict_l[\"train\"].append(list_train)\n",
        "  list_train=[]\n",
        "  for j in range(3):\n",
        "    flag=0\n",
        "    while(flag!=1):\n",
        "      num=random.randint(1,14)\n",
        "      if patient_list.count(str(num))> 0:\n",
        "        list_val.append(str(num))\n",
        "        patient_list.remove(str(num))\n",
        "        flag=1\n",
        "  if dict_l.get(\"validate\") is None:\n",
        "    dict_l[\"validate\"]=[list_val]\n",
        "  else:\n",
        "    dict_l[\"validate\"].append(list_val)\n",
        "  list_val=[]\n",
        "  for j in range(4):\n",
        "    flag=0\n",
        "    while(flag!=1):\n",
        "      num=random.randint(1,14)\n",
        "      if patient_list.count(str(num))> 0:\n",
        "        list_test.append(str(num))\n",
        "        patient_list.remove(str(num))\n",
        "        flag=1\n",
        "  if dict_l.get(\"test\") is None:\n",
        "    dict_l[\"test\"]=[list_test]\n",
        "  else:\n",
        "    dict_l[\"test\"].append(list_test)\n",
        "  list_test=[]    \n",
        "\n",
        "with open(file_w, \"w\") as outfile:\n",
        "\t\t\tjson.dump(dict_l, outfile) \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXmhL8uJCWRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "32f3cc1b-158d-4b92-f910-520ca2b50814"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "Y=np.load(\"drive/My Drive/MS_data/Y_Manual_2_new.npy\")\n",
        "print(len(Y))\n",
        "X=np.load(\"drive/My Drive/MS_data/X_union_new.npy\")\n",
        "print(len(X))\n",
        "f1=open(\"drive/My Drive/MS_data/per_paitent_records.json\")\n",
        "data_1=json.load(f1)\n",
        "f2=open(\"drive/My Drive/MS_data/set_divisions.json\")\n",
        "data_2=json.load(f2)\n",
        "i=1\n",
        "while i<=5:\n",
        "  file_1=\"drive/My Drive/MS_data/\"+str(i)\n",
        "  print(file_1)\n",
        "  os.mkdir(file_1)\n",
        "  train_list=(data_2['train'])[i-1]\n",
        "  file_1_ext=file_1+'/train'\n",
        "  print(file_1_ext)\n",
        "  os.mkdir(file_1_ext)\n",
        "  X_temp=[]\n",
        "  Y_temp=[]\n",
        "  for j in train_list:\n",
        "    st_index=data_1[str(j)][\"Starting\"]\n",
        "    end_index=data_1[str(j)][\"Ending\"]\n",
        "    X_temp.append(X[int(st_index):int(end_index)])\n",
        "    Y_temp.append(Y[int(st_index):int(end_index)])\n",
        "  file_1_X=file_1_ext+'/'+'X.npy'\n",
        "  file_1_Y=file_1_ext+'/'+'Y.npy'\n",
        "  X_temp_np=np.concatenate((X_temp[0],X_temp[1],X_temp[2],X_temp[3],X_temp[4],X_temp[5],X_temp[6]),axis=0)\n",
        "  Y_temp_np=np.concatenate((Y_temp[0],Y_temp[1],Y_temp[2],Y_temp[3],Y_temp[4],Y_temp[5],Y_temp[6]),axis=0)\n",
        "  print(len(X_temp_np))\n",
        "  print(len(Y_temp_np))\n",
        "  np.save(file_1_X,X_temp_np)\n",
        "  np.save(file_1_Y,Y_temp_np)\n",
        "  train_list=(data_2['validate'])[i-1]\n",
        "  file_1_ext=file_1+'/validate'\n",
        "  os.mkdir(file_1_ext)\n",
        "  X_temp=[]\n",
        "  Y_temp=[]\n",
        "  for j in train_list:\n",
        "    st_index=data_1[str(j)][\"Starting\"]\n",
        "    end_index=data_1[str(j)][\"Ending\"]\n",
        "    X_temp.append(X[int(st_index):int(end_index)])\n",
        "    Y_temp.append(Y[int(st_index):int(end_index)])\n",
        "  file_1_X=file_1_ext+'/'+'X.npy'\n",
        "  file_1_Y=file_1_ext+'/'+'Y.npy'\n",
        "  X_temp_np=np.concatenate((X_temp[0],X_temp[1],X_temp[2]),axis=0)\n",
        "  Y_temp_np=np.concatenate((Y_temp[0],Y_temp[1],Y_temp[2]),axis=0)\n",
        "  print(len(X_temp_np))\n",
        "  print(len(Y_temp_np))\n",
        "  np.save(file_1_X,X_temp_np)\n",
        "  np.save(file_1_Y,Y_temp_np)\n",
        "  train_list=(data_2['test'])[i-1]\n",
        "  file_1_ext=file_1+'/test'\n",
        "  os.mkdir(file_1_ext)\n",
        "  X_temp=[]\n",
        "  Y_temp=[]\n",
        "  for j in train_list:\n",
        "    st_index=data_1[str(j)][\"Starting\"]\n",
        "    end_index=data_1[str(j)][\"Ending\"]\n",
        "    X_temp.append(X[int(st_index):int(end_index)])\n",
        "    Y_temp.append(Y[int(st_index):int(end_index)])\n",
        "  file_1_X=file_1_ext+'/'+'X.npy'\n",
        "  file_1_Y=file_1_ext+'/'+'Y.npy'\n",
        "  X_temp_np=np.concatenate((X_temp[0],X_temp[1],X_temp[2],X_temp[3]),axis=0)\n",
        "  Y_temp_np=np.concatenate((Y_temp[0],Y_temp[1],Y_temp[2],Y_temp[3]),axis=0)\n",
        "  print(len(X_temp_np))\n",
        "  print(len(Y_temp_np))\n",
        "  np.save(file_1_X,X_temp_np)\n",
        "  np.save(file_1_Y,Y_temp_np)\n",
        "  i+=1\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2940\n",
            "2940\n",
            "drive/My Drive/MS_data/1\n",
            "drive/My Drive/MS_data/1/train\n",
            "1598\n",
            "1598\n",
            "467\n",
            "467\n",
            "861\n",
            "861\n",
            "drive/My Drive/MS_data/2\n",
            "drive/My Drive/MS_data/2/train\n",
            "1443\n",
            "1443\n",
            "724\n",
            "724\n",
            "759\n",
            "759\n",
            "drive/My Drive/MS_data/3\n",
            "drive/My Drive/MS_data/3/train\n",
            "1582\n",
            "1582\n",
            "469\n",
            "469\n",
            "875\n",
            "875\n",
            "drive/My Drive/MS_data/4\n",
            "drive/My Drive/MS_data/4/train\n",
            "1492\n",
            "1492\n",
            "618\n",
            "618\n",
            "816\n",
            "816\n",
            "drive/My Drive/MS_data/5\n",
            "drive/My Drive/MS_data/5/train\n",
            "1461\n",
            "1461\n",
            "641\n",
            "641\n",
            "824\n",
            "824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIIk37CVb3EM",
        "colab_type": "text"
      },
      "source": [
        "## Setting up Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpTizK5WYZWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "efe2c8bd-7183-4f58-b810-fe6f5ae2afdc"
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://fde7aff2.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtnIeIvcctIR",
        "colab_type": "text"
      },
      "source": [
        "## loading dataset and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQQ9O6Rocw8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}